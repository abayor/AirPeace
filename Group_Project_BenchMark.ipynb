{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Group Project BenchMark.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/abayor/AirPeace/blob/master/Group_Project_BenchMark.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "k5EhE2tn2PXs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Group Project\n",
        "\n",
        "This notebook along with the [TensorFlow and deep learning, without a PhD](https://codelabs.developers.google.com/codelabs/cloud-tensorflow-mnist/#0) codelabs should serve as a starter guide for your group projects. For the project, you are to build a model that achieves a minimum of 96% accuracy for a classification task on the MNIST dataset. This can be achieved by several methods, but you are required to follow some certain steps as outlined below:\n",
        "\n",
        "1. Load the mnist dataset from tensorflow. This consists of the train, validation, and test sets.\n",
        "    The train set has 55000 examples,\n",
        "    The validation set has 5000 examples, and\n",
        "    the test set has 10000 examples.\n",
        "    \n",
        "2. Visualize the examples in each set.\n",
        " \n",
        "3. Build a softmax regression model (a 1 layer neural network)and train it on the dataset.\n",
        "\n",
        "4. Add a hidden layer of 200 neurons, use sigmoid activation for hidden units, train and obtain train, validation and test accuracies and loss\n",
        "\n",
        "5. Build a five layers neural network with sigmoid activation\n",
        "\n",
        "6. Replace the sigmoid activations with relu\n",
        "\n",
        "7. Introduce learning rate decay\n",
        "\n",
        "8. Use dropout\n",
        "\n",
        "9. Convolutional Neural Networks\n"
      ]
    },
    {
      "metadata": {
        "id": "KuW0P6x22MJG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "cellView": "form",
        "outputId": "a6a2826a-ee43-4150-810f-5668feee8041"
      },
      "cell_type": "code",
      "source": [
        "#@title All imports and Initializations(RUN THIS CELL!)\n",
        "'''\n",
        "Obtain MNIST dataset using tensorflow\n",
        "'''\n",
        "import tensorflow as tf\n",
        "import math\n",
        "import numpy as np\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)\n",
        "\n",
        "\n",
        "def view_image(x,y):\n",
        "  '''\n",
        "  View 10 random images from a dataset\n",
        "  \n",
        "  input:\n",
        "    x => ndarray[of shape (m x n)] (examples)\n",
        "    y => ndarray[of shape (m x c)] (onehot encoded)\n",
        "          m = no of examples\n",
        "          c = no of classes\n",
        "  output:\n",
        "    None.\n",
        "   \n",
        "  '''\n",
        "  f, axarr = plt.subplots(2,5)\n",
        "  \n",
        "  for ax in f.axes:\n",
        "    i = np.random.randint(x.shape[0]) # pick a random example (ith example)\n",
        "    ax.get_xaxis().set_ticks([]) # don't label the xaxis\n",
        "    ax.get_yaxis().set_ticks([]) # don't label the yais\n",
        "    ax.text(0,0, np.argmax(y[i])) # display a text containing the ith example's class\n",
        "    ax.imshow(x[i].reshape(28,28)) # display the ith example\n",
        "\n",
        "    \n",
        "    \n",
        "# This function does the training\n",
        "\n",
        "def training(X_train, y_train, X_val, y_val, sess, epochs = 1, mini_batch = 100, step=None, pkeep=None):\n",
        "  \n",
        "    '''\n",
        "    **arguments**\n",
        "    X_train:\n",
        "      The input feature matrix\n",
        "    y_train:\n",
        "      The output true label\n",
        "    X_val:\n",
        "      The validation set feature matrix\n",
        "    y_val:\n",
        "      The validation set true label\n",
        "    sess:\n",
        "      A tensorflow session to run the computational graph\n",
        "    epochs:\n",
        "      No of times to run through the entire examples \n",
        "    mini_batch:\n",
        "      No of examples to use in each train step\n",
        "      \n",
        "      \n",
        "    **returns**\n",
        "    history: tuple\n",
        "      a tuple containing the train and validation accuracies and losses\n",
        "      \n",
        "    '''\n",
        "    \n",
        "    accuracies = []\n",
        "    loss = []\n",
        "    accuracies_validation = []\n",
        "    loss_validation = []\n",
        "    \n",
        "    steps_per_epoch = int(X_train.shape[0]/mini_batch)\n",
        "    training_steps = epochs * steps_per_epoch\n",
        "  \n",
        "    for i in range(1,training_steps+1):\n",
        "      # pick a mini batch from the training\n",
        "      s = i%steps_per_epoch\n",
        "      batch_X, batch_Y = X_train[(s-1)*mini_batch:(s)*mini_batch], y_train[(s-1)*mini_batch:(s)*mini_batch]\n",
        "\n",
        "      # compute train/validation loss and accuracy\n",
        "      if i%steps_per_epoch == 0:\n",
        "          # train\n",
        "          if(step != None and pkeep == None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_train, y: y_train})\n",
        "          if(step == None and pkeep != None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_train, y: y_train, pkeep_val: pkeep})\n",
        "          if(step != None and pkeep != None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_train, y: y_train, pkeep_val: pkeep})\n",
        "          if(step == None and pkeep == None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_train, y: y_train})\n",
        "          loss.append(c)\n",
        "          accuracies.append(a)\n",
        "          print(\"EPOCH \" + str(i/steps_per_epoch) + \"\\n\" + \" train accuracy:\" + str(a) + \"train loss: \" + str(c))\n",
        "          \n",
        "          # validation\n",
        "          if(step != None and pkeep == None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_val, y: y_val})\n",
        "          if(step == None and pkeep != None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_val, y: y_val, pkeep_val: 1})\n",
        "          if(step != None and pkeep != None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_val, y: y_val, pkeep_val: 1})\n",
        "          if(step == None and pkeep == None):\n",
        "            a, c = sess.run([accuracy, cross_entropy], feed_dict={X: X_val, y: y_val})\n",
        "         \n",
        "          loss_validation.append(c)\n",
        "          accuracies_validation.append(a)\n",
        "          print(\" ********* validation accuracy:\" + str(a) + \" validation loss: \" + str(c))\n",
        "\n",
        "      # the backpropagation training step\n",
        "     \n",
        "      if(step != None and pkeep == None):\n",
        "        sess.run(train_step, feed_dict={X: batch_X, y: batch_Y, step_val: i})\n",
        "      if(step == None and pkeep != None):\n",
        "        sess.run(train_step, feed_dict={X: batch_X, y: batch_Y, pkeep_val: pkeep})\n",
        "      if(step != None and pkeep != None):\n",
        "        sess.run([train_step], feed_dict={X: X_val, y: y_val, step_val: i, pkeep_val: pkeep})\n",
        "      if(step == None and pkeep == None):\n",
        "        sess.run(train_step, feed_dict={X: X_val, y: y_val})\n",
        "         \n",
        "      \n",
        "      history = (accuracies, loss, accuracies_validation, loss_validation)\n",
        "      \n",
        "    return history\n",
        "  \n",
        "\n",
        "\n",
        "def plot_history(history):\n",
        "  accuracies, loss, accuracies_validation, loss_validation = history\n",
        "  f, ax = plt.subplots(2,2)\n",
        "  ax[0,0].plot(accuracies)\n",
        "  ax[0,0].set(xlabel='epochs', ylabel='train_accuracy')\n",
        "\n",
        "  ax[0,1].plot(loss )\n",
        "  ax[0,1].set(xlabel='epochs', ylabel='train_loss')\n",
        "\n",
        "  ax[1,0].plot(accuracies_validation)\n",
        "  ax[1,0].set(xlabel='epochs', ylabel='val_accuracy')\n",
        "\n",
        "\n",
        "  ax[1,1].plot(loss_validation)\n",
        "  ax[1,1].set(xlabel='epochs', ylabel='val_loss')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-be6b62f0b2cd>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mIq-UYMV7lPM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Load the dataset\n",
        "for the train set, x_train contains the 55000 train images and y_train contains the onehot encoded label. Same applies to the validation and test set\n"
      ]
    },
    {
      "metadata": {
        "id": "54JONBsi2og5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = mnist.train.images\n",
        "y_train = mnist.train.labels\n",
        "x_val = mnist.validation.images\n",
        "y_val = mnist.validation.labels\n",
        "x_test = mnist.test.images\n",
        "y_test = mnist.test.labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fyGSjVYm8QF5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The train images are 28x28 gray scale images. But the loaded images are flattened to be of size (1x784). Hence the size of the train set images is 55000 by 784. this means that there are 55000 examples of size (28*28=784). The same applies to the validation and test set"
      ]
    },
    {
      "metadata": {
        "id": "W0pFX8d_7fON",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "533cbe63-a319-4583-d0c1-6b706af2f7ea"
      },
      "cell_type": "code",
      "source": [
        "print('shape of train set is: {0}, this means that it has {1} examples'.format(x_train.shape, x_train.shape[0]))\n",
        "print('shape of validation set is: {0}, this means that it has {1} examples'.format(x_val.shape, x_val.shape[0]))\n",
        "print('shape of test set is: {0}, this means that it has {1} examples'.format(x_test.shape, x_test.shape[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of train set is: (55000, 784), this means that it has 55000 examples\n",
            "shape of validation set is: (5000, 784), this means that it has 5000 examples\n",
            "shape of test set is: (10000, 784), this means that it has 10000 examples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5bK94_BcKgpt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Visualize examples in each set"
      ]
    },
    {
      "metadata": {
        "id": "_WlCHS7PAsIo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "View 10 random examples from train, validation and test set\n"
      ]
    },
    {
      "metadata": {
        "id": "45qVB5rpG6Su",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "View 10 random images from the train set"
      ]
    },
    {
      "metadata": {
        "id": "yfAfgPptB-se",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "a1f800b8-0330-4b37-dcd1-2e5677c0109b"
      },
      "cell_type": "code",
      "source": [
        "view_image(x_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAEGCAYAAADoqKVUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAACkDABAAhAwgQAIMD/Ac4+cWQWp2vIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f73c1fe2048>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "awn7v9iZJcIo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "View 10 random images from the validation set"
      ]
    },
    {
      "metadata": {
        "id": "RIgM8j_U-VLb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "bbe404ea-dcc0-4a0d-fb0c-aaf65b7fa69a"
      },
      "cell_type": "code",
      "source": [
        "view_image(x_val, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAEGCAYAAADoqKVUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVFOkAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f736940e240>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "dhFTCTnHJgCP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "View 10 random images from the test set"
      ]
    },
    {
      "metadata": {
        "id": "uRupYMZdCA58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "34c8a218-d38d-43b3-d7a7-2f01c8411532"
      },
      "cell_type": "code",
      "source": [
        "view_image(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAcwAAAEGCAYAAADoqKVUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f736699e780>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "LIluzD0HLuW6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Build a softmax regression model (a 1 layer neural network)and train it on the dataset.\n",
        "\n",
        "\n",
        "Build Computational Graph"
      ]
    },
    {
      "metadata": {
        "id": "8KVATReeJXo_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# input \n",
        "X = tf.placeholder(tf.float32, [None,784])\n",
        "# labels (onehot encoded)\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "# weights\n",
        "W = tf.Variable(tf.zeros([784, 10]))\n",
        "# biases\n",
        "b = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "# weigthed sum\n",
        "z = tf.matmul(X, W) + b\n",
        "\n",
        "# softmax activation\n",
        "h = tf.nn.softmax(z)\n",
        "\n",
        "# softmax cross entropy loss\n",
        "cross_entropy = -tf.reduce_mean(y * tf.log(h))\n",
        "\n",
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "correct_prediction = tf.equal(tf.argmax(h, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# training, learning rate = 0.005\n",
        "# learning rate\n",
        "lr = 0.05\n",
        "train_step = tf.train.GradientDescentOptimizer(lr).minimize(cross_entropy)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZWHM-c3bBcYn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start the session"
      ]
    },
    {
      "metadata": {
        "id": "p67DYcSDU0La",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize all variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KeJzsGiRAhqw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train for 100 epochs"
      ]
    },
    {
      "metadata": {
        "id": "tG4i3jLk4a8a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5227
        },
        "outputId": "bcc0dbf9-8f87-4c8a-ffc4-2cf51e0458aa"
      },
      "cell_type": "code",
      "source": [
        "history = training(x_train, y_train, x_val, y_val, sess, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1.0\n",
            " train accuracy:0.81290907train loss: 0.10421076\n",
            " ********* validation accuracy:0.8278 validation loss: 0.100569345\n",
            "EPOCH 2.0\n",
            " train accuracy:0.8397818train loss: 0.077530466\n",
            " ********* validation accuracy:0.854 validation loss: 0.07330518\n",
            "EPOCH 3.0\n",
            " train accuracy:0.85112727train loss: 0.0663209\n",
            " ********* validation accuracy:0.8682 validation loss: 0.061760645\n",
            "EPOCH 4.0\n",
            " train accuracy:0.85827273train loss: 0.060005482\n",
            " ********* validation accuracy:0.8778 validation loss: 0.0551724\n",
            "EPOCH 5.0\n",
            " train accuracy:0.8630546train loss: 0.055886123\n",
            " ********* validation accuracy:0.8838 validation loss: 0.050811954\n",
            "EPOCH 6.0\n",
            " train accuracy:0.8674train loss: 0.05295443\n",
            " ********* validation accuracy:0.8896 validation loss: 0.047660537\n",
            "EPOCH 7.0\n",
            " train accuracy:0.87052727train loss: 0.05074413\n",
            " ********* validation accuracy:0.8934 validation loss: 0.045246504\n",
            "EPOCH 8.0\n",
            " train accuracy:0.87290907train loss: 0.049008124\n",
            " ********* validation accuracy:0.8962 validation loss: 0.043319467\n",
            "EPOCH 9.0\n",
            " train accuracy:0.87527275train loss: 0.047602475\n",
            " ********* validation accuracy:0.899 validation loss: 0.041733246\n",
            "EPOCH 10.0\n",
            " train accuracy:0.8768909train loss: 0.04643719\n",
            " ********* validation accuracy:0.9014 validation loss: 0.040396243\n",
            "EPOCH 11.0\n",
            " train accuracy:0.8784909train loss: 0.04545291\n",
            " ********* validation accuracy:0.904 validation loss: 0.0392479\n",
            "EPOCH 12.0\n",
            " train accuracy:0.8803091train loss: 0.044608757\n",
            " ********* validation accuracy:0.9054 validation loss: 0.038246367\n",
            "EPOCH 13.0\n",
            " train accuracy:0.8814909train loss: 0.043875586\n",
            " ********* validation accuracy:0.9078 validation loss: 0.03736174\n",
            "EPOCH 14.0\n",
            " train accuracy:0.8829273train loss: 0.043231975\n",
            " ********* validation accuracy:0.9094 validation loss: 0.03657199\n",
            "EPOCH 15.0\n",
            " train accuracy:0.88403636train loss: 0.042661842\n",
            " ********* validation accuracy:0.9112 validation loss: 0.03586051\n",
            "EPOCH 16.0\n",
            " train accuracy:0.8848364train loss: 0.042152826\n",
            " ********* validation accuracy:0.9128 validation loss: 0.03521449\n",
            "EPOCH 17.0\n",
            " train accuracy:0.88543636train loss: 0.041695263\n",
            " ********* validation accuracy:0.9136 validation loss: 0.034623895\n",
            "EPOCH 18.0\n",
            " train accuracy:0.88603634train loss: 0.041281477\n",
            " ********* validation accuracy:0.914 validation loss: 0.03408073\n",
            "EPOCH 19.0\n",
            " train accuracy:0.8866train loss: 0.040905297\n",
            " ********* validation accuracy:0.9148 validation loss: 0.033578523\n",
            "EPOCH 20.0\n",
            " train accuracy:0.8871273train loss: 0.04056169\n",
            " ********* validation accuracy:0.9154 validation loss: 0.033111993\n",
            "EPOCH 21.0\n",
            " train accuracy:0.88765454train loss: 0.0402465\n",
            " ********* validation accuracy:0.9164 validation loss: 0.032676775\n",
            "EPOCH 22.0\n",
            " train accuracy:0.8882train loss: 0.039956283\n",
            " ********* validation accuracy:0.9174 validation loss: 0.032269213\n",
            "EPOCH 23.0\n",
            " train accuracy:0.8887454train loss: 0.03968814\n",
            " ********* validation accuracy:0.9176 validation loss: 0.03188624\n",
            "EPOCH 24.0\n",
            " train accuracy:0.88903636train loss: 0.03943962\n",
            " ********* validation accuracy:0.9176 validation loss: 0.03152525\n",
            "EPOCH 25.0\n",
            " train accuracy:0.8894train loss: 0.039208632\n",
            " ********* validation accuracy:0.9192 validation loss: 0.031183999\n",
            "EPOCH 26.0\n",
            " train accuracy:0.88985455train loss: 0.03899338\n",
            " ********* validation accuracy:0.9198 validation loss: 0.030860577\n",
            "EPOCH 27.0\n",
            " train accuracy:0.89016366train loss: 0.038792323\n",
            " ********* validation accuracy:0.9214 validation loss: 0.030553311\n",
            "EPOCH 28.0\n",
            " train accuracy:0.8905636train loss: 0.038604107\n",
            " ********* validation accuracy:0.9218 validation loss: 0.03026075\n",
            "EPOCH 29.0\n",
            " train accuracy:0.8909636train loss: 0.038427558\n",
            " ********* validation accuracy:0.9228 validation loss: 0.029981626\n",
            "EPOCH 30.0\n",
            " train accuracy:0.8914545train loss: 0.03826165\n",
            " ********* validation accuracy:0.9234 validation loss: 0.029714815\n",
            "EPOCH 31.0\n",
            " train accuracy:0.89181817train loss: 0.038105465\n",
            " ********* validation accuracy:0.9246 validation loss: 0.029459331\n",
            "EPOCH 32.0\n",
            " train accuracy:0.8920909train loss: 0.03795821\n",
            " ********* validation accuracy:0.9254 validation loss: 0.029214289\n",
            "EPOCH 33.0\n",
            " train accuracy:0.89245456train loss: 0.037819166\n",
            " ********* validation accuracy:0.926 validation loss: 0.02897891\n",
            "EPOCH 34.0\n",
            " train accuracy:0.8927818train loss: 0.037687693\n",
            " ********* validation accuracy:0.9262 validation loss: 0.02875249\n",
            "EPOCH 35.0\n",
            " train accuracy:0.8930727train loss: 0.03756321\n",
            " ********* validation accuracy:0.9266 validation loss: 0.028534397\n",
            "EPOCH 36.0\n",
            " train accuracy:0.8933273train loss: 0.03744522\n",
            " ********* validation accuracy:0.927 validation loss: 0.028324068\n",
            "EPOCH 37.0\n",
            " train accuracy:0.89345455train loss: 0.037333254\n",
            " ********* validation accuracy:0.9282 validation loss: 0.028120982\n",
            "EPOCH 38.0\n",
            " train accuracy:0.8937455train loss: 0.037226893\n",
            " ********* validation accuracy:0.9292 validation loss: 0.027924677\n",
            "EPOCH 39.0\n",
            " train accuracy:0.8938182train loss: 0.03712575\n",
            " ********* validation accuracy:0.9296 validation loss: 0.027734734\n",
            "EPOCH 40.0\n",
            " train accuracy:0.8942train loss: 0.037029505\n",
            " ********* validation accuracy:0.9298 validation loss: 0.027550757\n",
            "EPOCH 41.0\n",
            " train accuracy:0.8942364train loss: 0.036937814\n",
            " ********* validation accuracy:0.9302 validation loss: 0.0273724\n",
            "EPOCH 42.0\n",
            " train accuracy:0.8944909train loss: 0.03685041\n",
            " ********* validation accuracy:0.9302 validation loss: 0.027199341\n",
            "EPOCH 43.0\n",
            " train accuracy:0.8946train loss: 0.03676702\n",
            " ********* validation accuracy:0.9306 validation loss: 0.027031276\n",
            "EPOCH 44.0\n",
            " train accuracy:0.8948182train loss: 0.036687415\n",
            " ********* validation accuracy:0.9314 validation loss: 0.02686794\n",
            "EPOCH 45.0\n",
            " train accuracy:0.8948727train loss: 0.03661136\n",
            " ********* validation accuracy:0.9316 validation loss: 0.026709072\n",
            "EPOCH 46.0\n",
            " train accuracy:0.8950545train loss: 0.036538664\n",
            " ********* validation accuracy:0.932 validation loss: 0.026554449\n",
            "EPOCH 47.0\n",
            " train accuracy:0.8951455train loss: 0.03646913\n",
            " ********* validation accuracy:0.9326 validation loss: 0.026403852\n",
            "EPOCH 48.0\n",
            " train accuracy:0.8952182train loss: 0.036402587\n",
            " ********* validation accuracy:0.9336 validation loss: 0.026257081\n",
            "EPOCH 49.0\n",
            " train accuracy:0.8953091train loss: 0.036338873\n",
            " ********* validation accuracy:0.934 validation loss: 0.02611395\n",
            "EPOCH 50.0\n",
            " train accuracy:0.89543635train loss: 0.036277834\n",
            " ********* validation accuracy:0.9346 validation loss: 0.025974287\n",
            "EPOCH 51.0\n",
            " train accuracy:0.8956train loss: 0.03621934\n",
            " ********* validation accuracy:0.935 validation loss: 0.025837932\n",
            "EPOCH 52.0\n",
            " train accuracy:0.8958train loss: 0.036163256\n",
            " ********* validation accuracy:0.9352 validation loss: 0.025704734\n",
            "EPOCH 53.0\n",
            " train accuracy:0.89583635train loss: 0.036109462\n",
            " ********* validation accuracy:0.9352 validation loss: 0.025574556\n",
            "EPOCH 54.0\n",
            " train accuracy:0.8958727train loss: 0.03605785\n",
            " ********* validation accuracy:0.9352 validation loss: 0.02544726\n",
            "EPOCH 55.0\n",
            " train accuracy:0.8959818train loss: 0.03600831\n",
            " ********* validation accuracy:0.9362 validation loss: 0.02532273\n",
            "EPOCH 56.0\n",
            " train accuracy:0.89605457train loss: 0.035960745\n",
            " ********* validation accuracy:0.9368 validation loss: 0.025200844\n",
            "EPOCH 57.0\n",
            " train accuracy:0.8961818train loss: 0.035915066\n",
            " ********* validation accuracy:0.9368 validation loss: 0.025081499\n",
            "EPOCH 58.0\n",
            " train accuracy:0.8962182train loss: 0.035871178\n",
            " ********* validation accuracy:0.937 validation loss: 0.02496459\n",
            "EPOCH 59.0\n",
            " train accuracy:0.8962909train loss: 0.035829008\n",
            " ********* validation accuracy:0.9372 validation loss: 0.024850022\n",
            "EPOCH 60.0\n",
            " train accuracy:0.8965091train loss: 0.035788484\n",
            " ********* validation accuracy:0.9372 validation loss: 0.024737703\n",
            "EPOCH 61.0\n",
            " train accuracy:0.8966182train loss: 0.035749525\n",
            " ********* validation accuracy:0.9374 validation loss: 0.024627551\n",
            "EPOCH 62.0\n",
            " train accuracy:0.89674544train loss: 0.03571206\n",
            " ********* validation accuracy:0.938 validation loss: 0.024519484\n",
            "EPOCH 63.0\n",
            " train accuracy:0.89689094train loss: 0.035676036\n",
            " ********* validation accuracy:0.9384 validation loss: 0.024413425\n",
            "EPOCH 64.0\n",
            " train accuracy:0.8969091train loss: 0.03564138\n",
            " ********* validation accuracy:0.9384 validation loss: 0.024309296\n",
            "EPOCH 65.0\n",
            " train accuracy:0.89707273train loss: 0.035608057\n",
            " ********* validation accuracy:0.9386 validation loss: 0.024207039\n",
            "EPOCH 66.0\n",
            " train accuracy:0.8970909train loss: 0.035575993\n",
            " ********* validation accuracy:0.939 validation loss: 0.024106583\n",
            "EPOCH 67.0\n",
            " train accuracy:0.89721817train loss: 0.035545144\n",
            " ********* validation accuracy:0.939 validation loss: 0.024007866\n",
            "EPOCH 68.0\n",
            " train accuracy:0.8972909train loss: 0.03551547\n",
            " ********* validation accuracy:0.9392 validation loss: 0.02391083\n",
            "EPOCH 69.0\n",
            " train accuracy:0.8972909train loss: 0.03548691\n",
            " ********* validation accuracy:0.9392 validation loss: 0.023815418\n",
            "EPOCH 70.0\n",
            " train accuracy:0.8972727train loss: 0.035459433\n",
            " ********* validation accuracy:0.9392 validation loss: 0.023721578\n",
            "EPOCH 71.0\n",
            " train accuracy:0.89738184train loss: 0.035432983\n",
            " ********* validation accuracy:0.9394 validation loss: 0.023629263\n",
            "EPOCH 72.0\n",
            " train accuracy:0.89756364train loss: 0.035407536\n",
            " ********* validation accuracy:0.9394 validation loss: 0.023538424\n",
            "EPOCH 73.0\n",
            " train accuracy:0.8978364train loss: 0.035383042\n",
            " ********* validation accuracy:0.9394 validation loss: 0.023449013\n",
            "EPOCH 74.0\n",
            " train accuracy:0.8978909train loss: 0.03535948\n",
            " ********* validation accuracy:0.9396 validation loss: 0.02336098\n",
            "EPOCH 75.0\n",
            " train accuracy:0.89794546train loss: 0.03533681\n",
            " ********* validation accuracy:0.9402 validation loss: 0.023274295\n",
            "EPOCH 76.0\n",
            " train accuracy:0.89796364train loss: 0.035315\n",
            " ********* validation accuracy:0.9406 validation loss: 0.02318891\n",
            "EPOCH 77.0\n",
            " train accuracy:0.8980909train loss: 0.03529402\n",
            " ********* validation accuracy:0.9406 validation loss: 0.02310479\n",
            "EPOCH 78.0\n",
            " train accuracy:0.89823633train loss: 0.035273828\n",
            " ********* validation accuracy:0.941 validation loss: 0.023021895\n",
            "EPOCH 79.0\n",
            " train accuracy:0.89827275train loss: 0.03525442\n",
            " ********* validation accuracy:0.941 validation loss: 0.022940192\n",
            "EPOCH 80.0\n",
            " train accuracy:0.8981818train loss: 0.03523575\n",
            " ********* validation accuracy:0.9414 validation loss: 0.022859653\n",
            "EPOCH 81.0\n",
            " train accuracy:0.89821815train loss: 0.035217807\n",
            " ********* validation accuracy:0.9414 validation loss: 0.022780234\n",
            "EPOCH 82.0\n",
            " train accuracy:0.89823633train loss: 0.035200555\n",
            " ********* validation accuracy:0.9412 validation loss: 0.022701913\n",
            "EPOCH 83.0\n",
            " train accuracy:0.89829093train loss: 0.035183974\n",
            " ********* validation accuracy:0.9414 validation loss: 0.022624658\n",
            "EPOCH 84.0\n",
            " train accuracy:0.8983818train loss: 0.035168044\n",
            " ********* validation accuracy:0.9416 validation loss: 0.022548443\n",
            "EPOCH 85.0\n",
            " train accuracy:0.8985091train loss: 0.03515274\n",
            " ********* validation accuracy:0.942 validation loss: 0.022473237\n",
            "EPOCH 86.0\n",
            " train accuracy:0.8984727train loss: 0.035138052\n",
            " ********* validation accuracy:0.942 validation loss: 0.022399014\n",
            "EPOCH 87.0\n",
            " train accuracy:0.89845455train loss: 0.035123948\n",
            " ********* validation accuracy:0.942 validation loss: 0.022325747\n",
            "EPOCH 88.0\n",
            " train accuracy:0.89854544train loss: 0.035110414\n",
            " ********* validation accuracy:0.9422 validation loss: 0.022253418\n",
            "EPOCH 89.0\n",
            " train accuracy:0.8985818train loss: 0.035097435\n",
            " ********* validation accuracy:0.9424 validation loss: 0.022181999\n",
            "EPOCH 90.0\n",
            " train accuracy:0.8988train loss: 0.035084985\n",
            " ********* validation accuracy:0.9424 validation loss: 0.022111464\n",
            "EPOCH 91.0\n",
            " train accuracy:0.89878184train loss: 0.035073064\n",
            " ********* validation accuracy:0.9426 validation loss: 0.022041801\n",
            "EPOCH 92.0\n",
            " train accuracy:0.89896363train loss: 0.03506164\n",
            " ********* validation accuracy:0.9426 validation loss: 0.021972984\n",
            "EPOCH 93.0\n",
            " train accuracy:0.8989818train loss: 0.035050698\n",
            " ********* validation accuracy:0.9426 validation loss: 0.021904988\n",
            "EPOCH 94.0\n",
            " train accuracy:0.89896363train loss: 0.035040222\n",
            " ********* validation accuracy:0.9428 validation loss: 0.021837797\n",
            "EPOCH 95.0\n",
            " train accuracy:0.89901817train loss: 0.035030212\n",
            " ********* validation accuracy:0.943 validation loss: 0.0217714\n",
            "EPOCH 96.0\n",
            " train accuracy:0.89903635train loss: 0.035020646\n",
            " ********* validation accuracy:0.9432 validation loss: 0.021705767\n",
            "EPOCH 97.0\n",
            " train accuracy:0.89901817train loss: 0.035011526\n",
            " ********* validation accuracy:0.943 validation loss: 0.021640886\n",
            "EPOCH 98.0\n",
            " train accuracy:0.8990545train loss: 0.03500281\n",
            " ********* validation accuracy:0.943 validation loss: 0.02157674\n",
            "EPOCH 99.0\n",
            " train accuracy:0.8990909train loss: 0.034994498\n",
            " ********* validation accuracy:0.9434 validation loss: 0.021513311\n",
            "EPOCH 100.0\n",
            " train accuracy:0.899train loss: 0.03498659\n",
            " ********* validation accuracy:0.9434 validation loss: 0.021450587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ksNrxDcFQN59",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "plot the train and validation acurracy and loss against the number of epochs"
      ]
    },
    {
      "metadata": {
        "id": "XwyJ_ytTP9Fp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 361
        },
        "outputId": "4d7d8d1e-54ba-4282-a1c2-3417d2c070ad"
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfwAAAFYCAYAAAC2307rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3Xl8VOXd///XmTXJzGSZMANZ2Awg\nGGQzUDEiLgm24nJrFaJFXGstfLUu3IrBivdPpWKVtqJW7kqtRSq0SpXWW0AqWC0RqggIFoQoEAIk\nGbJOktnP74+QkQjJDEOSmWQ+z8eDR2bmzJm8Ez35nOs617kuRVVVFSGEEEL0appoBxBCCCFE15OC\nL4QQQsQBKfhCCCFEHJCCL4QQQsQBKfhCCCFEHJCCL4QQQsQBXbQDdIWqqoaw3peWlkRNTVMXpzk9\nkik8sZgJYjNXR5lsNks3pzl94RzPPe33Hk2xmEsyhSdUplDHc7e38BcsWMD06dMpKipix44dbbat\nX7+eH/7wh9x44428/vrrYe1zJnQ6bad9VmeRTOGJxUwQm7liMVNni8WfMRYzQWzmkkzhOdNM3drC\n37JlCwcOHGDlypWUlpZSXFzMypUrAQgEAjzxxBP89a9/JTU1lR//+McUFBRw8ODBdvcRQgghRHi6\nteCXlJRQUFAAQE5ODnV1dTidTsxmMzU1NSQnJ2O1WgE4//zz2bRpE2VlZe3uI4QQQojwdGuXvsPh\nIC0tLfjcarVSVVUVfNzY2Mj+/fvxer1s3rwZh8PR4T5CCCGECE9UB+2dOI2/oig8/fTTFBcXY7FY\nyM7ODrlPe9LSksK+1hGLg5YkU3hiMROcOlcgoOL1B9BpNWg1CgB+fwBnsxe314/b46e8ysnRY42o\nKvj8AY4ea6KmwYU/oIIKGo2C3x/A7fXj8wfwB1QURUGrKHj9Aby+AD5fABUVc6KeUUNs3HZVbruZ\neosNn5ezt7yOH08dgaIo0Y4jRMzq1oJvt9txOBzB55WVldhstuDzCRMm8Kc//QmA5557jqysLNxu\nd4f7nEq4IyttNkvYI/q7i2QKT1dlcnv9NB4vwh5vS3FtLdZ1Tg+1TjfVDW6cTR58fhWtRsGUqENz\nvOjq9Tqamj14vAFcHh9NLh8NzV7qGz0thRtQFNBqFHz+yNatUgCdToNGUVBVlYCqotVq0GkU9LqW\nTrvqOhd+v8rU7/XHbk9u93fVG04Evig9xrZ9DmYUDCMpoVfeeCREp+jWoyM/P5/FixdTVFTErl27\nsNvtba7F33nnnSxcuJDExEQ2bNjAbbfdRkZGRof7CHEqrYXQ2eyjzumm2e3D5fHTWmI1ikIgoNLQ\n5KGmwU1FTRMHK50cdrS0sDuL0aDFnKBnUD8LiUYdPn8AX0AlEFAx6DSYEvQY9Fr0Og221AT6WZPQ\najQoCvRJTSTNbESnPd4jEFDRaRV0Wo20ZE9g0Lec5Hh8fpJ6553GQnSKbj06xo0bR25uLkVFRSiK\nwvz581m1ahUWi4XCwkKmTZvG7bffjqIo3HXXXVitVqxW60n7iPjk9QWorG2m3unmP4fqKDtcR63T\nQ3WDC2ezl0CgpcAfq2+m2e0/7c836DUMyUohPTkBg16LUa/FoG/pgtdpNSSbDKSaDVgtCViS9Oh1\nGnwBlcZmL6ra0uq297FQW9uIQdeyr04rc1t1NcPxy3ce7+n/NxcinnT76fCcOXPaPB8+fHjw8ZQp\nU5gyZUrIfUTP5Q8EOFbvxuX24fW3XHP2+gI0NHlpaPbicvtwNnupbfTQ7PLi9au4vX6aXT4cdS4C\nIZrfRr2WPikJmGw6NBoFU6KeFJMBU4KeBIMWRVFQaWlhazQKlkQDqRYD9tRE0lMS0GpOv0AnJxmC\nj21pieDznfZniMgFW/jeQJSTCBHbpP9LnDFVVYMFu8nlpdnto8nto7HZR0OTJ9gKP1bnorKmOXgt\nO1xGvZYEg5azMpPJ7JNEqtlIpt2CFpUUsxGrxUiyyYBGo6CRru5utWDBArZv346iKBQXFzNq1Kjg\nNrfbzWOPPcbevXtZtWpVWPtEwqBvaeG7fdLCF6IjUvBFSF5fgANHG6iqbaahyUNFTTNHjjXhbPbi\n8vg4Vu8Kq3VlStAxoK+FftZETAl6dLqWLm+DToM5SY8lUU+iUYcpQU+K2YApQdfu9epYHEgYbzqa\nSAvgmWeeYcSIEezduzfsfSJh0EkLX4hwSMEXQMttYOVVjTibvVQ3uNj5dTXfHKnH6wvQ6PKeckS5\nTqshwaClX1oSttRELKaWIp1o1JFo0GJKbCniKWYjaRYjiUb536036WgiLYD777+f2tpaVq9eHfY+\nkTDq5Rq+EOGQv8BxJqCqVFQ3sf9IAwcqWlrttU43ZZWN+PxtW0jJSS0t7r7pSWRak+iXbiLZpKdP\nciKZfZJIStBH6acQscDhcJCbmxt83jopVmvxNpvN1NbWntY+kWjt0vf4pIUvREek4PdyqqpyqKqR\nL/dXs+dgLXsP1dLoajuoTKtRyLKZOCszhVSzAXOinrMHpJGZnoSiKNJ9LsISzqRYkewTaiKt9LQk\nAIwJ+pibVyDW8rSKxVySKTxnkkkKfi+jqipllU6+3F/D14fr2FteR53TE9zeJyWBUTnpnJWZwsB+\nFvqmJWJK1MtgN3HaQk2k1Vn7hJpIy+3yAnCsujGmTkxj9UQ5FnNJpvCEyhTqZEAKfi+gqirljkY2\n7TzKJ7uOUntCgU9O0nN+bl9yB1kZMTANa3JCFJOK3iTURFqdtU8orbfluWXQnhAdkoLfQ/kDAfYd\nqmPbPgef73VQWdMMQJJRxwUj+5E72MrQ7JZJZGRWNtEVQk2kde+993L06FG++eYbbr75ZqZNm8ZV\nV13V6RNpfXsNXwbtCdERKfg9SJ3TzZbdlewoPca+8jrcnpY/cEaDlryzbeQNtzN2aB/0YS4cJMSZ\n6mgireeffz6sfc6UMTjTnrTwheiIFPwY1uz2sf9IPV8dqmPnN8f4+nB9cJ73jPQkzh6QxpghfRgx\nMFWKvIhb3860Jy18IToiBT/GqKpK6eE6PvisnH/vrgje/64okJOVwoThdvKG20k1G6OcVIjYIF36\nQoRHCn6McHv9bPlPBR/tOMK+Q3UA9LMmMXZoH3KyUhg+IFXuexfiFGSmPSHCIwU/ysodjXz4eTn/\n2nmUZrcPjQJjh/bh0nHZnDMoTQbcCRFCcC596dIXokNS8KMgEFDZvs/B+5+Wsftgy0xkKSYDl503\niGsvHYoiXZNChM3Yeg1fZtoTokNS8LuRx+tn086jrNlyMHgb3YiBaVwyNosxQ/ug02qwpSXF3GQP\nQsSylgWWZNCeEKFIwe8Gbq+f9/9dxvpPy6hv8qLTKkwalUHh+P5k285s0hEh4p2iKBj1WrmGL0QI\nUvC72I5SB6+v+wpHnYtEo44fnD+Awrz+MspeiE5kNGhllL4QIUjB7yKqqvLOx9+w+l/70WoUfnD+\nAK6cOEiWiBWiC7S08KXgC9ERqT5dIBBQWfrufyjZdZQ+KQnc88NR9LdL170QXcVo0FJT7wv9RiHi\nmBT8TqaqKq+//xUlu46Sk5nMPdePIjnJEO1YQvRqRr106QsRSrcX/AULFrB9+3YURaG4uJhRo0YF\nty1fvpzVq1ej0WgYOXIk8+bNo6KiguLiYjweD4FAgEceeYSRI0d2d+ywqKrK2x99w8bPy+lvN3P/\ntDEkJcg5lRBdzWjQ4fEGUFVV5q4Qoh3dWo22bNnCgQMHWLlyJaWlpRQXF7Ny5UoAnE4nS5cuZd26\ndeh0Om6//Xa2bdvG2rVrKSwspKioiK1bt/KrX/2KpUuXdmfssARUlRXr97L+s0P0SUng/mmjpdgL\n0U2Mxyff8foCwYl4hBBtabrzm5WUlFBQUABATk4OdXV1OJ1OAPR6PXq9nqamJnw+H83NzaSkpJCW\nlkZtbcvkNPX19aSlpXVn5LAtX/cV6z87RFYfE4/MOE9G4QvRjYyG1vn05dY8IdrTrU1Qh8NBbm5u\n8LnVaqWqqgqz2YzRaGT27NkUFBRgNBqZOnUqgwcP5tZbb+X666/n7bffxul08sYbb4T8PmlpSejC\nXD3OZrNE/PO0+teOw2z4vJxBGcksmJWP5Qyv2XdGps4mmcIXi7liMVNnai34bo8fc6KsOSHEqURc\n8O+//35uuOEGLrjggoi/udq61istXfpLlixhzZo1mM1mbrnlFnbv3s0HH3zAD37wA37605+yYcMG\nFi5cyAsvvNDh59bUNIX1/W02yxnPaldd72Lxys8x6DT8+MoRuBrduBrdEX9eZ2TqbJIpfLGYq6NM\nveVEwCgr5gkRUsRd+oWFhaxYsYKpU6fy4osvcvTo0ZD72O12HA5H8HllZSU2mw2A0tJS+vfvj9Vq\nxWAwkJeXx86dO9m6dSuTJk0CID8/n507d0YaudN5fQF++/ZOGl0+igqGkpFuinYkIeJSsEtfZtsT\nol0RF/wrrriC559/nr/85S8MGjSIBx54gB//+Mds2rSp3X3y8/NZu3YtALt27cJut2M2t9yfnpWV\nRWlpKS6XC4CdO3cyaNAgBg4cyPbt2wHYsWMHAwcOjDRyp1JVlWVr91B6uJ7zc/syeXRmtCMJEbeM\nsmKeECGd0TX85uZm1q1bx9tvv00gEOCSSy7hj3/8I5s3b+b+++8/6f3jxo0jNzeXoqIiFEVh/vz5\nrFq1CovFQmFhIXfccQczZ85Eq9UyduxY8vLyGDBgAPPmzWPNmjUAzJs370wid5oPtpbz8RdHGNjP\nwq3fHy63AgkRRd8O2pOCL0R7Ii74jzzyCB9//DEFBQXMnTuX4cOHA3DjjTfywx/+8JQFH2DOnDlt\nnrfuB1BUVERRUVGb7Xa7nd/97neRxuwSew7W8Mb6vSQn6bnnunPlNiAhosyob/lTJl36QrQv4oI/\nbtw45s2bF+yS9/l86HQ6FEXhySef7LSAsaamwc1Lb+9EUWDWtediTU6IdiQh4t631/ClhS9EeyK+\nhm+xWNq01m+66aZgt/s555xz5sli1Kp/ltLQ5GXapUMY1j812nGEEJw4Sl9a+EK0J+KC/4c//IFf\n/vKXwee///3vefXVVzslVKwqq3Sy6YujZNtMXDYuO9pxhBDHBe/Dlxa+EO2KuOCrqorF8u09vGaz\nudcPXPvLhn2owA2XDEGj6d0/qxA9SbCFLwVfiHZFfA1/5MiR3HfffUyYMAFVVfnoo4/azKLX2+za\nX83Ob6o5Z1AaIwdbox1HCHECuQ9fiNAiLviPPvooq1evZseOHSiKwlVXXcUVV1zRmdliRkBV+csH\n+wC44eIhvb4nQ4ieRmbaEyK0iAu+oihcc801XHPNNQB4PB5+9rOf8fzzz3dauFixeVcFByudTMzt\ny8B+vWMqUiF6E2nhCxFaxAX/7bff5umnn6aurg4AjUbD+eef32nBYoXPH2DVP79Gp1W4dtJZ0Y4j\nRExZsGAB27dvR1EUiouLGTVqVHDbpk2bWLRoEVqtlosuuojZs2fT2NjIww8/TF1dHV6vl9mzZwen\nzj4Tcg1fiNAiHrS3bNky/va3v5GXl8dnn33GY489xg9/+MPOzBYTPt/r4Fi9i4tGZ9InNTHacYTo\nEh9++CHvvPMOAA8++CBTpkxh3bp1He6zZcsWDhw4wMqVK3nqqad46qmn2mx/8sknWbx4MW+88Qb/\n+te/2LdvH3/9618ZPHgwy5Yt4ze/+c1J+0QqOEpfbssTol1ndB++zWbD7/eTlJTE9OnTeeuttzoz\nW0zYsPUQAJfKbXiiF3vppZeYNGkSH374IYFAgL/+9a8sW7asw31KSkooKCgAICcnh7q6OpxOJwBl\nZWWkpKSQkZGBRqNh8uTJlJSUkJaWRm1tLQD19fWkpaV1Sn5p4QsRWsRd+lqtlg0bNpCRkcHixYsZ\nMmQI5eXlnZkt6sodjew+WMuIgWlk9pGV8ETvlZCQgNVq5cMPP+Saa67BZDKh0XTcHnA4HG3uzLFa\nrVRVVWE2m6mqqsJqtbbZVlZWxs0338yqVasoLCykvr6eJUuWhMyWlpaETtfx9NV+//GWvaLE1JK/\nsZTlRLGYSzKF50wyRVzwn3nmGSorKykuLubXv/41X375JT//+c8jDhKLWlv3l4zNinISIbqW2+3m\nlVde4aOPPuLhhx9m//79NDQ0nNZnqKoa8j3vvPMOmZmZLF26lN27d1NcXMyqVas63Kempink59ps\nFnRaBWeTh6qq08vdVWw2S8xkOVEs5pJM4QmVKdTJQMQFf+PGjcFr9k888USkHxOzfP4An+yqIMVs\nYOywPtGOI0SXeuKJJ/jzn//ML37xC4xGIx9//PFJC119l91ux+FwBJ9XVlZis9lOua2iogK73c7W\nrVu58MILgZaFsyorK/H7/Wi1Z74AlUGnlS59IToQ8TX8999//7RbAD1JaXkdTW4f44bZ0Ibo2hSi\npxs0aBC33347eXl57N69G7PZzNixYzvcJz8/n7Vr1wKwa9cu7HZ7cDGt7OxsnE4nhw4dwufzsWHD\nBvLz8xk4cCDbt28HoLy8HJPJ1CnFHsCg18hteUJ0IOIWvsvl4tJLL2Xw4MHo9frg68uXL++UYNG2\nbV9L62R0jrTuRe83d+5cCgsL0Wg03HPPPRQWFrJhwwZ+85vftLvPuHHjyM3NpaioCEVRmD9/PqtW\nrcJisVBYWMjjjz/Ogw8+CMAVV1zB4MGDsdvtFBcXM2PGDHw+H48//nin/QwGvRaXR1r4QrQn4oI/\na9aszswRc7bvO4ZRr2XEQFkRT/R+FRUVfP/73+fVV1/lpptu4rbbbuPWW28Nud93u/2HDx8efDx+\n/HhWrlzZZrvJZOrwJOJMWJL0OGpdBFQVjcyGKcRJIu6r9vv9p/zXG1RUN3G0uolzBqWhDzE6WIje\nwOPxoKoq77//PhdffDEATU2hB8vFkhSTkYCq4mz2RjuKEDEp4hb+Sy+9FHzs9XrZt28f48aNY+LE\niZ0SLJq2t3bnD5HufBEfJkyYwHnnncekSZMYPHgwf/jDHxg8eHC0Y52WFJMBgHqnh+QkQ5TTCBF7\nIi74352U49ixYzz33HNnHCgWbC89BsDonPQoJxGie8yZM4e77rqL5ORkAAoKCvjRj34U5VSnp7Xg\n1zV6kGmyhDhZxAX/u9LT0/n6669Dvq+jubeXL1/O6tWr0Wg0jBw5knnz5gGwdOlSVq9ejU6nY/78\n+W326Wxuj5+9h2oZ0NdMitnYZd9HiFhSWVnJr3/9a7744gsURWHMmDHcd999bSbPiXXJ5uMt/EZP\nlJMIEZsiLvj//d//3WaZ2CNHjoScmevEubdLS0spLi4ODupxOp0sXbqUdevWodPpuP3229m2bRsm\nk4l3332Xt956iz179vCPf/yjSwv+nrJafH6VXFnzXsSRxx57jEmTJnHbbbehqiqbNm2iuLiYl19+\nOdrRwnZiC18IcbKIC/4FF1wQfKwoCmazmfz8/A73aW/ubbPZjF6vR6/X09TURFJSEs3NzaSkpPD+\n++/zgx/8AJ1OR25ubpupPLvCl/urAcgdJAVfxI/m5uY2XfjDhg3jgw8+iGKi05ccLPjuKCcRIjZF\nPEp/ypQpGI1Grr32Wv7rv/6LqqoqAoGOJ71wOBxtFstonXsbwGg0Mnv2bAoKCrjkkksYPXo0gwcP\npry8nCNHjnDHHXdwyy23sHv37kgjh2XXN9UYdBqGZqd06fcRIpY0NzdTWVkZfH706FE8np7VUpYW\nvhAdi7iFP3fuXMaPHx987nK5eOihh3jxxRfD/owT5952Op0sWbKENWvWYDabg8VdVVX8fj+vvPIK\nn332GfPmzQu5Kl84i220OnHu4WN1zZQ7Ghk33E5mRvTuv+9tCzZ0lVjMBLGZK1SmWbNmcd1112Gz\n2VBVlerq6k5bura7BAu+Uwq+EKcSccGvra1l5syZwee33XZbyC7AjubeLi0tpX///sFBQnl5eezc\nuZM+ffpw1llnoSgKeXl5Ya3IF85iG3DyQgT/+uIIAEMzk6O2aEJPXLAhGmIxE8Rmro4ytZ4IXHzx\nxaxfv579+/cDMHjwYIzGnjVoVa/TkmTUUd8kBV+IU4m44Hu9XkpLS8nJyQFg586deL0dT3iRn5/P\n4sWLKSoqOmnu7aysLEpLS3G5XCQkJLBz504mT57MkCFDWLFiBVdeeSWlpaVkZGREGjmk3QdrADhH\nrt+LOBFq1ruf/exn3ZSkc6SYDdLCF6IdERf8Rx55hFmzZtHQ0EAgECAtLY2FCxd2uE+oubfvuOMO\nZs6ciVarZezYseTl5QHwz3/+k+nTpwMto4m7SlmFE4NOQ1YfU5d9DyFiSWctXBMrUkwGjhxrwucP\noNPKoldCnCjigj969Gjee+896urqUBQFk8nUZhGd9nQ093ZRURFFRUUn7XPvvfdy7733Rho1LD5/\ngMPHGulvN6PRyDzcIj78v//3/0K+58EHH+wxk2q1jtRvaPKSZulZlySE6GoRnwKvWbOGWbNmkZaW\nRmpqKj/60Y9Ys2ZNZ2brVkerm/D5VbJt5mhHESKmnDh6P9almFqKvNyaJ8TJIi74f/jDH/jlL38Z\nfP773/+eV199tVNCRcOhSicA/e1S8IU4kdKDVp5Lkdn2hGhXxAVfVVUslm9v9TGbzT3qD8N3lUnB\nF6LHa100RwbuCXGyiK/hjxw5kvvuu48JEyagqiofffRRl8+C15VaC362FHwheqzWFr5MviPEySIu\n+I8++iirV69mx44dKIrCVVddxRVXXNGZ2bpVWZWT9GQjpoTQAw+FiCcnTpAV62S2PSHaF3HBVxSF\na665hmuuuQYAj8fDz372M55//vlOC9dd6ps81Dk9shyuEKfQk07kpeAL0b6IC/7bb7/N008/TV1d\nHQAajYbzzz+/04J1p+CAvb7SnS/i09///nd+97vfUV9fj6qqqKqKoihs3LiRG2+8MdrxwmZJMqAo\nUOuUUfpCfFfEBX/ZsmX87W9/44EHHmDJkiX87W9/azOIryc5VNUIILfkibi1ePFinnzySTIzM6Md\n5YxoNAr21ESOHmsKnrQIIVpEPErfYrFgs9nw+/0kJSUxffr0kIvaxCpHbTMAfdOSopxEiOgYOHAg\n48ePJysrq82/niizjwlns5eGpo6n+hYi3kTcwtdqtWzYsIGMjAwWL17MkCFDwlrYJhYdq3cBYE2W\nmblEfBo7diyLFi1iwoQJbabbnThxYhRTRSazj4nP9zo47GgMzrwnhDiDgv/MM89QWVlJcXExv/71\nr/nyyy/5+c9/3pnZuk11gxu9ToM5UUboi/i0adMmAD7//PPga4qi9NiCD1DuaGT4wLQopxEidkRc\n8NPT00lPbxnV/sQTT7TZ1pPm3gaoqXdhtRjlep+IW8uWLYt2hE6Tmd5S8A8fa4xyEiFiS8QFvyM9\nae5tr89PfZOXLBmwJ+LQk08+yaOPPspNN910yhPe5cuXRyHVmclIT0IBjjik4Atxoi4p+D2ppVzd\n0HL7jly/F/Ho+uuvB+C+++47aVtPOo5PZNBrsaUmclgKvhBtxP2C0dX1xwu+JSHKSYTofq3LU0+Y\nMIHc3Fyys7PJzs7GbrezcOHCkPsvWLCA6dOnU1RUxI4dO9ps27RpE9dffz3Tp0/nxRdfDL6+evVq\nrr76aq677jo2btzYqT9Pq8w+JuqbvDQ0yQQ8QrTqkhZ+T1ItI/SF4He/+x1LlizB4/GQlJSE2+3m\nqquu6nCfLVu2cODAAVauXElpaSnFxcWsXLkyuP3JJ59k6dKl9O3blxkzZnD55ZeTnp7Oiy++yFtv\nvUVTUxOLFy/m4osv7vSfJ7OPiW37Wkbqnz1ARuoLAV3Uwu9Jc2+3Fvz0ZGnhi/i1du1aNm3axOjR\no/nkk0949tlnGTp0aIf7lJSUUFBQAEBOTg51dXU4nS2zVpaVlZGSkkJGRgYajYbJkydTUlJCSUkJ\nEydOxGw2Y7fbTxrw21ky+7TMqXH4WFOXfL4QPVGXFPyeNPf2seNd+mlS8EUcM5lMGAwGvN6WyWou\nu+wy/vGPf3S4j8PhIC3t29verFYrVVVVAFRVVWG1Wk/adujQIVwuF3fffTc33XQTJSUlXfDTnHBr\nXpWzSz5fiJ4o4i793jL3dnXD8S59i3Tpi/iVkpLC6tWrGTZsGI888gg5OTmnfbdNuD17tbW1vPDC\nCxw+fJiZM2eyYcOGDgcIpqUlodNp293eymb7dmrvlNQk9DoN+48627ze3aL5vTsSi7kkU3jOJFPE\nBb+3zL1dU+8myagj0Rj3wxlEHFu4cCHHjh2jsLCQ1157jaNHj7Jo0aIO97Hb7TgcjuDzyspKbDbb\nKbdVVFRgt9tJTExk7Nix6HQ6BgwYgMlkorq6Ojinx6nU1ITulrfZLFRVNbR5LSczmT0Ha/nmYHVU\nJtU6VaZYEIu5JFN4QmUKdTIQcZd+pHNvdzSqd/ny5UyfPp0bb7yRp556qs02h8PB+PHj2bx5c6SR\nT+lYvUsG7Im4t2zZMrKzs0lMTOTuu+/m0UcfDY7gb09+fj5r164FYNeuXdjtdszmlvkssrOzcTqd\nHDp0CJ/Px4YNG8jPz+fCCy/kk08+IRAIUFNTQ1NTU5vLAp1p+MA0VGDPwdou+XwhepqIm7WRzL3d\n0ahep9PJ0qVLWbduHTqdjttvv51t27YxZswYoGUq3/79+0ca95Qam724PH6scv1exLmvvvqKAwcO\nMHDgwLD3GTduHLm5uRQVFaEoCvPnz2fVqlVYLBYKCwt5/PHHefDBB4GWcT2DBw8G4PLLL2fatGkA\nPProo2g0XXN38PABacA37D5Yw3ln27rkewjRk0Rc8COZe7u9Ub1msxm9Xo9er6epqYmkpCSam5tJ\nSUkJ7mcymRg2bFikcU+pdZU8Kfgi3u3Zs4crrriC1NRU9Ho9qqricrlC9qjNmTOnzfMTewXGjx/f\n5ja9VkVFRRQVFXVO8A4MzkjGoNOw+2BNl38vIXqCiAt+JHNvOxwOcnNzg89bR+6azWaMRiOzZ8+m\noKAAo9HI1KlTGTx4MB6PhxdffJGXXnqJBQsWRBr3lKpaC74M2BNxzm63s2TJkuDgW1VVue6666Id\n64zodRqGZKfw5f4a6ps8JCdBvGIVAAAgAElEQVTJ/fgivp12we/MubdPHNXrdDpZsmQJa9aswWw2\nc8stt7B7927Wr1/PDTfcQHJyctifG+6o3i8OtJz5Z/ZNjqnRmLGUpZVkCl8s5mov0+rVq3nxxRc5\ncuQIN910U/B1n89HRkZGd8XrMsMHpPHl/hr2HKxl/HB7tOMIEVWnXfDPZO7tjkb1lpaW0r9//+C9\nu3l5eezcuZOPP/6YQCDA8uXLOXjwIDt27OA3v/lNh5OChDOqF6DZ7QfA5/HGzGjMnjgyNBpiMRPE\nZq6OMl199dVMnTqVefPmcc899wRf12g02O09v0CeM8jKqn9+zed7q6Tgi7h32gX/xLm3Gxsbqaur\nA8Dj8TBnzhzefPPNdvfNz89n8eLFFBUVnTSqNysri9LSUlwuFwkJCezcuZPJkyezYsWK4P5z587l\n2muvDTkDWLhcbh8ARn3o3gAheiutVsvTTz8d7RhdYnCGBVtqAp9/5cDt8WM0yLEu4lfE1/AjmXs7\n1KjeO+64g5kzZ6LVahk7dix5eXmRxgtL8/GCnyB/BITolRRF4Xvn9OPvm/bz+d4qzs/tF+1IQkRN\nxAW/de7tO+64g2XLlvGPf/yDw4cPh9yvo1G9oUbvdnYrpNnTWvBl0h0hequJuX35+6b9fPJlhRR8\nEdcivgE2krm3Y43r+DV86eYTovfKSDcxsK+FnV9XUy/L5Yo4FnHB/+7c26+88sppz70dbdKlL0R8\nmJjbl4Cq8q8dR6IdRYioibjgL1y4kHHjxvHII48wcODAsObejjXNMmhPiLhw4agMEgxa1v27DK/P\nH+04QkTFGU28c9dddwFw9913d1qg7uQ6fg1fuvSF6N2SEvRcMjaL9zYf5OMvjnLJ2NDrfgjR20Tc\nwm+de7sna3b7MOq1aELMHyCE6PmmjO+PTqvhvU8O4A8Eoh1HiG4XcQs/0rm3Y4nL7ZPWvRBxIsVs\nZNKoDDZ8Xs6H2w5z6bjsaEcSoltFXPB7w9zbzW6fDNgTIo5cnT+IT748yqoPvyZvuF3m1xdx5bQL\nfm+ae7vZ7ceWoo92DCFEN0kxG/mvSWfxxvq9vLmxlNuvGBHtSEJ0m9Mu+L1l7m1VVXF5pEtfiHhz\n6bgsPt5xhI93HCHvbBujcvpEO5IQ3SKiQXutc29nZWUF/2VkZKDV9pzi6fEGUFWZZU+IeKPVaLhj\n6gh0Wg2v/P0/VNe7oh1JiG4R8Sj9ns7llVn2hIhXA/paKLpsCM5mLy+v3oXXJ6P2Re8XtwXf7ZFZ\n9oSIZ5eMzWLCCDv7DtXxyt+/JKCq0Y4kRJeK2/5sl6elhZ8gs+wJEZcUReGOqSOobXDz792VmJP0\nzCgchiLzcoheKm5b+K0FX7r0hYhfep2We64fRZbNxIat5bz63m4CAWnpi94p7gu+dOkLEd9MCXoe\nunEsA/tZ+HjHEV5Y9UVwnQ0hepO4Lfhub2vBj9urGkKI4yxJBh66cSwjBqaxbZ+DJ//4KUeONUY7\nlhCdKm4LvksG7QkhTpBo1PHA9NEU5GVz5FgT//Pqv9nweTmqDOYTvUQcF/zj1/Bl0J4Q4jitRsNN\nBcOY9V8j0es0LFu7h1++8bm09kWvELcF3y3X8IUQ7cgbbuf/u+N7jBnSh90Ha3ls6Rb+tP4rGpo8\n0Y4mRMTi9gK2XMMXQnQkzWLk3utH8flXVaz4YC/rPz3ExzuOcNl52RSO7y8L74gep9ur3YIFC9i+\nfTuKolBcXMyoUaOC25YvX87q1avRaDSMHDmSefPm4fP5mDdvHgcPHsTv9/PQQw+Rl5d3xjlcbrkt\nTwgR2thhNs7NSWfD1nLe/eQA75YcYN2/y7hgZD8uOy+bbJs52hGFCEu3FvwtW7Zw4MABVq5cSWlp\nKcXFxaxcuRIAp9PJ0qVLWbduHTqdjttvv51t27ZRWlpKYmIib7zxBnv37uWRRx7hzTffPOMsLq8M\n2hPiTHV0Ar9p0yYWLVqEVqvloosuYvbs2cFtLpeLK6+8klmzZvWIZbV1Wg2F4/szeUwm/9x+mHX/\nLuPDbYf5cNthcrKSmTQqk7yz7SQlSI+hiF3d+n9nSUkJBQUFAOTk5FBXV4fT6cRsNqPX69Hr9TQ1\nNZGUlERzczMpKSlcffXVXHnllQBYrVZqa2s7JYtMvCPEmenoBB7gySefZOnSpfTt25cZM2Zw+eWX\nM2TIEAB++9vfkpKSEq3oETPotRTk9efScdl8vtfBh9vK2fVNNaXl9by+7ivOPcvK+OF2RuWkRzuq\nECfp1oLvcDjIzc0NPrdarVRVVWE2mzEajcyePZuCggKMRiNTp05l8ODBbfZ/7bXXgsW/I2lpSeh0\nHRdylZbpM7MzU2NupL7NZol2hJNIpvDFYq6uyNTRCXxZWRkpKSlkZGQAMHnyZEpKShgyZAilpaXs\n27ePiy++uNMzdReNRuG8s22cd7YNR10zn+yqoGTXUT7f6+DzvQ60GoXcs9I5u38KuYOsZNvNaGTK\nXhFlUe1/OvH+VqfTyZIlS1izZg1ms5lbbrmF3bt3M3z4cKDl+v6uXbt4+eWXQ35uTU1TyPfUN7rR\naBTqahpjau5sm81CVVVDtGO0IZnCF4u5Osp0JicCHZ3AV1VVYbVa22wrKysDYOHChfz85z/n7bff\njvh7x5I+KYlcecEgrrxgEOWORrbuqWTbvmPs2Odgxz4Hf6EUc6KeswekMiw7laH9U8i2mdFp4/Ym\nKREl3Vrw7XY7Docj+LyyshKbzQZAaWkp/fv3D/6RyMvLY+fOnQwfPpy//OUvfPDBB7z00kvo9fpO\nyeJy+0k0aGOq2AvRk4UzQc3bb7/NmDFj6N+/f9ifG06PHcRGz4rNZmHMiH4A1DS4+HxPFdu+quSL\nfQ4+21PFZ3uqgJZLA0OyUxjaP40h2SmclZVCls2MtptOAmLhd/Vdkik8Z5KpWwt+fn4+ixcvpqio\niF27dmG32zGbW0a4ZmVlUVpaisvlIiEhgZ07dzJ58mTKyspYsWIFr7/+OkajsdOyuL0+Eo0ywEaI\nSHV0Av/dbRUVFdjtdjZu3EhZWRkbN27k6NGjGAwG+vXrxwUXXNDu9wmnxy5We1bOHZjKuQNTUQuG\nUlXnYm9ZLfvK6ygtr+M/+6v58pvq4Pt1Wg1ZfUxk2Uxk9TGRkW4iIz2J9JSETu0NiNXflWQKLVSm\nUCcD3Vrxxo0bR25uLkVFRSiKwvz581m1ahUWi4XCwkLuuOMOZs6ciVarZezYseTl5bFo0SJqa2u5\n6667gp+zdOlSDIYzuwfW7fGTbO68Ewgh4k1HJ/DZ2dk4nU4OHTpEv3792LBhA88++ywzZswI7r94\n8WKysrI6LPa9haIo2FMTsacmkn9uy7gGt8fPgYoGDlY0cLDCSVmlk3JHIwcq2v5B12oU+qQm0jct\nEVtq678E+qQkkp6cIHcGiLB1+/8pc+bMafO89Ro9QFFREUVFRW22P/DAAzzwwAOdnsPl8WOXFr4Q\nEQt1Av/444/z4IMPAnDFFVecNAg33hkNWob1T2VY/9Tga/5AgKpaF4cdjRw51siRY01UVDdRUdPM\njupT93QkGrVYLQmkJRtJMxtJsxhJtRhJNRlJMRtIMRlINhlkzICIz5n2AgEVjy9AkhR8Ic5IRyfw\n48ePb3Ob3nfdc889XZarp9JqNPSzJtHPmgTY2mxrdHlx1LqorG3GUdeMo9bFsXoX1fUuquvdlDs6\nnu/flKAj2WTAmpJIgl6DJcmAOVGPJVGPOVGPqfVrgg5Top4kow6NRsY49SZxWfFcHplWVwjRs5gS\n9Jj66RnY79TXaV0eHzUNbmoa3NQ5PdQ63dQ6PdQ1uqlv9FDX6KG+0cORY6HHRLRKNGpJMupINOqC\nXxMTjn816Eg0akkw6EgwaI//a3lsNGgx6r/9atBpZIB0DIjLihecR98YW/ffCyFEpBIMOjLSdWSk\nmzp8n9Vq4puyGpxNHhqavDibvThdXhqbWx43unw0uXw0Nntpcvtocnk5Vu/mkDvyFQMVWu5MMOo1\nx79qMeg1GHRaDHotZpMBNRDAoNOg12rR6zUtj3Ua9NqWr7rjj3XaEx8rJ72u0ygtj7UK2uNfNYoi\nJxzEacF3eVqm1ZVR+kKIeKPVakgxtVzbPx0BVcXl9tPs9tHs8dHs9uHy+INfW/75cHtbHrtb/3lP\n/BfA6/NT63Tj9QXw+AJd9FO2pQDa1hMAjYJW0/JYe6rHGgWNRiHBqCfg96PRaIKvaVq3KwoaDcHH\nikZBqxx/j6KgaGh5T/A1vt2mtDxXWj9HaRnUqSh8u10DCi2vKYqCQachd7A15M8ZSlxXvBQZpS+E\nEGHRKApJCbpOvSsgoKp4fQGSU5I4crQOry+A2+vH6w/g9Qbw+VtOCnz+AJ7jz73Hn3v9LV99PhWv\nP4D/+Gt+vxr86vMH8AdO/ur3q/gDLY+9ngD+gC/43O9XCQRUQs8q0b1mfv9sbshMDf3GDsRlwe9n\nTeLeH47ie6OzcDe5ox1HCCHikkZRMOq1JJsMuJMToh2nDWu6mcrK+uMnByoB9fjXQMvJQkBtGQAe\nOL7t268En6vB12nzHvX4viqtX1XU1v2Ob1dbv9LSk5B3tv2Mf6a4LPiKojBmaB+STQaqpOALIYT4\nDm1wLEC0k3QeuTFTCCGEiANS8IUQQog4IAVfCCGEiANS8IUQQog4oKjhrGkphBBCiB5NWvhCCCFE\nHJCCL4QQQsQBKfhCCCFEHJCCL4QQQsQBKfhCCCFEHJCCL4QQQsSBuJxLf8GCBWzfvh1FUSguLmbU\nqFFRy/LMM8/w2Wef4fP5+MlPfsK5557LQw89hN/vx2az8ctf/hKD4fSWsewMLpeLK6+8klmzZjFx\n4sSoZ1q9ejWvvPIKOp2Oe++9l7PPPjvqmRobG3n44Yepq6vD6/Uye/ZsbDYbjz/+OABnn302//M/\n/9MtWb766itmzZrFrbfeyowZMzhy5Mgpfz+rV6/mtddeQ6PRMG3aNG644YZuydeVYuV4lmM5fLF2\nPMfSsQxdeDyrcWbz5s3qXXfdpaqqqu7bt0+dNm1a1LKUlJSod955p6qqqlpdXa1OnjxZnTt3rvp/\n//d/qqqq6nPPPacuX748KtkWLVqkXnfddepbb70V9UzV1dXqlClT1IaGBrWiokJ99NFHo55JVVV1\n2bJl6rPPPquqqqoePXpUvfzyy9UZM2ao27dvV1VVVR944AF148aNXZ6jsbFRnTFjhvroo4+qy5Yt\nU1VVPeXvp7GxUZ0yZYpaX1+vNjc3q1OnTlVramq6PF9XipXjWY7l8MXi8Rwrx7Kqdu3xHHdd+iUl\nJRQUFACQk5NDXV0dTqczKlnGjx/Pb37zGwCSk5Npbm5m8+bNXHbZZQBccskllJSUdHuu0tJS9u3b\nx8UXXwwQ9UwlJSVMnDgRs9mM3W7niSeeiHomgLS0NGprawGor68nNTWV8vLyYAuzu3IZDAZ+97vf\nYbd/u3zmqX4/27dv59xzz8VisZCQkMC4cePYunVrl+frSrFyPMuxHL5YPJ5j5ViGrj2e467gOxwO\n0tLSgs+tVitVVVVRyaLVaklKSgLgzTff5KKLLqK5uTnYlZWenh6VbAsXLmTu3LnB59HOdOjQIVwu\nF3fffTc33XQTJSUlUc8EMHXqVA4fPkxhYSEzZszgoYceIjk5Obi9u3LpdDoSEtquJX6q34/D4cBq\ntQbfE83/9ztLrBzPciyHLxaP51g5lqFrj+e4vIZ/IjUGZhZev349b775Jr///e+ZMmVK8PVoZHv7\n7bcZM2YM/fv3P+X2aP2+amtreeGFFzh8+DAzZ85skyNamd555x0yMzNZunQpu3fvZvbs2Vgslqjn\n+q72csRKvs4U7Z9JjuXwxNrx3FOOZTiz4znuCr7dbsfhcASfV1ZWYrPZopbno48+4uWXX+aVV17B\nYrGQlJSEy+UiISGBioqKNt063WHjxo2UlZWxceNGjh49isFgiHqm9PR0xo4di06nY8CAAZhMJrRa\nbVQzAWzdupULL7wQgOHDh+N2u/H5fMHt0coFnPK/2an+3x8zZkxU8nWWWDqe5VgOTywez7F8LEPn\nHc9x16Wfn5/P2rVrAdi1axd2ux2z2RyVLA0NDTzzzDMsWbKE1NRUAC644IJgvnXr1jFp0qRuzfTr\nX/+at956iz//+c/ccMMNzJo1K+qZLrzwQj755BMCgQA1NTU0NTVFPRPAwIED2b59OwDl5eWYTCZy\ncnL49NNPo5oLTv3/0ejRo/niiy+or6+nsbGRrVu3kpeXF5V8nSVWjmc5lsMXi8dzLB/L0HnHc1yu\nlvfss8/y6aefoigK8+fPZ/jw4VHJsXLlShYvXszgwYODrz399NM8+uijuN1uMjMz+cUvfoFer49K\nvsWLF5OVlcWFF17Iww8/HNVMK1as4M033wTgpz/9Keeee27UMzU2NlJcXMyxY8fw+Xz87Gc/w2az\n8dhjjxEIBBg9ejSPPPJIl+fYuXMnCxcupLy8HJ1OR9++fXn22WeZO3fuSb+fNWvWsHTpUhRFYcaM\nGVx99dVdnq+rxcLxLMfy6Ym14zlWjmXo2uM5Lgu+EEIIEW/irktfCCGEiEdS8IUQQog4IAVfCCGE\niANS8IUQQog4IAVfCCGEiANS8EXUrVq1ijlz5kQ7hhDiDMmxHNuk4AshhBBxIO6m1hWRW7ZsGe+9\n9x5+v5+zzjqLO++8k5/85CdcdNFF7N69G4Bf/epX9O3bl40bN/Liiy+SkJBAYmIiTzzxBH379mX7\n9u0sWLAAvV5PSkoKCxcuBMDpdDJnzhxKS0vJzMzkhRdeoLKyMthacLlcTJ8+neuvvz5qP78QvYUc\ny3GqUxfyFb3W9u3b1ZtvvlkNBAKqqqrqU089pf7xj39Uhw0bpn7xxReqqqrqr371K3XBggVqU1OT\nmp+frx45ckRV1Za1pufOnauqqqoWFhaqe/bsUVVVVV999VX173//u/rWW2+pl112mdrU1KQGAgG1\nsLBQ/eKLL9RXX31Vfeyxx1RVVVWXyxVcG1oIETk5luOXtPBFWDZv3szBgweZOXMmAE1NTVRUVJCa\nmsrIkSMBGDduHK+99hr79+8nPT2dfv36ATBhwgRWrFhBdXU19fX1DBs2DIBbb70VaLnud+6555KY\nmAhA3759aWhoYNKkSfzpT39i7ty5TJ48menTp3fzTy1E7yPHcvySgi/CYjAYuPTSS3nssceCrx06\ndIjrrrsu+FxVVRRFQVGUNvue+LrazkzOWq32pH1ycnJ49913+fe//82aNWt47bXXWLFiRSf+VELE\nHzmW41evnEu/qqohrPelpSVRU9PUxWlOj2QKTyxmgtjM1VEmm81yytdjSTjHc0/7vUdTLOaSTOEJ\nlSnU8RzXo/R1Om3oN3UzyRSeWMwEsZkrFjN1tlj8GWMxE8RmLskUnjPNFNcFXwghhIgXUvCFEBFb\nsGAB06dPp6ioiB07drTZ5na7efjhh9tcGw61jxCi60jBF0JEZMuWLRw4cICVK1fy1FNP8dRTT7XZ\n/swzzzBixIjT2kcI0XVklL4QPYA/EKDO6eFYvYvqejfVDS5qGzwkGrWkWYzotBqa3D6+PlxPRXUT\nKnBWRjI3X352l2UqKSmhoKAAgJycHOrq6nA6nZjNZgDuv/9+amtrWb16ddj7ROKTXUc5UFXKtMln\nnTSqXAjxLSn4QnSxgKpyxNFIVa0r+JqKSmOzj+p6F9UNLmoaPPgDAfx+lVqnm/omL/DtDTRuT4BA\nmDfU6LQatBqFJKOu3VunOoPD4SA3Nzf43Gq1UlVVFSzeZrOZ2tra09onElv+U8m2fQ6uOn8gSQny\nJ02I9sjRIcRpqq534ahrKd5Vtc2UltfR6PIBYLMmYdQqOE8o5hXVzTS5fWF/viVJT3qyEc0JrVWD\nQUt6cgJWixHr8a+pFiNNbh+1DW4Cqopeq2FgPwv9rElRaelGcnIRzj5paUkdjk5ONhsBMCcnkJ6S\neNoZulKs3vYYi7kkU3jOJJMUfCHaUd/oYds+B/sO1XGoyklAVWlo8lLT4A77M3RahfSURMYM7UNW\nH1ObQpyUoMOabCQ9OSHYLa8ooNX0jKE1drsdh8MRfF5ZWYnNZuv0fULdC60GAgAcOVpPwBP+iVVX\ns9ksYc8J0p1iMZdkCk+oTKFOBqTgi16r2e3D4/UTUKGu0U1tg6dNi9Lt81NT727T+lZVaGjyUFnT\nzN5DdcFudJ1Wg06rYNRrGTu0D5l9TCgKJCcZGJKdQpolAVVV0Rn17C+rwZSox2oxYjEZ2rTUe5P8\n/HwWL15MUVERu3btwm63h+yaj2SfUIz6lta/y+M/o88RoreTgi96tLpGD/sO1Qavjze5fRyrc3Gw\nooFyR+MZffbgjGQmjLBzziArWX1MaDShC7fNZsGs7xkt9DM1btw4cnNzKSoqQlEU5s+fz6pVq7BY\nLBQWFnLvvfdy9OhRvvnmG26++WamTZvGVVddddI+Z8poaCn4bq8UfCE6IgVfxDy3109tgxuvP0Ag\noFLX6KF251E2fFrG/qOn7t4y6DUMH5BKsskAQLLJQJrZiPaEoq3XaUizJGBK1KHw7eumRB1WS0Kw\nkIj2tS552mr48OHBx88//3xY+5wpw/EWvkcKvhAdkoIvYoKqqpSW17P5PxWUVzkBaHL5qG5w42z2\nnnIfjaKQOyiNswektVwf1ygk6LVYk1sGtum08dHSjncJemnhCxEOKfii2/mOt9RbHaxwsuKDvXx9\nuL7N+wx6DenJCQzsaybNkoBBr0FBIdls4KzsVAb0ScKSZOju+CLGSJe+EOGRgi+6lM8fYPeBGr48\nUENpeR0VNc3UN3pO+d7zhtm4aEwmIwamodG0dLK3d3tZLI6gFdFhOD5mwi2D9oTokBR80enqGz18\n9lUV+w7V8sXX1cEueY2i0CclgYz+qehPGNhm1GspzOvPsP6p0YosejBjsEs/EOUkQsQ2Kfii07g8\nPjZsLedvm/YHb5FKMRkoOC+bMUP7cFZmMgkG+V9OdC6jXMMXIizy11dERFVVmt0+qmpdfH2knv8c\nqGHHPgceXwBzop5plwxmVE46/dKTeu196CI2yDV8IcIjBV+cFmezlw+3lfPB1vKTZpzrm5bI+bn9\nKMjLxpSgj1JCEW+khS9EeKTgi5M0uVrmgT9a3cS+8jrqmry43T4cdS7Kq5yoQKJRy+icdKzJCQzo\na2ZodioZ6dGZw13Et2DBl0F7QnRICr4AoKK6ifc2H2TPwRoqappP+R69TsPQ/qmMGdKHi0Znyspk\nIiZIC1+I8Mhf7Djn9vp55+NveP/fZfgDKolGLbmD0rClJWFLSeCszGRGj+hH9bFGDHqNTGYjYo4U\nfCHC06UFf8GCBWzfvh1FUSguLmbUqFHBbevXr+e3v/0tBoOBqVOnMmPGDACeeeYZPvvsM3w+Hz/5\nyU+YMmUKc+fOZdeuXaSmtty2dccdd3DxxRd3ZfRez+cPsLeslj+u+4qK6ib6pCRwwyVDOG+Y7aQ5\n4y1JBlyN4a8QJ0R30utbVhn0SJe+EB3qsoK/ZcsWDhw4wMqVKyktLaW4uJiVK1cCEAgEeOKJJ/jr\nX/9KamoqP/7xjykoKGD//v3s3buXlStXUlNTw7XXXsuUKVMAeOCBB7jkkku6Km6v5vH6OVDRwLF6\nF+VVjew7VMc3R+rx+AIowJTx/bnuorOCc5IL0ZNolJZVDOU+fCE61mUFv6SkhIKCAgBycnKoq6vD\n6XRiNpupqakhOTkZq9UKwPnnn8+mTZu45pprgr0AycnJNDc34/fLWXuk9pXXsWHrIbbudbQZ0KQA\nmTYTQ7NTOf+cvjLhjejxEgw66dIXIoQuK/gOh4Pc3Nzgc6vVSlVVFWazGavVSmNjI/v37ycrK4vN\nmzczYcIEtFotSUlJALz55ptcdNFFaLUtrc7XX3+dV199lfT0dH7+858HTxbEyQ5WNLD8/a/Ye6gO\ngD4pCVw0KpO+1kTsaYmclZFMktw2J3oRo0ErBV+IELpt0J6qfrtYiqIoPP300xQXF2OxWMjOzm7z\n3vXr1/Pmm2/y+9//HoBrrrmG1NRURowYwf/+7//ywgsv8Nhjj7X7vdLSktDpwuuettksEfw0XSvS\nTHVON++V7Gfl+3vw+VXyRvTl2otzODenzxnfLtebfk9dLRZzxWKmzpRg0NLQzhoNQogWXVbw7XY7\nDocj+LyyshKbzRZ8PmHCBP70pz8B8Nxzz5GVlQXARx99xMsvv8wrr7yCxdLyR2rixInB/S699FIe\nf/zxDr93TU1TWBljcQGWSDKVOxpZ9WEp2/cdI6CqpJgN3PaDEYzKSQfA4XB2e6auFouZIDZzdZSp\nt5wIJBilS1+IULrsHqv8/HzWrl0LwK5du7Db7ZjN5uD2O++8k2PHjtHU1MSGDRuYOHEiDQ0NPPPM\nMyxZsiQ4Ih/gnnvuoaysDIDNmzczdOjQrordY9Q3eti4rZwlq3cxf+kWPt/roL/dzLRLhvDknd8L\nFnsh4kGCQYs/oOLzy8A9IdrTZS38cePGkZubS1FREYqiMH/+fFatWoXFYqGwsJBp06Zx++23oygK\nd911F1arNTg6/7777gt+zsKFC/nRj37EfffdR2JiIklJSfziF7/oqtg9Qlmlk0Urt1F3vAuzb1oi\n0y8byuicdJnpTsSl1kWZPF6/zBUhRDu69Br+nDlz2jwfPnx48PGUKVOCt9y1mj59OtOnTz/pczIz\nM3nrrbe6JmQP0uTy8dlXlaz4xz6a3T6uzh/E+OF2MvqYZIEaEddaF9BxefwyIFWIdshMez3E+k/L\n+POGUnz+AFqNwo+vOoeJuf2iHUuImNDawpfr+EK0Twp+DAqoKvWNHmoa3PgDKtv2Ovi/Tw6QbDJw\n2XnZfO+cvthTE6MdU4iYkWBsaeF7ZPIdIdolBT+GBAIq75Xs5/X/+5L6Jm+bbfbURB4sGoNNCr0Q\nJ5EWvhChScGPEf85UMO5cAgAACAASURBVMMb6/dyqMqJUa/lvLNtWC0J6HUajHoNF43JIsVkiHZM\nIWJSgkEW0BEiFCn4UdTs9vHp7ko++bKC/xyoQQEuG9+fqd8bQKrZGO14QoTU0QJZmzZtYtGiRWi1\nWi666CJmz55NY2MjDz/8MHV1dXi9XmbPns2kSZPOOEfroD23LKAjRLuk4Hcznz/AwQonn+6p5MNt\n5TS7W/5ADR+QyrRLhzD+3KyYm7hFiFPpaIEsgCeffJKlS5fSt29fZsyYweWXX84nn3zC4MGDefDB\nB6moqOCWW25hzZo1Z5xFuvSFCC1kwS8tLSUnJ6c7svRqFTVNrN1SRsnOo8E/SskmA5dPGMDE3H5y\nbV70OB0tkFVWVkZKSgoZGRkATJ48mZKSEqxWK3v27AGgvr6etLS0TsmSKAVfiJBCFvx7772X5ORk\nrr/+eq644goSE6Uwna6Pth/mtTV7CKgq6ckJTBzZj2H9UzhvmA19mHP+CxFrOlogq6qqqs0CV1ar\nlbKyMm6++WZWrVpFYWEh9fX1LFmyJOT3CWdtjG+qGgHQG3QxNV1wLGU5USzmkkzhOZNMIQv+u+++\ny1dffcV7773HzTffzIgRI7jhhhvaXKsT7XvvkwP8ZWMp5kQ9PyocRt5wG1qNzAQmep8TF8hqzzvv\nvENmZiZLly5l9+7dFBcXs2rVqg73CWdtjNZBe8dqmmLmklgsrqsAsZlLMoUnVKZQJwNhXcMfNmwY\nw4YNIz8/n0WLFjFr1iwGDhzIU089xaBBg04rcDx5t2Q/b334NWkWIw9OH0NmH1O0IwnRaTpaIOu7\n2yoqKrDb7WzdupULL7wQaJl5s7KyEr/fH1wGO1LfTq0r9+EL0Z6QTc3y8nJeeOEFvv/97/OHP/yB\nu+++m48++oiHH36Y//7v/+6OjD3S2i0HeevDr0lPNvLIj8ZJsRe9TkcLZGVnZ+N0Ojl06BA+n48N\nGzaQn5/PwIED2b59O9Dyt8VkMp1xsYcTptaVa/hCtCtkC//mm2/m+uuv57XXXqNv377B10eNGiXd\n+qegqirvfPwNq/+1n1SzgTk3jqWPDMgTvVCoBbIef/xxHvz/27vz+Kaq/P/jr+xtmm4pXWjZCsi+\ni4zsqCx+wcHli8JgARWdURj9OoNDsS6ALKIyOgzugrj8EOoAKjOjgM4AilQWkUJRBKpAC5TuS5qk\nbZr7+6M0UG2bAG2TNp/n49FHm9zm5p22p5/cc889Z84cAMaPH098fDxRUVEkJSWRkJCAw+Fwu9S1\np1yD9uSyPCHq5Lbgb968mS+//NJV7NetW8fEiRMJCgriqaeeavSAzc0/tqezZe9pWoUGMGdKP6LD\njd6OJESjqW+BrOuuu67GZXoAQUFBrFixosFzVB/hl8sRvhB1ctul//jjj9c4F2e325k7d26jhmqu\n9h/NZsve07SOMJI07Vop9kI0kQCDXJYnhDtuC35hYSHTp0933b733nspLi5u1FDNUV6RnXc+O4pe\np+aPd/SWmfKEaEJ6rRoVUvCFqI/bgl9RUUF6errrdlpaGhUVFfU8wv+cyyvlr8kHsZY5mDq6C60j\nZICeEE1JpVKh12vkHL4Q9XB7Dv/xxx9n1qxZlJSUUFlZidls5vnnn2+KbM3Cj6cL+PvGQ9jKKvmf\n37RjeJ/W3o4khF8y6DRyhC9EPdwW/L59+7J161YKCgpQqVSEhYVx4MCBpsjm80rtFby++QjlFU5+\n/9seXN8zxtuRhPBbAToNdjnCF6JObgu+xWLhk08+oaCgAKjq4t+4cSO7du1yu/P6VtL64osveO21\n19Dr9UyYMIGEhIQ6H3Pu3Dnmzp1LZWUlkZGRvPDCC+j13l8qdt0XxymylHPHiI5S7IXwspAgPT+d\nLcbpVFCrVd6OI4TPcXsO/9FHH+XHH39k06ZNlJaWsn37do+unb10Ja0lS5awZMkS1zan08miRYt4\n6623WLt2Ldu3bycrK6vOx/z9739n6tSpfPDBB7Rv354NGzZc+StuIN8dy2F3WhYdYoL5n+vbeTuO\nEFeloqKCrKwsAI4ePcrHH3+MzWbzcqrLExZswKkolFjLvR1FCJ/ktuCXlZXxzDPPEBcXR2JiIu+9\n9x6fffaZ2x3XtZIWQEFBASEhIZjNZtRqNddffz27d++u8zF79uzhpptuAuCGG24gJSXlil9wQ8gv\ntvP2pz+g06qZeUsPmRtfNHvz5s3j4MGDnD9/nocffphjx44xb948b8e6LGGmql6/AkuZl5MI4Zvc\ndulXVFRgtVpxOp0UFBQQHh5ORkaG2x3Xt5KW2WymtLSUkydPEhcXx549exg0aFCdj7HZbK4u/IiI\nCHJycup9bk9W16p2uSsPVToVXvxHKqV2B7P+tw/9ujd8V35LW6GpsfhiJvDNXO4ynT9/nptvvpk1\na9YwdepU7r33Xu65556mCddAwoOrLoUtLCkHOcMmxK+4Lfi33norH374IXfeeSfjx4/HbDbTvn37\ny36iS1fSUqlULFu2jKSkJIKDg2nTpo3bx9R33y95sroWXNlqSNv2ZZCWnseALpFc2zmiwVdTao4r\nNHmDL2YC38xVX6bqNwLl5eUoisLnn3/uOpVmtXrWjnxF9dwXcoQvRO3cFvzqebIBBg8eTF5eHt27\nd3e74/pW0gIYNGgQH3zwAQB//etfiYuLo6ysrNbHGI1G7HY7AQEBrlW3vCG/2M5HX/5EUICW6Td3\ndf1chGjuBg0axLXXXsvw4cOJj4/nnXfeIT4+3tuxLkt1wS8skYIvRG3cnny+dJa96OhoevTo4VGh\nq28lLYD777+fvLw8rFYr27dvZ/DgwXU+ZsiQIa77t23bxvDhwy/vVTaQtZ8fo6yikrtu6EyI0ftX\nCQjRUB577DF27Njhmud+9OjRLF682MupLk91l74c4QtRO7dH+N27d2fFihX0798fnU7nun/w4MH1\nPs7dSlp33XUX9913HyqVit///veYzWbMZvOvHgPw8MMPk5iYSHJyMrGxsdx2221X+bIv33fHc/ju\neC5d2oYxTCbXES3Mzp07KSws5NZbb2XOnDkcPnyYxx57jLFjx3o7mseqB+0VSsEXolZuC/4PP/wA\nwP79+133qVQqtwUf6l9Ja+zYsbX+M/nlY6Dq9MCaNWvcPl9jsZc7WPv5MTRqFdPHSVe+aHleffVV\nXnvtNXbu3InT6eSjjz7iwQcfbFYFP0CvJdCgkS59IergtuC///77TZHDp3381c/kF5dxy5D2xLaS\nefJFyxMQEIDZbGbnzp3ceuutBAUFoW6Gl5uGmQwUWuQ6fCFq47bgT506tdYj2rVr1zZKIF+TW2Tj\ni/2ZRIUFcsvgDt6OI0SjKCsrY9WqVXz55ZckJiZy8uRJSkp862oDT4SZDJzLs1LhqETn4aW5QvgL\ntwX/0UcfdX1dUVHBN998g9HoP+u8b9uXgVNRmDisA3qd/AMRLdOiRYv48MMPWbZsGQaDgV27dtV6\nes3XuUbqW8qJDAv0chohfIvbgj9o0KAat4cOHcoDDzzQaIF8icVWwZepZzGHGBjUPdrbcYRoNNdc\ncw0zZszg+++/5/PPP+fGG28kNjbW27Eum2ukfkmZFHwhfsFtwf/lrHrnzp3j559/brRAvmT7d2co\nr3AyZnhbtJrmdz5TCE+tW7eOt956i969e6MoCsuWLeOPf/wjt99+u7ejXRYZqS9E3dwW/BkzZri+\nVqlUmEwm/vjHPzZqKF/gVBS2H8gk0KBlRN/md6QjxOX45JNP+OyzzzAYqo6QrVYr9957b7Mr+Ben\n15WCL8QvuS34//3vf3E6na4RuxUVFTWux2+pTmWVUGgpZ2ivGAINbn9MQjRrWq3WVewBjEZjs2zn\nl57DF0LU5LafeuvWrcyaNct1++6772bLli2NGsoXHDxeNcVv386tvJxEiMYXExPDokWL+M9//sN/\n/vMfFi5cSOvWzW+CKZltT4i6uS34a9as4YUXXnDdfvvtt706CU5TST2Ri1ajome82dtRhGh0ixYt\nIjo6mk2bNvHRRx8RGxvLokWL3D5u6dKlTJ48mSlTpnDo0KEa23bv3s2kSZOYPHkyr7zyiuv+zZs3\nM3HiRO644w527NjRoK8jJEiPiqp1L4QQNbntq1YUheDgi0trmkymFj/TXH6xndPZFnrGm6U7X7Ro\nTqcTAIPBwP33339Zj927dy+nTp0iOTmZ9PR0kpKSSE5Odm1fvHgxq1evJjo6moSEBMaNG0dERASv\nvPIKGzduxGq1snLlSkaNGtVgr0erURMVHsjZ3FIURWnx/6uEuBxuq1mvXr149NFHGTRoEIqi8NVX\nX9GrV6+myOY1qSequvP7SXe+aOHqWgyrulhWT61dm5SUFEaPHg1Ap06dKCoqwmKxYDKZyMjIIDQ0\n1HVaYOTIkaSkpBAREcHgwYMxmUyYTCaPehEuV5soE9/+mENBSRnmkIAG378QzZXbgv/kk0+yefNm\nDh06hEqlYuLEidx8881Nkc1rUtPzAOjbOcLLSYRoXEePHnX7Pbt27WLYsGG/uj83N5eePXu6bpvN\nZnJycjCZTOTk5GA2m2tsy8jIwGazYbfbefDBBykuLubhhx92uy5HeLgRrQez5kVGVvVEdu0Qwbc/\n5lBS7qRrZLCbRzWuSC8/f118MZdk8szVZHJb8G02Gzqdjqeeegqoul7XZrMRFNQy55Qvq6jkh1MF\nxLUKolWoTNwhxJtvvllrwf8lRVE82l9hYSEvv/wyZ8+eZfr06Wzfvr3erveCAqvbfUZGBpOTUzUV\ncERQ1dUFacezad/Ke7OCXprJl/hiLsnkGXeZ3L0ZcDtoLzExkdzcXNdtu93O3LlzLyNi8/Lj6QIq\nHE76dJKjeyGg7kIeFRVV439DdnY2kZGRtW47f/48UVFRRERE0L9/f7RaLe3atSMoKIj8/PwGzdsm\nygRARralQfcrRHPntuAXFhYyffp01+17772X4uLiRg3lTdXd+VLwhahS19H30KFD2bp1KwBHjhwh\nKioKk6mq2LZp0waLxUJmZiYOh4Pt27czdOhQhg0bxjfffIPT6aSgoACr1Up4eHiD5o0IDSBAryEz\np7RB9ytEc+e2S7+iooL09HQ6deoEQFpaGhUVFY0ezBsUReFweh6BBi2d4kK9HUcInzZgwAB69uzJ\nlClTUKlUzJ8/n02bNhEcHMyYMWNYsGABc+bMAWD8+PHEx8cDMG7cOO666y6gaoxQQy/Dq1apaBNl\n4qczxbJqnhCXcFvwH3/8cWbNmkVJSQmVlZWYzWaef/75psjW5M7lWcktsjOwW5TMnS+EB365ol63\nbt1cX1933XU1LtOrNmXKFKZMmdKoudpGmjiRWcTZXCvtY3xv4JUQ3uC24Pft25etW7dSUFCASqUi\nLCyMAwcONEW2Jneouju/o3TnC1HN08F4vqT6PP7p7BIp+EJc4LbgWywWPvnkEwoKCoCqLv6NGzey\na9cutztfunQpqampqFQqkpKS6NOnj2vb2rVr2bx5M2q1ml69evHEE0/w2muvsXv3bqBqQpDc3Fy2\nbt3KjTfeSExMDBpNVdfc8uXLiY5u+OVqj2cWAsjsesJvbNiwod7tkyZNYtWqVU2UpuG0lYF7QvyK\n24L/6KOPEhsby65duxg3bhxff/01CxYscLvj+mbhslgsrF69mm3btqHVarnvvvs4ePAgDz30EA89\n9BAAH330EXl5ea79vfXWW41+KWBGtoVgo861xKYQLd23335b7/ZJkybVWFSnuWgbZUKrUXEso9Db\nUYTwGW4LfllZGc888wzTpk0jMTGRwsJCFi1a5Jphqy71zcKl0+nQ6XRYrVaMRiM2m43Q0IuD5BwO\nB+vWreO99967ypfnOVuZg9wiOz06hMt0nMJvPPvss3Vua8r219AMOg3XtAnjh1MFFJeWExIkb+KF\n8GiUvtVqdV1GEx4eTkZGhtsd1zcLl8FgYPbs2YwePRqDwcCECRNcI3gBtm3bxrBhwwgIuDgt5vz5\n8zlz5gzXXnstc+bMqbcoezozF1ycqOD7n6t6E7q0N3t9diVvP39tJJPnfDGXu0w//PADr7/+uuvU\nXXl5OVlZWTUuyW1uesWb+eFUAd+fzOf6njHejiOE17kt+Lfeeisffvghd955J+PHj8dsNtO+ffvL\nfqJLB/5YLBbeeOMNtmzZgslkYsaMGRw9etQ1wnfjxo0sXLjQ9f2PPPIIw4cPJzQ0lNmzZ7N169Z6\np/f1ZGYuqDlr0eFj2QBEmPRenV2pOc7u5A2+mAl8M1d9marfCCxcuJBp06bx5ptv8qc//YktW7bw\n5z//uSljNrie8Wb+sSOdIz9LwRcCPCj4v/vd71xfDx48mLy8PLp37w7UPcc21D8LV3p6Om3btnXN\ntT1w4EDS0tLo1q0bVquVrKws2rRp43rsbbfd5vp6xIgRHDt2rMHn88+8MLinerCPEP4kICCACRMm\nsG7dOkaNGsXw4cOZNWsWgwYN8na0K9YmykSIUUfayXxZOU8IPJhp71LR0dE1Vtd688036/ze+mbh\niouLIz09Hbu9as3qtLQ0OnToAFQt5tGxY0fXfkpKSpg5cybl5eUA7Nu3j2uuueZyYnskI8eCRq2i\ndUTLXCNAiPqUlZVx7NgxDAYDe/fupaioiDNnzng71lVRq1T0iDdTZCnnTK7MuifEVS32Xt/1ue5m\n4Zo5cybTp09Ho9HQv39/Bg4cCPCrVbaCg4MZMWIEkydPxmAw0KNHjwY/uncqCpnZpcREGNFpZcId\n4X+GDx/OqVOneOSRR5g7dy55eXk88MAD3o511Xp2MPPNkfMcTs+jTaT03gn/dlUF310XWX2zcNU1\n29a4ceMYN25cjftmzJjBjBkzriJp/XILbZRVVEp3vvBb+/btIzk5mZtvvpmXXnqJHj16eDtSg+jb\nuRUatYrdaVnc/Jt20q0v/JocznJxco62cgQg/NSaNWv46KOPaN++Pc8++ywTJ06s95Rdc2EK1NHv\nmlacyS3lZJZvDaYUoqlJwQfX+b04KfjCj5nNZqZOncpf/vIX+vXrxxtvvOHtSA1iWO/WAOw6dM7L\nSYTwrqsq+M1xju3a5BZVDR6MDAtw851CtEwHDx5k2bJljB07lhUrVjBgwAB27tzp7VgNoldHM6Em\nPXu+P0+Fo9LbcYTwmjrP4bfUObZrk3eh4EeESMEX/mnx4sVMnDiRDz74gFatWnk7ToPSqNUM6RnD\nZ3tOs/eHbIZeOOIXwt/UWfBb6hzbtckrshMSpEevk3WzhX9y9wa/ubthQBzb9mXw75RTDO4Zg1ot\ng/eE/6mz4LfUObZ/yako5BXbZQlNIVqwVqGBDO0dw5ep59h79DzX95CZ94T/cXtZXkucY/tSRZZy\nKp2KdOcL0cKNH9yBXYey+OfXJxnULVqO8oXfcTtob+HChYwdO5aioiLuu+8+OnTowPPPP98U2ZpE\n9fn7VqFS8IVoyaLCAhnSK4ZzeVa+OnTW23GEaHJuC371HNvBwcGMGjWKJUuWsHr16qbI1iRyi2wA\nREjBF6LFu31ERwL0GjbsSKe4tNzbcYRoUm4LfkucY/tSecVyhC+EvwgPNnDHiI6U2h0k//eEt+MI\n0aTcFvxL59h+6qmnGDt2LL/97W+bIluTyJVL8oTwKzcOaEP7mGBSjmSx/2i2t+MI0WTcDtprqXNs\nV3Ndgy9H+EL4BbVaxf239GDRu/tY89kPtIs2ERVu9HYsIRqd2yP8ljrHdrXcIjumQB0B+qtaR0gI\nv7R06VImT57MlClTOHToUI1tu3fvZtKkSUyePJlXXnmlxja73c7o0aPZtGlTU8Z1iWsVxLSxXbGV\nVfLqR2nYyx1eySFEU/Joat2WOse2cuEafOnOF+Ly7d27l1OnTpGcnMySJUtYsmRJje2LFy9m5cqV\nrFu3jq+//poTJy6eM3/ttdcIDQ1t6sg1DO3dmpH9YjmdbeHVj9NwVDq9mkeIxua24LfkObYLLWVU\nOJwyYE+IK5CSksLo0aMB6NSpE0VFRVgsVStPZmRkEBoaSuvWrVGr1YwcOZKUlBQA0tPTOXHiBKNG\njfJWdJe7x3ShT6cI0n7KZ82nP+B0toz1QYSojduCv3jxYmJjY/nggw9YvXo1t912GyZTy1hVLqdA\nLskT4krl5uYSHh7uum02m8nJyQEgJycHs9lc67bnnnuOefPmNW3YOmg1ah66tRedYkNIOXKeN/95\nRI70RYvl9sR1S55j21XwpUtfiKvmyeqZH3/8Mf369aNt27Ye7zc83IhW636di8jIK58ee+nsYSxc\n9Q17f8jGocDchIEEBequeH8Nkakx+WIuyeSZq8nUqCPVli5dSmpqKiqViqSkJPr06ePatnbtWjZv\n3oxaraZXr1488cQTbNq0iRUrVtCuXTsAhgwZwkMPPcTRo0dZsGABAF27dmXhwoUNkq/YWjXxRrDx\n6hu2EP4mKiqK3Nxc1+3s7GwiIyNr3Xb+/HmioqLYsWMHGRkZ7Nixg6ysLPR6PTExMQwZMqTO5yko\nsLrNEhkZTE5OyVW8Gnj49t688vFhDhzN5s9/28kj/9v7qkbvN0SmxuCLuSSTZ9xlcvdmoNEK/qUD\netLT00lKSiI5ORkAi8XC6tWr2bZtG1qtlvvuu4+DBw8CMH78eBITE2vsa8mSJa43DHPmzGHnzp2M\nHDnyqjNaLhR8Y4AUfCEu19ChQ1m5ciVTpkzhyJEjREVFuU73tWnTBovFQmZmJjExMWzfvp3ly5eT\nkJDgevzKlSuJi4urt9g3JYNew/9N6kPyf07wxbeZLHxnHzNu7sag7tHejiZEg2i0gl/XgB6TyYRO\np0On02G1WjEajdhstjpH7JaXl3PmzBlX78ANN9xASkpKgxT8UlsFAEEBckmeEJdrwIAB9OzZkylT\npqBSqZg/fz6bNm0iODiYMWPGsGDBAubMmQNUvZGPj4/3cmL3NGo1U8d0oX1MMP9v2zFe/+QIh9Lz\n+N3oawiSAwPRzDVapcvNzaVnz56u29WDdkwmEwaDgdmzZzN69GgMBgMTJkwgPj6e7777jr179zJz\n5kwcDgeJiYlEREQQEhLi2k9ERIRr8M/Vslwo+EYp+EJckccee6zG7W7durm+vu6661y9erV5+OGH\nGy3X1RrauzUdY0N485/fszstiyM/5zP5ps78pns0KpWssieapyardJcO6LFYLLzxxhts2bIFk8nE\njBkzOHr0KH379sVsNjNq1Ci+++47EhMTWbVqVZ37qYung3ws1qqC3y4unLBgw2W+osbT0gaKNBZf\nzAS+mcsXM/m61hFBPDn9WrbsOc3mr0/y5ubv2fHdWSbf2Jn41iHudyCEj2m0gl/fgJ709HTatm3r\numxn4MCBpKWlMWnSJDp16gRA//79yc/PJzw8nMLCQtd+qgf/1MeTQT4AFlvVOXxbqZ0Ku2+snNUc\nB4p4gy9mAt/MVV8meSNQP41azYTBHbiuezTrvzjOwRO5LHp3PwO7RTFxaAfaRLaMS5SFf/Bopr0r\nMXToULZu3QrwqwE9cXFxpKenY7dXzWOflpZGhw4deOutt/jXv/4FwLFjxzCbzej1ejp27Mj+/fsB\n2LZtG8OHD2+QjBZbBQadBq2m0X4MQogWICoskEcm9eEvv+tPfOtg9h/N5unVe3ll02HSzxR5O54Q\nHmm0I3x3A3pmzpzJ9OnT0Wg09O/fn4EDB9KmTRv+8pe/sH79ehwOh2uqzqSkJJ5++mmcTid9+/Zt\nsFG9FmuFnL8XQnise/twnpw+kNT0PP759c98eyyHb4/l0CkuhJsGtOHarlHotHIAIXyTSvHkpHgz\n42mX6sMrviLcpOeZmb9p5ESea25dwt7ii5nAN3M19y59T36e3vi5K4rC0dOFbN17msPpeSiAKVDH\nkF4xDO3dmgE9W/vc3wI0v79Rb2mOmbx2Hb6vczoVSm0VxLUK8nYUIUQzpFKp6N4+nO7tw8kusLLj\nu7N8nXaObfsy2LYvgw6tQ7i2SysGdY8mMizQ23GF8N+Cby2rWg5TrsEXQlytqHAjd93YmTtGdiT1\nRC6707I4/FMeJ88Vs3HnT7SLNjGgSyT9OreibZRJLu0TXuG31c5ql2vwhRANS6tRc23XKK7tGkVg\nkIFtu39m34/Z/HCygNPnLXz81c+YQwz07hhBr/gIurcPk5k+RZPx22pXaq8+wpfGJoRoeCajnuF9\nYxneNxarvYJDP+WReiKPtJ/y2HnwLDsPnkWlgg4xIXRvH063dmF0bhNKgN5v/y2LRua3f1nWCwVf\njvCFEI3NGKDj+h4xXN8jBqdT4adzxRz5OZ8jJ/P5+WwxP58r5tNvTqFWqWgXbaJzm1A6x4XSKTYU\nc4hBTgGIBuG31a7UXj2PvhzhCyGajlqtonNcVUG/dVg89nIHxzOL+PF0IccyCvn5XDEns0r4Yn8m\nAKFBejrGhtAhJpgOrUNoHx1MSJDey69CNEd+W/DlCF8I4QsC9Fp6d4ygd8cIAMorKjmZVUL6mSLS\nLxz9f3c8l++OX5y5NDzYQNsoU42PqPBANGqZA0DUzW+r3cUjfL/9EQghfJBep6FL2zC6tA1z3VdQ\nUsbJrGJOZZVwMquE0+dLOJSex6H0PNf3aDVqYiOMxEYGERsRROuIIGJbGYkMC5TZRAXgxwX/4hG+\ndOkLIXxbeLCB8OBI+l8T6bqvuLScjBwLmdkWMnMsZOaUci63lNPZlhqP1ahVRIYFEmM2EhNhpHO7\ncIxaNdFmI6EmPWoZH+A3/LbgXxyl77c/AiFEMxYSpKdnkJmeHcyu+5xOhdwiG2dySzmXZ+VcbilZ\n+VbXByeAPadd36/XqmkVFkhUWCCRYYG0CgsgMjSQyLAAIkID5IqBFsZvf5sXr8OXI3whRMugVquI\nCjcSFW6k/zUX71cUhRJbBVl5VmwOhROn88kusFV9FNo4m1ta6/5MgToiQgNoFVL1BsAcEkBEiAFz\nSADmYAPBQdJDbQ5OVQAAD5BJREFU0Jz4bcGXI3whhL9QqVSEGPWEGPVERgbTNz7ctU1RFCy2CnKL\n7OQU2sgptJFXZCenyE5ukZ2zuaWcyqp9/naNWnXhdMMlHyYDYRe+DjUZCAvSo9dpmuqlinr4bbWz\n2h0Y9LI0rhDCv6lUKoKNeoKNeuJbh/xqu6IoFFsryCuyk19sJ6/YTn5xGfkldgpKysgvtnPiTBH1\nLcMWFKAl1GQgNEhPmElPqMlAiFFPqElPaJCeDg6FyvIKggJ10mPQiPy24JfaKzAFSne+EELUR6VS\nERqkd80HUBtHpZPi0nIKSsootJRd+Fx1u6i06usiS1mdpw6qqVUqgo06QoL0hBh1BAdV9UoEG3UX\n3pRc8jlQT6BBI5MSXQa/LfhWu4PIcFnBSgghrpZWo646rx8SUO/3VTgqKSotp8hSTnFpOYWlVZ/L\nnQrnc0spvnA7p9BGxi+uNqiNRq3CZNQRHKjDdOmHUYcpQEfQL+4PCtRhNGhRq/3zTYJfFnynomAr\nc2AyymxVQgjRVHRaDa1CA2kVWvNgq7Z13ssrKimxVlBsLafEWk6JteLCR9XXFtuFr20V5BWXkZlT\nf+9BNRVVE64FBegICqz6fOlto0FHUICW1tHBOMocrm3GAC0B+ubdo+CXBd9W5kAB6dIXQggfpddp\niAjVEBFaf69BNUelk1Jb1RuBqg8HFls5pXaH677S6o8L9+WXlOGodHqcSaUCo0GLMaDqjYExQEug\nQeu6L9BQ/aGp2m7QEHBhe/U2ndZ748b8suC7RuhLwRfiqixdupTU1FRUKhVJSUn06dPHtW337t28\n+OKLaDQaRowYwezZswF4/vnn+fbbb3E4HPzhD39g7Nix3oovWhCtRl01MNBkuKzHlVVUYrU7KLVX\nVH2+8IZApdWQnWupuq+sApvdQWmZA1uZA6vdQVa+lbKKyivIqaoq/vqLbw4C9Bc+X7g/QK8h0FD1\nOUCvJdioo3Nc6GU/16+e+6r3UI/6/hmsXbuWzZs3o1ar6dWrF0888QQOh4MnnniC06dPU1lZydy5\ncxk4cCDTpk3DarViNBoBSExMpFevXlecy+GoekcXdpl/GEKIi/bu3cupU6dITk4mPT2dpKQkkpOT\nXdsXL17M6tWriY6OJiEhgXHjxpGbm8vx48dJTk6moKCA22+/XQq+8CqDToNBpyE8uGY9qO00wy85\nKp3YyysptVe43gjYyhxYyxzYyiqxlV1624G9zIG1rBJ7edV9RaXlHr9pmHFzVyaNqX3QpKcareDX\n98/AYrGwevVqtm3bhlar5b777uPgwYOkp6cTGBjIunXrOH78OI8//jgbNmwA4Nlnn6VLly4Nki0m\nwsi947sxcmA7nOWOBtmnEP4mJSWF0aNHA9CpUyeKioqwWCyYTCYyMjIIDQ2ldevWAIwcOZKUlBSm\nTp3qeuMfEhKCzWajsrISjUau0xbNj1ajxhSovqrTw5VOJ2XllVjLHNjLKrGXV2Ird1R9Lqv6XOl0\n1phW+YrzXvUe6lDfPwOdTodOp3MdtdtsNkJDQ5k4cSK33HILAGazmcLCwkbJplapGN4nlojQQLfv\n4IQQtcvNzaVnz56u22azmZycHEwmEzk5OZjN5hrbMjIy0Gg0rp66DRs2MGLECCn2wq9p1GqMAeom\nmfW10Qp+ff8MDAYDs2fPZvTo0RgMBiZMmEB8fHyNx7/77ruu4g/w97//nYKCAjp16kRSUhIBAZ4N\n5BBCNA2lvplXfuGLL75gw4YNvP32226/NzzciFbr/k1BZGSwx8/fVHwxE/hmLsnkmavJ1GSD9i79\nZ2CxWHjjjTfYsmULJpOJGTNmcPToUbp16wZUnd8/cuQIr7/+OgDTp0+na9eutGvXjvnz57N27Vpm\nzpxZ53N5+g8CWt4vtLFIJs/5Yq7GyBQVFUVu7sU12rOzs4mMjKx12/nz54mKigLgq6++4vXXX2fV\nqlUEB7vPVVBgdfs9npxvbWq+mAl8M5dk8oy7TO7aeaMV/Pr+GaSnp9O2bVtXl9/AgQNJS0ujW7du\n/OMf/+C///0vr776KjpdVRfHmDFjXPu58cYb+fTTT+t9bk/+QUDz/IV6g2TynC/mqi/T1bwRGDp0\nKCtXrmTKlCkcOXKEqKgoTCYTAG3atMFisZCZmUlMTAzbt29n+fLllJSU8Pzzz/POO+8QFhbm5hmE\nEA2p0S4IHDp0KFu3bgX41T+DuLg40tPTsdvtAKSlpdGhQwcyMjJYv349L7/8MgZD1YhJRVG45557\nKC4uBmDPnj1cc801tTyjEKIpDRgwgJ49ezJlyhQWL17M/Pnz2bRpE59//jkACxYsYM6cOdx9992M\nHz+e+Ph4Pv30UwoKCnj00UeZNm0a06ZN4+zZs15+JUL4B5VyOSfeLtPy5cvZv38/KpWK+fPn8/33\n3xMcHMyYMWNYv349mzZtQqPR0L9/f+bOncuLL77Iv//9b2JjY137WL16NV988QWrVq0iMDCQ6Oho\nlixZQmCgTIsrhBBCeKpRC74QQgghfIOsDSuEEEL4ASn4QgghhB+Qgi+EEEL4ASn4QgghhB+Qgi+E\nEEL4Ab9cHre+Vfya2i+XCu3duzdz586lsrKSyMhIXnjhBfR6fZPnstvt3HLLLcyaNYvBgwd7PdPm\nzZtZtWoVWq2WRx55hK5du3o9U2lpKYmJiRQVFVFRUcHs2bOJjIxkwYIFAHTt2pWFCxc2SZZjx44x\na9Ys7rnnHhISEjh37lytP5/Nmzfz7rvvolarueuuu7jzzjubJF9j8pX2LG3Zc77Wnn2pLUMjtmfF\nz+zZs0f5/e9/ryiKopw4cUK56667vJYlJSVFuf/++xVFUZT8/Hxl5MiRyrx585RPP/1UURRF+etf\n/6qsXbvWK9lefPFF5Y477lA2btzo9Uz5+fnK2LFjlZKSEuX8+fPKk08+6fVMiqIo77//vrJ8+XJF\nURQlKytLGTdunJKQkKCkpqYqiqIof/7zn5UdO3Y0eo7S0lIlISFBefLJJ5X3339fURSl1p9PaWmp\nMnbsWKW4uFix2WzKhAkTlIKCgkbP15h8pT1LW/acL7ZnX2nLitK47dnvuvTrWsXPG6677jpWrFgB\nXFwqdM+ePdx0000A3HDDDaSkpDR5rvT0dE6cOMGoUaMAvJ4pJSWFwYMHYzKZiIqKYtGiRV7PBBAe\nHu5a0bG4uJiwsDDOnDnjOsJsqlx6vZ633nrLNVc91P47S01NpXfv3gQHBxMQEMCAAQM4cOBAo+dr\nTL7SnqUte84X27OvtGVo3PbsdwU/NzeX8PBw1+3qVfy8obalQm02m6srKyIiwivZnnvuOebNm+e6\n7e1MmZmZ2O12HnzwQaZOnUpKSorXMwFMmDCBs2fPMmbMGBISEpg7dy4hISGu7U2VS6vV/mr1yNp+\nPrm5ub9astZbf/sNxVfas7Rlz/lie/aVtgyN25798hz+pRQfmGjw0qVCx44d67rfG9k+/vhj+vXr\nR9u2bWvd7q2fV2FhIS+//DJnz55l+vTpNXJ4K9Mnn3xCbGwsq1ev5ujRo8yePbvG6m++8LcFdefw\nlXwNyduvSdqyZ3ytPTeXtgxX1579ruDXt4qfN/xyqVCj0YjdbicgIKDGkqJNZceOHWRkZLBjxw6y\nsrLQ6/VezxQREUH//v3RarW0a9eOoKAgNBqNVzMBHDhwgGHDhgHQrVs3ysrKcDgcru3eygXU+jur\n7W+/X79+XsnXUHypPUtb9owvtmdfbsvQcO3Z77r061vFr6lVLxX6xhtvuJYKHTJkiCvftm3bGD58\neJNm+tvf/sbGjRv58MMPufPOO5k1a5bXMw0bNoxvvvkGp9NJQUEBVqvV65kA2rdvT2pqKgBnzpwh\nKCiITp06sX//fq/mgtr/jvr27cvhw4cpLi6mtLSUAwcOMHDgQK/kayi+0p6lLXvOF9uzL7dlaLj2\n7JeL5/xyFb9u3bp5JUdycjIrV64kPj7edd+yZct48sknKSsrIzY2lmeffRadTueVfCtXriQuLo5h\nw4aRmJjo1Uzr169nw4YNADz00EP07t3b65lKS0tJSkoiLy8Ph8PB//3f/xEZGcnTTz+N0+mkb9++\nPP74442eIy0tjeeee44zZ86g1WqJjo5m+fLlzJs371c/ny1btrB69WpUKhUJCQlMnDix0fM1Nl9o\nz9KWL4+vtWdfacvQuO3ZLwu+EEII4W/8rktfCCGE8EdS8IUQQgg/IAVfCCGE8ANS8IUQQgg/IAVf\nCCGE8ANS8IXXbdq0iccee8zbMYQQV0nasm+Tgi+EEEL4Ab+bWldcuffff5/PPvuMyspKOnbsyP33\n388f/vAHRowYwdGjRwF46aWXiI6OZseOHbzyyisEBAQQGBjIokWLiI6OJjU1laVLl6LT6QgNDeW5\n554DwGKx8Nhjj5Genk5sbCwvv/wy2dnZrqMFu93O5MmTmTRpktdevxAthbRlP9WgC/mKFis1NVWZ\nNm2a4nQ6FUVRlCVLlijvvfee0qVLF+Xw4cOKoijKSy+9pCxdulSxWq3K0KFDlXPnzimKUrXW9Lx5\n8xRFUZQxY8YoP/74o6IoirJmzRrlX//6l7Jx40blpptuUqxWq+J0OpUxY8Yohw8fVtasWaM8/fTT\niqIoit1ud60NLYS4ctKW/Zcc4QuP7Nmzh9OnTzN9+nQArFYr58+fJywsjF69egEwYMAA3n33XU6e\nPElERAQxMTEADBo0iPXr15Ofn09xcTFdunQB4J577gGqzvv17t2bwMBAAKKjoykpKWH48OF88MEH\nzJs3j5EjRzJ58uQmftVCtDzSlv2XFHzhEb1ez4033sjTTz/tui8zM5M77rjDdVtRFFQqFSqVqsZj\nL71fqWMmZ41G86vHdOrUiX//+9/s27ePLVu28O6777J+/foGfFVC+B9py/5LBu0JjwwYMIAvv/yS\n0tJSANauXUtOTg5FRUV8//33QNUSk127dqVDhw7k5eVx9uxZAFJSUujbty/h4eGEhYVx6NAhAN5+\n+23Wrl1b53P+85//5PDhwwwZMoT58+dz7ty5GktWCiEun7Rl/yVH+MIjvXv35u6772batGkYDAai\noqL4zW9+Q3R0NJs2bWLZsmUoisKLL75IQEAAS5Ys4U9/+pNrDe4lS5YA8MILL7B06VK0Wi3BwcG8\n8MILbNu2rdbn7Ny5M/Pnz0ev16MoCg888ABarfzJCnE1pC37L1ktT1yxzMxMpk6dypdffuntKEKI\nqyBt2T9Il74QQgjhB+QIXwghhPADcoQvhBBC+AEp+EIIIYQfkIIvhBBC+AEp+EIIIYQfkIIvhBBC\n+AEp+EIIIYQf+P/gVRR8dD8htgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f736941b470>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "aH__v13zQaBS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Obtain the test accuracy"
      ]
    },
    {
      "metadata": {
        "id": "qk5hIPFoQZP5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "90fdead5-6030-46f9-eaf9-2d1ca2055435"
      },
      "cell_type": "code",
      "source": [
        "a_test, c_test  = sess.run([accuracy, cross_entropy], feed_dict={X: x_test, y: y_test})\n",
        "\n",
        "print('Test accuracy is: ', (\"%.2f\"%(a_test*100))+'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is:  90.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "mqPhv-PHLftr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hberBIgCRzXd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can try increasing the number of epochs for better accuracy"
      ]
    },
    {
      "metadata": {
        "id": "2gWfbEKXA_3Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Add a hidden layer of 200 neurons, use sigmoid activation for hidden units, train and obtain train, validation and test accuracies and loss\n",
        "\n",
        "Computational graph"
      ]
    },
    {
      "metadata": {
        "id": "TroRdqrI7_vX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create computational graph\n",
        "\n",
        "# input \n",
        "X = tf.placeholder(tf.float32, [None,784])\n",
        "# labels (onehot encoded)\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "''' First hidden layer with 200 neurons'''\n",
        "# weights 1\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))\n",
        "# biases 1\n",
        "b1 = tf.Variable(tf.zeros([200]))\n",
        "\n",
        "# weigthed sum\n",
        "z1 = tf.matmul(X, W1) + b1\n",
        "\n",
        "#  activation\n",
        "h1 = tf.nn.sigmoid(z1)\n",
        "\n",
        "\n",
        "''' Second/output Layer'''\n",
        "# weights 2\n",
        "W2 = tf.Variable(tf.truncated_normal([200, 10], stddev=0.1))\n",
        "# biases 2\n",
        "b2 = tf.Variable(tf.zeros([10]))\n",
        "\n",
        "# weigthed sum\n",
        "z2 = tf.matmul(h1, W2) + b2\n",
        "\n",
        "# softmax activation\n",
        "h2 = tf.nn.softmax(z2)\n",
        "\n",
        "# softmax cross entropy loss\n",
        "cross_entropy = -tf.reduce_mean(y * tf.log(h2))\n",
        "\n",
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "correct_prediction = tf.equal(tf.argmax(h2, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# training, learning rate = 0.005\n",
        "# learning rate\n",
        "lr = 0.005\n",
        "train_step = tf.train.GradientDescentOptimizer(lr).minimize(cross_entropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P74SqWbSSOvh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ItGQVt1SSPR6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start session"
      ]
    },
    {
      "metadata": {
        "id": "XpiYTydxJEbH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Start session\n",
        "\n",
        "# initialize all variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Ea8h4_RLnDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5227
        },
        "outputId": "ddb567dc-dadf-4846-9b59-63cb71edccf1"
      },
      "cell_type": "code",
      "source": [
        "history = training(x_train, y_train, x_val, y_val, sess, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1.0\n",
            " train accuracy:0.13854545train loss: 0.23432532\n",
            " ********* validation accuracy:0.1416 validation loss: 0.23346566\n",
            "EPOCH 2.0\n",
            " train accuracy:0.17956364train loss: 0.22730322\n",
            " ********* validation accuracy:0.1862 validation loss: 0.22651786\n",
            "EPOCH 3.0\n",
            " train accuracy:0.24534546train loss: 0.22273418\n",
            " ********* validation accuracy:0.2548 validation loss: 0.22188616\n",
            "EPOCH 4.0\n",
            " train accuracy:0.3141818train loss: 0.21853791\n",
            " ********* validation accuracy:0.3216 validation loss: 0.21757375\n",
            "EPOCH 5.0\n",
            " train accuracy:0.37703636train loss: 0.21446864\n",
            " ********* validation accuracy:0.3986 validation loss: 0.21337779\n",
            "EPOCH 6.0\n",
            " train accuracy:0.429train loss: 0.21049492\n",
            " ********* validation accuracy:0.45 validation loss: 0.20927797\n",
            "EPOCH 7.0\n",
            " train accuracy:0.4695091train loss: 0.20660679\n",
            " ********* validation accuracy:0.4898 validation loss: 0.20526657\n",
            "EPOCH 8.0\n",
            " train accuracy:0.5022182train loss: 0.20279802\n",
            " ********* validation accuracy:0.5218 validation loss: 0.20133795\n",
            "EPOCH 9.0\n",
            " train accuracy:0.52878183train loss: 0.19906414\n",
            " ********* validation accuracy:0.5448 validation loss: 0.19748753\n",
            "EPOCH 10.0\n",
            " train accuracy:0.55192727train loss: 0.1954015\n",
            " ********* validation accuracy:0.5646 validation loss: 0.1937118\n",
            "EPOCH 11.0\n",
            " train accuracy:0.5706train loss: 0.19180761\n",
            " ********* validation accuracy:0.5836 validation loss: 0.1900081\n",
            "EPOCH 12.0\n",
            " train accuracy:0.58745456train loss: 0.18828055\n",
            " ********* validation accuracy:0.5996 validation loss: 0.18637457\n",
            "EPOCH 13.0\n",
            " train accuracy:0.6014train loss: 0.18481909\n",
            " ********* validation accuracy:0.6146 validation loss: 0.18280993\n",
            "EPOCH 14.0\n",
            " train accuracy:0.614train loss: 0.18142238\n",
            " ********* validation accuracy:0.6278 validation loss: 0.17931345\n",
            "EPOCH 15.0\n",
            " train accuracy:0.6257455train loss: 0.17809016\n",
            " ********* validation accuracy:0.6388 validation loss: 0.1758848\n",
            "EPOCH 16.0\n",
            " train accuracy:0.63583636train loss: 0.17482238\n",
            " ********* validation accuracy:0.6476 validation loss: 0.17252393\n",
            "EPOCH 17.0\n",
            " train accuracy:0.6453091train loss: 0.1716193\n",
            " ********* validation accuracy:0.6558 validation loss: 0.16923113\n",
            "EPOCH 18.0\n",
            " train accuracy:0.6542364train loss: 0.16848119\n",
            " ********* validation accuracy:0.6644 validation loss: 0.16600671\n",
            "EPOCH 19.0\n",
            " train accuracy:0.6638182train loss: 0.16540858\n",
            " ********* validation accuracy:0.6722 validation loss: 0.16285115\n",
            "EPOCH 20.0\n",
            " train accuracy:0.672train loss: 0.16240188\n",
            " ********* validation accuracy:0.6804 validation loss: 0.15976489\n",
            "EPOCH 21.0\n",
            " train accuracy:0.67945457train loss: 0.15946157\n",
            " ********* validation accuracy:0.6884 validation loss: 0.15674835\n",
            "EPOCH 22.0\n",
            " train accuracy:0.6864train loss: 0.15658805\n",
            " ********* validation accuracy:0.6976 validation loss: 0.15380195\n",
            "EPOCH 23.0\n",
            " train accuracy:0.69323635train loss: 0.15378161\n",
            " ********* validation accuracy:0.706 validation loss: 0.15092586\n",
            "EPOCH 24.0\n",
            " train accuracy:0.70012724train loss: 0.15104239\n",
            " ********* validation accuracy:0.714 validation loss: 0.14812024\n",
            "EPOCH 25.0\n",
            " train accuracy:0.7062727train loss: 0.14837053\n",
            " ********* validation accuracy:0.7208 validation loss: 0.14538512\n",
            "EPOCH 26.0\n",
            " train accuracy:0.7123455train loss: 0.14576593\n",
            " ********* validation accuracy:0.7268 validation loss: 0.14272036\n",
            "EPOCH 27.0\n",
            " train accuracy:0.7181818train loss: 0.14322841\n",
            " ********* validation accuracy:0.7324 validation loss: 0.14012566\n",
            "EPOCH 28.0\n",
            " train accuracy:0.7239091train loss: 0.14075767\n",
            " ********* validation accuracy:0.7394 validation loss: 0.13760063\n",
            "EPOCH 29.0\n",
            " train accuracy:0.7293818train loss: 0.13835315\n",
            " ********* validation accuracy:0.7448 validation loss: 0.13514465\n",
            "EPOCH 30.0\n",
            " train accuracy:0.73498183train loss: 0.13601427\n",
            " ********* validation accuracy:0.7486 validation loss: 0.13275701\n",
            "EPOCH 31.0\n",
            " train accuracy:0.7393636train loss: 0.1337402\n",
            " ********* validation accuracy:0.7534 validation loss: 0.1304368\n",
            "EPOCH 32.0\n",
            " train accuracy:0.7438727train loss: 0.1315302\n",
            " ********* validation accuracy:0.7586 validation loss: 0.12818311\n",
            "EPOCH 33.0\n",
            " train accuracy:0.74874544train loss: 0.12938319\n",
            " ********* validation accuracy:0.7654 validation loss: 0.12599482\n",
            "EPOCH 34.0\n",
            " train accuracy:0.75267273train loss: 0.12729813\n",
            " ********* validation accuracy:0.7688 validation loss: 0.1238707\n",
            "EPOCH 35.0\n",
            " train accuracy:0.7567273train loss: 0.12527387\n",
            " ********* validation accuracy:0.7734 validation loss: 0.12180951\n",
            "EPOCH 36.0\n",
            " train accuracy:0.76103634train loss: 0.123309106\n",
            " ********* validation accuracy:0.7774 validation loss: 0.119809866\n",
            "EPOCH 37.0\n",
            " train accuracy:0.7647455train loss: 0.121402554\n",
            " ********* validation accuracy:0.7824 validation loss: 0.11787035\n",
            "EPOCH 38.0\n",
            " train accuracy:0.7681636train loss: 0.119552866\n",
            " ********* validation accuracy:0.7856 validation loss: 0.11598947\n",
            "EPOCH 39.0\n",
            " train accuracy:0.77156365train loss: 0.11775862\n",
            " ********* validation accuracy:0.7902 validation loss: 0.114165746\n",
            "EPOCH 40.0\n",
            " train accuracy:0.7747273train loss: 0.116018355\n",
            " ********* validation accuracy:0.7934 validation loss: 0.11239756\n",
            "EPOCH 41.0\n",
            " train accuracy:0.7771091train loss: 0.11433066\n",
            " ********* validation accuracy:0.7962 validation loss: 0.11068345\n",
            "EPOCH 42.0\n",
            " train accuracy:0.77927274train loss: 0.112693965\n",
            " ********* validation accuracy:0.797 validation loss: 0.1090217\n",
            "EPOCH 43.0\n",
            " train accuracy:0.7817636train loss: 0.11110685\n",
            " ********* validation accuracy:0.7978 validation loss: 0.10741084\n",
            "EPOCH 44.0\n",
            " train accuracy:0.78407276train loss: 0.10956778\n",
            " ********* validation accuracy:0.8 validation loss: 0.10584921\n",
            "EPOCH 45.0\n",
            " train accuracy:0.78656363train loss: 0.10807527\n",
            " ********* validation accuracy:0.8022 validation loss: 0.10433523\n",
            "EPOCH 46.0\n",
            " train accuracy:0.7885636train loss: 0.10662787\n",
            " ********* validation accuracy:0.8048 validation loss: 0.102867424\n",
            "EPOCH 47.0\n",
            " train accuracy:0.7906909train loss: 0.10522411\n",
            " ********* validation accuracy:0.8058 validation loss: 0.10144421\n",
            "EPOCH 48.0\n",
            " train accuracy:0.7933273train loss: 0.10386254\n",
            " ********* validation accuracy:0.8072 validation loss: 0.10006403\n",
            "EPOCH 49.0\n",
            " train accuracy:0.79547274train loss: 0.10254175\n",
            " ********* validation accuracy:0.8084 validation loss: 0.098725475\n",
            "EPOCH 50.0\n",
            " train accuracy:0.7975091train loss: 0.10126038\n",
            " ********* validation accuracy:0.8106 validation loss: 0.09742708\n",
            "EPOCH 51.0\n",
            " train accuracy:0.7992727train loss: 0.10001706\n",
            " ********* validation accuracy:0.813 validation loss: 0.0961674\n",
            "EPOCH 52.0\n",
            " train accuracy:0.80096364train loss: 0.098810464\n",
            " ********* validation accuracy:0.8142 validation loss: 0.094945095\n",
            "EPOCH 53.0\n",
            " train accuracy:0.80258185train loss: 0.09763936\n",
            " ********* validation accuracy:0.8164 validation loss: 0.09375885\n",
            "EPOCH 54.0\n",
            " train accuracy:0.8042train loss: 0.096502446\n",
            " ********* validation accuracy:0.8174 validation loss: 0.092607304\n",
            "EPOCH 55.0\n",
            " train accuracy:0.8056909train loss: 0.09539852\n",
            " ********* validation accuracy:0.8196 validation loss: 0.09148924\n",
            "EPOCH 56.0\n",
            " train accuracy:0.8071455train loss: 0.09432642\n",
            " ********* validation accuracy:0.821 validation loss: 0.09040344\n",
            "EPOCH 57.0\n",
            " train accuracy:0.8085818train loss: 0.09328502\n",
            " ********* validation accuracy:0.8222 validation loss: 0.08934873\n",
            "EPOCH 58.0\n",
            " train accuracy:0.8102train loss: 0.092273206\n",
            " ********* validation accuracy:0.8238 validation loss: 0.08832397\n",
            "EPOCH 59.0\n",
            " train accuracy:0.8112182train loss: 0.091289915\n",
            " ********* validation accuracy:0.825 validation loss: 0.08732807\n",
            "EPOCH 60.0\n",
            " train accuracy:0.8125091train loss: 0.09033414\n",
            " ********* validation accuracy:0.8256 validation loss: 0.08635997\n",
            "EPOCH 61.0\n",
            " train accuracy:0.8137818train loss: 0.089404866\n",
            " ********* validation accuracy:0.8266 validation loss: 0.08541865\n",
            "EPOCH 62.0\n",
            " train accuracy:0.8151818train loss: 0.088501155\n",
            " ********* validation accuracy:0.828 validation loss: 0.08450312\n",
            "EPOCH 63.0\n",
            " train accuracy:0.8162train loss: 0.08762211\n",
            " ********* validation accuracy:0.8294 validation loss: 0.08361248\n",
            "EPOCH 64.0\n",
            " train accuracy:0.8175273train loss: 0.08676684\n",
            " ********* validation accuracy:0.8316 validation loss: 0.0827458\n",
            "EPOCH 65.0\n",
            " train accuracy:0.8184364train loss: 0.08593451\n",
            " ********* validation accuracy:0.8326 validation loss: 0.08190221\n",
            "EPOCH 66.0\n",
            " train accuracy:0.8194364train loss: 0.08512429\n",
            " ********* validation accuracy:0.834 validation loss: 0.081080906\n",
            "EPOCH 67.0\n",
            " train accuracy:0.82061815train loss: 0.08433541\n",
            " ********* validation accuracy:0.8352 validation loss: 0.08028109\n",
            "EPOCH 68.0\n",
            " train accuracy:0.8216train loss: 0.08356711\n",
            " ********* validation accuracy:0.8358 validation loss: 0.07950196\n",
            "EPOCH 69.0\n",
            " train accuracy:0.8225273train loss: 0.08281867\n",
            " ********* validation accuracy:0.8366 validation loss: 0.078742795\n",
            "EPOCH 70.0\n",
            " train accuracy:0.8236727train loss: 0.08208938\n",
            " ********* validation accuracy:0.838 validation loss: 0.07800286\n",
            "EPOCH 71.0\n",
            " train accuracy:0.82469094train loss: 0.081378594\n",
            " ********* validation accuracy:0.8392 validation loss: 0.077281505\n",
            "EPOCH 72.0\n",
            " train accuracy:0.8255091train loss: 0.080685675\n",
            " ********* validation accuracy:0.8398 validation loss: 0.0765781\n",
            "EPOCH 73.0\n",
            " train accuracy:0.8266train loss: 0.08000999\n",
            " ********* validation accuracy:0.8406 validation loss: 0.075892\n",
            "EPOCH 74.0\n",
            " train accuracy:0.8274train loss: 0.07935096\n",
            " ********* validation accuracy:0.8414 validation loss: 0.0752226\n",
            "EPOCH 75.0\n",
            " train accuracy:0.8281818train loss: 0.07870807\n",
            " ********* validation accuracy:0.8424 validation loss: 0.074569345\n",
            "EPOCH 76.0\n",
            " train accuracy:0.8291091train loss: 0.078080684\n",
            " ********* validation accuracy:0.8438 validation loss: 0.07393165\n",
            "EPOCH 77.0\n",
            " train accuracy:0.83003634train loss: 0.07746834\n",
            " ********* validation accuracy:0.8454 validation loss: 0.07330901\n",
            "EPOCH 78.0\n",
            " train accuracy:0.8306909train loss: 0.07687053\n",
            " ********* validation accuracy:0.846 validation loss: 0.07270093\n",
            "EPOCH 79.0\n",
            " train accuracy:0.83149093train loss: 0.076286756\n",
            " ********* validation accuracy:0.8468 validation loss: 0.0721069\n",
            "EPOCH 80.0\n",
            " train accuracy:0.83236367train loss: 0.075716555\n",
            " ********* validation accuracy:0.8472 validation loss: 0.07152646\n",
            "EPOCH 81.0\n",
            " train accuracy:0.833train loss: 0.07515949\n",
            " ********* validation accuracy:0.8488 validation loss: 0.070959166\n",
            "EPOCH 82.0\n",
            " train accuracy:0.8336545train loss: 0.074615136\n",
            " ********* validation accuracy:0.8498 validation loss: 0.07040457\n",
            "EPOCH 83.0\n",
            " train accuracy:0.83436364train loss: 0.0740831\n",
            " ********* validation accuracy:0.8512 validation loss: 0.069862284\n",
            "EPOCH 84.0\n",
            " train accuracy:0.8351273train loss: 0.07356297\n",
            " ********* validation accuracy:0.8522 validation loss: 0.06933192\n",
            "EPOCH 85.0\n",
            " train accuracy:0.8356909train loss: 0.07305437\n",
            " ********* validation accuracy:0.8534 validation loss: 0.06881308\n",
            "EPOCH 86.0\n",
            " train accuracy:0.83647275train loss: 0.072556965\n",
            " ********* validation accuracy:0.8544 validation loss: 0.0683054\n",
            "EPOCH 87.0\n",
            " train accuracy:0.8372train loss: 0.072070375\n",
            " ********* validation accuracy:0.8562 validation loss: 0.06780853\n",
            "EPOCH 88.0\n",
            " train accuracy:0.83778185train loss: 0.07159424\n",
            " ********* validation accuracy:0.8562 validation loss: 0.067322105\n",
            "EPOCH 89.0\n",
            " train accuracy:0.8387455train loss: 0.071128316\n",
            " ********* validation accuracy:0.8568 validation loss: 0.06684588\n",
            "EPOCH 90.0\n",
            " train accuracy:0.8392909train loss: 0.070672266\n",
            " ********* validation accuracy:0.8572 validation loss: 0.066379495\n",
            "EPOCH 91.0\n",
            " train accuracy:0.84007275train loss: 0.070225745\n",
            " ********* validation accuracy:0.8572 validation loss: 0.06592264\n",
            "EPOCH 92.0\n",
            " train accuracy:0.84074545train loss: 0.06978848\n",
            " ********* validation accuracy:0.8584 validation loss: 0.06547502\n",
            "EPOCH 93.0\n",
            " train accuracy:0.8414909train loss: 0.06936022\n",
            " ********* validation accuracy:0.8588 validation loss: 0.06503638\n",
            "EPOCH 94.0\n",
            " train accuracy:0.8419818train loss: 0.06894067\n",
            " ********* validation accuracy:0.8598 validation loss: 0.064606436\n",
            "EPOCH 95.0\n",
            " train accuracy:0.8426545train loss: 0.0685296\n",
            " ********* validation accuracy:0.8606 validation loss: 0.06418495\n",
            "EPOCH 96.0\n",
            " train accuracy:0.8432train loss: 0.068126775\n",
            " ********* validation accuracy:0.861 validation loss: 0.06377171\n",
            "EPOCH 97.0\n",
            " train accuracy:0.84363633train loss: 0.06773194\n",
            " ********* validation accuracy:0.8618 validation loss: 0.06336641\n",
            "EPOCH 98.0\n",
            " train accuracy:0.8442train loss: 0.06734486\n",
            " ********* validation accuracy:0.8622 validation loss: 0.062968865\n",
            "EPOCH 99.0\n",
            " train accuracy:0.84492725train loss: 0.0669653\n",
            " ********* validation accuracy:0.8638 validation loss: 0.06257883\n",
            "EPOCH 100.0\n",
            " train accuracy:0.8454546train loss: 0.066593066\n",
            " ********* validation accuracy:0.8646 validation loss: 0.062196095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AhihJDfKx-mH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bpsEIn_-ShHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5da7b0ad-83a0-4750-bff5-3978c2d1b264"
      },
      "cell_type": "code",
      "source": [
        "a_test, c_test  = sess.run([accuracy, cross_entropy], feed_dict={X: x_test, y: y_test})\n",
        "\n",
        "print('Test accuracy is: ', (\"%.2f\"%(a_test*100))+'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is:  85.52%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b8puHuHPSh5L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BYvKaU1WT2HZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can try increasing the number of epochs for better accuracy"
      ]
    },
    {
      "metadata": {
        "id": "pcvZJfOK4abr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# You are to build the computational graph by completing the required code statement with None assigned"
      ]
    },
    {
      "metadata": {
        "id": "wqg1bwq5MmZQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Build a five layer neural network with sigmoid activation"
      ]
    },
    {
      "metadata": {
        "id": "DRDdoKBSMsdY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "c4f6593e-fa4b-4eeb-ade7-1257a6c1eea9"
      },
      "cell_type": "code",
      "source": [
        "#Create computational graph\n",
        "\n",
        "# input \n",
        "X = tf.placeholder(tf.float32, [None,784])\n",
        "# labels (onehot encoded)\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "''' First hidden layer with 200 neurons'''\n",
        "# weights 1\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))\n",
        "# biases 1\n",
        "b1 = tf.Variable(tf.zeros([200]))\n",
        "\n",
        "# weigthed sum\n",
        "z1 = tf.matmul(X, W1) + b1\n",
        "\n",
        "#  activation\n",
        "h1 = tf.nn.sigmoid(z1)\n",
        "\n",
        "''' Second hidden layer with 100 neurons'''\n",
        "################## START CODE #########################\n",
        "# weights 1\n",
        "W2 = None\n",
        "# biases 1\n",
        "b2 = None\n",
        "\n",
        "# weigthed sum\n",
        "z2 = tf.matmul(h1, W2) + b2\n",
        "\n",
        "#  activation\n",
        "h2 = tf.nn.sigmoid(z2)\n",
        "\n",
        "####################### END #############################\n",
        "\n",
        "''' third Layer with 60 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W3 = None\n",
        "# biases 2\n",
        "b3 = None\n",
        "\n",
        "# weigthed sum\n",
        "z3 = None\n",
        "#  activation\n",
        "h3 = None\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fourth Layer with 30 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W4 = None\n",
        "# biases 2\n",
        "b4 = tf.Variable(tf.zeros([30]))\n",
        "\n",
        "# weigthed sum\n",
        "z4 = None\n",
        "\n",
        "\n",
        "#  activation\n",
        "h4 = None\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fifth/output Layer with 10 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W5 = None\n",
        "# biases 2\n",
        "b5 = None\n",
        "# weigthed sum\n",
        "z5 = None\n",
        "\n",
        "# softmax activation (optional)\n",
        "h5 = tf.nn.softmax(z5)\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "\n",
        "\n",
        "# cross-entropy loss function (= -sum(y_i * log(hi)) )\n",
        "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
        "# problems with log(0) which is NaN\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=z5, labels=y)\n",
        "cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "################### END ###############################\n",
        "\n",
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "correct_prediction = tf.equal(tf.argmax(h5, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# training\n",
        "################# START CODE ########################\n",
        "# learning rate\n",
        "lr = None\n",
        "train_step = None\n",
        "\n",
        "################# END ###############################"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-18-88f5c69e6796>:82: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KTJcRkYlT_FP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start a session"
      ]
    },
    {
      "metadata": {
        "id": "uVUDCOLNUBQq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Start session\n",
        "\n",
        "# initialize all variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4xmeL4flULAw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train & visualize train/val loss and accuracy"
      ]
    },
    {
      "metadata": {
        "id": "mgQVQj5AUKBg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5227
        },
        "outputId": "4fd54686-468d-4299-e7a7-86c77e6687d0"
      },
      "cell_type": "code",
      "source": [
        "history = training(x_train, y_train, x_val, y_val, sess, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1.0\n",
            " train accuracy:0.11234546train loss: 2.299229\n",
            " ********* validation accuracy:0.1126 validation loss: 2.2965806\n",
            "EPOCH 2.0\n",
            " train accuracy:0.5646545train loss: 1.3100142\n",
            " ********* validation accuracy:0.5888 validation loss: 1.255211\n",
            "EPOCH 3.0\n",
            " train accuracy:0.7897636train loss: 0.6934016\n",
            " ********* validation accuracy:0.8318 validation loss: 0.5764511\n",
            "EPOCH 4.0\n",
            " train accuracy:0.8810545train loss: 0.44543943\n",
            " ********* validation accuracy:0.9368 validation loss: 0.26042506\n",
            "EPOCH 5.0\n",
            " train accuracy:0.89878184train loss: 0.3827483\n",
            " ********* validation accuracy:0.9704 validation loss: 0.14195396\n",
            "EPOCH 6.0\n",
            " train accuracy:0.9054545train loss: 0.37272328\n",
            " ********* validation accuracy:0.9898 validation loss: 0.06667749\n",
            "EPOCH 7.0\n",
            " train accuracy:0.9087273train loss: 0.37858084\n",
            " ********* validation accuracy:0.9962 validation loss: 0.03355467\n",
            "EPOCH 8.0\n",
            " train accuracy:0.9107091train loss: 0.38938072\n",
            " ********* validation accuracy:0.9984 validation loss: 0.020447787\n",
            "EPOCH 9.0\n",
            " train accuracy:0.9112909train loss: 0.39687082\n",
            " ********* validation accuracy:0.9988 validation loss: 0.014104097\n",
            "EPOCH 10.0\n",
            " train accuracy:0.9114909train loss: 0.40457052\n",
            " ********* validation accuracy:0.9994 validation loss: 0.009833786\n",
            "EPOCH 11.0\n",
            " train accuracy:0.9118909train loss: 0.41190624\n",
            " ********* validation accuracy:0.9996 validation loss: 0.0071394728\n",
            "EPOCH 12.0\n",
            " train accuracy:0.91221815train loss: 0.4185236\n",
            " ********* validation accuracy:0.9998 validation loss: 0.005022275\n",
            "EPOCH 13.0\n",
            " train accuracy:0.9126727train loss: 0.42436263\n",
            " ********* validation accuracy:0.9998 validation loss: 0.003844722\n",
            "EPOCH 14.0\n",
            " train accuracy:0.9130545train loss: 0.42963412\n",
            " ********* validation accuracy:0.9998 validation loss: 0.0030987542\n",
            "EPOCH 15.0\n",
            " train accuracy:0.91316366train loss: 0.43530372\n",
            " ********* validation accuracy:1.0 validation loss: 0.0023846999\n",
            "EPOCH 16.0\n",
            " train accuracy:0.9135454train loss: 0.43983456\n",
            " ********* validation accuracy:1.0 validation loss: 0.0019439438\n",
            "EPOCH 17.0\n",
            " train accuracy:0.9138train loss: 0.4436606\n",
            " ********* validation accuracy:1.0 validation loss: 0.0016686196\n",
            "EPOCH 18.0\n",
            " train accuracy:0.914train loss: 0.44713658\n",
            " ********* validation accuracy:1.0 validation loss: 0.0014677959\n",
            "EPOCH 19.0\n",
            " train accuracy:0.9142train loss: 0.45033374\n",
            " ********* validation accuracy:1.0 validation loss: 0.0013119144\n",
            "EPOCH 20.0\n",
            " train accuracy:0.9142train loss: 0.45329162\n",
            " ********* validation accuracy:1.0 validation loss: 0.0011864445\n",
            "EPOCH 21.0\n",
            " train accuracy:0.91443634train loss: 0.45604146\n",
            " ********* validation accuracy:1.0 validation loss: 0.0010829039\n",
            "EPOCH 22.0\n",
            " train accuracy:0.91465455train loss: 0.4586094\n",
            " ********* validation accuracy:1.0 validation loss: 0.0009958423\n",
            "EPOCH 23.0\n",
            " train accuracy:0.9147818train loss: 0.46101725\n",
            " ********* validation accuracy:1.0 validation loss: 0.0009215375\n",
            "EPOCH 24.0\n",
            " train accuracy:0.91492724train loss: 0.4632835\n",
            " ********* validation accuracy:1.0 validation loss: 0.0008573487\n",
            "EPOCH 25.0\n",
            " train accuracy:0.91514546train loss: 0.46542385\n",
            " ********* validation accuracy:1.0 validation loss: 0.0008013271\n",
            "EPOCH 26.0\n",
            " train accuracy:0.91514546train loss: 0.46745142\n",
            " ********* validation accuracy:1.0 validation loss: 0.0007520021\n",
            "EPOCH 27.0\n",
            " train accuracy:0.9152train loss: 0.46937746\n",
            " ********* validation accuracy:1.0 validation loss: 0.0007082402\n",
            "EPOCH 28.0\n",
            " train accuracy:0.9153636train loss: 0.47121164\n",
            " ********* validation accuracy:1.0 validation loss: 0.00066915306\n",
            "EPOCH 29.0\n",
            " train accuracy:0.9155091train loss: 0.47296256\n",
            " ********* validation accuracy:1.0 validation loss: 0.0006340319\n",
            "EPOCH 30.0\n",
            " train accuracy:0.9155818train loss: 0.47463748\n",
            " ********* validation accuracy:1.0 validation loss: 0.00060230895\n",
            "EPOCH 31.0\n",
            " train accuracy:0.9156train loss: 0.47624272\n",
            " ********* validation accuracy:1.0 validation loss: 0.00057350995\n",
            "EPOCH 32.0\n",
            " train accuracy:0.91574544train loss: 0.47778383\n",
            " ********* validation accuracy:1.0 validation loss: 0.00054725737\n",
            "EPOCH 33.0\n",
            " train accuracy:0.91587275train loss: 0.4792658\n",
            " ********* validation accuracy:1.0 validation loss: 0.0005232305\n",
            "EPOCH 34.0\n",
            " train accuracy:0.91603637train loss: 0.4806931\n",
            " ********* validation accuracy:1.0 validation loss: 0.0005011581\n",
            "EPOCH 35.0\n",
            " train accuracy:0.9160727train loss: 0.48206997\n",
            " ********* validation accuracy:1.0 validation loss: 0.00048081184\n",
            "EPOCH 36.0\n",
            " train accuracy:0.916train loss: 0.48339918\n",
            " ********* validation accuracy:1.0 validation loss: 0.0004620057\n",
            "EPOCH 37.0\n",
            " train accuracy:0.91605455train loss: 0.4846846\n",
            " ********* validation accuracy:1.0 validation loss: 0.00044456287\n",
            "EPOCH 38.0\n",
            " train accuracy:0.91612726train loss: 0.48592877\n",
            " ********* validation accuracy:1.0 validation loss: 0.00042835227\n",
            "EPOCH 39.0\n",
            " train accuracy:0.9161818train loss: 0.48713452\n",
            " ********* validation accuracy:1.0 validation loss: 0.00041324235\n",
            "EPOCH 40.0\n",
            " train accuracy:0.9161818train loss: 0.48830375\n",
            " ********* validation accuracy:1.0 validation loss: 0.00039912687\n",
            "EPOCH 41.0\n",
            " train accuracy:0.9161818train loss: 0.48943943\n",
            " ********* validation accuracy:1.0 validation loss: 0.00038591414\n",
            "EPOCH 42.0\n",
            " train accuracy:0.91623634train loss: 0.49054253\n",
            " ********* validation accuracy:1.0 validation loss: 0.0003735216\n",
            "EPOCH 43.0\n",
            " train accuracy:0.91629094train loss: 0.49161538\n",
            " ********* validation accuracy:1.0 validation loss: 0.00036187263\n",
            "EPOCH 44.0\n",
            " train accuracy:0.9162727train loss: 0.49265978\n",
            " ********* validation accuracy:1.0 validation loss: 0.00035090357\n",
            "EPOCH 45.0\n",
            " train accuracy:0.91629094train loss: 0.493676\n",
            " ********* validation accuracy:1.0 validation loss: 0.00034056138\n",
            "EPOCH 46.0\n",
            " train accuracy:0.9163455train loss: 0.49466708\n",
            " ********* validation accuracy:1.0 validation loss: 0.00033079303\n",
            "EPOCH 47.0\n",
            " train accuracy:0.91638184train loss: 0.49563384\n",
            " ********* validation accuracy:1.0 validation loss: 0.00032154814\n",
            "EPOCH 48.0\n",
            " train accuracy:0.9164909train loss: 0.49657705\n",
            " ********* validation accuracy:1.0 validation loss: 0.00031279275\n",
            "EPOCH 49.0\n",
            " train accuracy:0.9164364train loss: 0.49749783\n",
            " ********* validation accuracy:1.0 validation loss: 0.0003044829\n",
            "EPOCH 50.0\n",
            " train accuracy:0.91654545train loss: 0.49839765\n",
            " ********* validation accuracy:1.0 validation loss: 0.00029659088\n",
            "EPOCH 51.0\n",
            " train accuracy:0.9166train loss: 0.49927717\n",
            " ********* validation accuracy:1.0 validation loss: 0.00028908567\n",
            "EPOCH 52.0\n",
            " train accuracy:0.91663635train loss: 0.50013703\n",
            " ********* validation accuracy:1.0 validation loss: 0.00028193978\n",
            "EPOCH 53.0\n",
            " train accuracy:0.9166545train loss: 0.50097823\n",
            " ********* validation accuracy:1.0 validation loss: 0.00027512392\n",
            "EPOCH 54.0\n",
            " train accuracy:0.9166727train loss: 0.501803\n",
            " ********* validation accuracy:1.0 validation loss: 0.00026862163\n",
            "EPOCH 55.0\n",
            " train accuracy:0.9167455train loss: 0.5026091\n",
            " ********* validation accuracy:1.0 validation loss: 0.00026240977\n",
            "EPOCH 56.0\n",
            " train accuracy:0.91672724train loss: 0.50339955\n",
            " ********* validation accuracy:1.0 validation loss: 0.00025647026\n",
            "EPOCH 57.0\n",
            " train accuracy:0.9168182train loss: 0.5041751\n",
            " ********* validation accuracy:1.0 validation loss: 0.00025078555\n",
            "EPOCH 58.0\n",
            " train accuracy:0.9168182train loss: 0.5049346\n",
            " ********* validation accuracy:1.0 validation loss: 0.0002453395\n",
            "EPOCH 59.0\n",
            " train accuracy:0.91685456train loss: 0.5056804\n",
            " ********* validation accuracy:1.0 validation loss: 0.00024011686\n",
            "EPOCH 60.0\n",
            " train accuracy:0.91687274train loss: 0.50641173\n",
            " ********* validation accuracy:1.0 validation loss: 0.00023510627\n",
            "EPOCH 61.0\n",
            " train accuracy:0.9168909train loss: 0.50712955\n",
            " ********* validation accuracy:1.0 validation loss: 0.00023029446\n",
            "EPOCH 62.0\n",
            " train accuracy:0.9168909train loss: 0.50783616\n",
            " ********* validation accuracy:1.0 validation loss: 0.00022566553\n",
            "EPOCH 63.0\n",
            " train accuracy:0.91694546train loss: 0.50852895\n",
            " ********* validation accuracy:1.0 validation loss: 0.0002212183\n",
            "EPOCH 64.0\n",
            " train accuracy:0.91696364train loss: 0.5092101\n",
            " ********* validation accuracy:1.0 validation loss: 0.00021693345\n",
            "EPOCH 65.0\n",
            " train accuracy:0.9169818train loss: 0.5098797\n",
            " ********* validation accuracy:1.0 validation loss: 0.00021280983\n",
            "EPOCH 66.0\n",
            " train accuracy:0.91696364train loss: 0.51053786\n",
            " ********* validation accuracy:1.0 validation loss: 0.00020883446\n",
            "EPOCH 67.0\n",
            " train accuracy:0.91703635train loss: 0.51118517\n",
            " ********* validation accuracy:1.0 validation loss: 0.00020500136\n",
            "EPOCH 68.0\n",
            " train accuracy:0.9170727train loss: 0.51182216\n",
            " ********* validation accuracy:1.0 validation loss: 0.00020129967\n",
            "EPOCH 69.0\n",
            " train accuracy:0.91712725train loss: 0.51244926\n",
            " ********* validation accuracy:1.0 validation loss: 0.00019772445\n",
            "EPOCH 70.0\n",
            " train accuracy:0.9171818train loss: 0.5130662\n",
            " ********* validation accuracy:1.0 validation loss: 0.00019427287\n",
            "EPOCH 71.0\n",
            " train accuracy:0.91725457train loss: 0.51367307\n",
            " ********* validation accuracy:1.0 validation loss: 0.00019093638\n",
            "EPOCH 72.0\n",
            " train accuracy:0.91727275train loss: 0.5142711\n",
            " ********* validation accuracy:1.0 validation loss: 0.00018770847\n",
            "EPOCH 73.0\n",
            " train accuracy:0.91727275train loss: 0.5148609\n",
            " ********* validation accuracy:1.0 validation loss: 0.00018458349\n",
            "EPOCH 74.0\n",
            " train accuracy:0.91725457train loss: 0.5154419\n",
            " ********* validation accuracy:1.0 validation loss: 0.00018155885\n",
            "EPOCH 75.0\n",
            " train accuracy:0.9172182train loss: 0.5160137\n",
            " ********* validation accuracy:1.0 validation loss: 0.00017863006\n",
            "EPOCH 76.0\n",
            " train accuracy:0.9172364train loss: 0.5165772\n",
            " ********* validation accuracy:1.0 validation loss: 0.00017578997\n",
            "EPOCH 77.0\n",
            " train accuracy:0.91727275train loss: 0.5171331\n",
            " ********* validation accuracy:1.0 validation loss: 0.00017303575\n",
            "EPOCH 78.0\n",
            " train accuracy:0.9173091train loss: 0.5176822\n",
            " ********* validation accuracy:1.0 validation loss: 0.0001703651\n",
            "EPOCH 79.0\n",
            " train accuracy:0.9173091train loss: 0.5182238\n",
            " ********* validation accuracy:1.0 validation loss: 0.00016777319\n",
            "EPOCH 80.0\n",
            " train accuracy:0.9173273train loss: 0.518757\n",
            " ********* validation accuracy:1.0 validation loss: 0.00016525807\n",
            "EPOCH 81.0\n",
            " train accuracy:0.9173273train loss: 0.5192831\n",
            " ********* validation accuracy:1.0 validation loss: 0.00016281543\n",
            "EPOCH 82.0\n",
            " train accuracy:0.91736364train loss: 0.51980335\n",
            " ********* validation accuracy:1.0 validation loss: 0.00016043549\n",
            "EPOCH 83.0\n",
            " train accuracy:0.9173273train loss: 0.52031577\n",
            " ********* validation accuracy:1.0 validation loss: 0.00015812696\n",
            "EPOCH 84.0\n",
            " train accuracy:0.9173091train loss: 0.5208222\n",
            " ********* validation accuracy:1.0 validation loss: 0.00015588045\n",
            "EPOCH 85.0\n",
            " train accuracy:0.9172909train loss: 0.5213224\n",
            " ********* validation accuracy:1.0 validation loss: 0.00015369568\n",
            "EPOCH 86.0\n",
            " train accuracy:0.9173091train loss: 0.52181536\n",
            " ********* validation accuracy:1.0 validation loss: 0.00015157207\n",
            "EPOCH 87.0\n",
            " train accuracy:0.91734546train loss: 0.52230227\n",
            " ********* validation accuracy:1.0 validation loss: 0.00014950137\n",
            "EPOCH 88.0\n",
            " train accuracy:0.91734546train loss: 0.5227828\n",
            " ********* validation accuracy:1.0 validation loss: 0.00014748459\n",
            "EPOCH 89.0\n",
            " train accuracy:0.9173091train loss: 0.5232574\n",
            " ********* validation accuracy:1.0 validation loss: 0.0001455256\n",
            "EPOCH 90.0\n",
            " train accuracy:0.9173091train loss: 0.523727\n",
            " ********* validation accuracy:1.0 validation loss: 0.00014361339\n",
            "EPOCH 91.0\n",
            " train accuracy:0.9173091train loss: 0.524192\n",
            " ********* validation accuracy:1.0 validation loss: 0.00014174827\n",
            "EPOCH 92.0\n",
            " train accuracy:0.9173273train loss: 0.5246527\n",
            " ********* validation accuracy:1.0 validation loss: 0.00013992781\n",
            "EPOCH 93.0\n",
            " train accuracy:0.91736364train loss: 0.525107\n",
            " ********* validation accuracy:1.0 validation loss: 0.00013815008\n",
            "EPOCH 94.0\n",
            " train accuracy:0.9174train loss: 0.52555484\n",
            " ********* validation accuracy:1.0 validation loss: 0.00013642346\n",
            "EPOCH 95.0\n",
            " train accuracy:0.9174train loss: 0.52599823\n",
            " ********* validation accuracy:1.0 validation loss: 0.00013473426\n",
            "EPOCH 96.0\n",
            " train accuracy:0.91736364train loss: 0.5264366\n",
            " ********* validation accuracy:1.0 validation loss: 0.00013308541\n",
            "EPOCH 97.0\n",
            " train accuracy:0.9173818train loss: 0.5268699\n",
            " ********* validation accuracy:1.0 validation loss: 0.00013147728\n",
            "EPOCH 98.0\n",
            " train accuracy:0.91734546train loss: 0.5272984\n",
            " ********* validation accuracy:1.0 validation loss: 0.00012990528\n",
            "EPOCH 99.0\n",
            " train accuracy:0.91736364train loss: 0.52772313\n",
            " ********* validation accuracy:1.0 validation loss: 0.00012836732\n",
            "EPOCH 100.0\n",
            " train accuracy:0.9173818train loss: 0.52814335\n",
            " ********* validation accuracy:1.0 validation loss: 0.00012686609\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4xIQk0TdyAbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YS8PMju1UdLL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test accuracy"
      ]
    },
    {
      "metadata": {
        "id": "nMUiYVfRUZtD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9ce0a54-3633-4ed1-ea2a-fe3a69e5e107"
      },
      "cell_type": "code",
      "source": [
        "a_test, c_test  = sess.run([accuracy, cross_entropy], feed_dict={X: x_test, y: y_test})\n",
        "\n",
        "print('Test accuracy is: ', (\"%.2f\"%(a_test*100))+'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is:  92.11%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oSFuvfiKUXaU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. Replace the sigmoid activations with relu"
      ]
    },
    {
      "metadata": {
        "id": "HtB2pCriVBh2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Computational graph"
      ]
    },
    {
      "metadata": {
        "id": "ZcGVjBjLUiIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create computational graph\n",
        "\n",
        "# input \n",
        "X = tf.placeholder(tf.float32, [None,784])\n",
        "# labels (onehot encoded)\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "\n",
        "''' First hidden layer with 200 neurons'''\n",
        "################## START CODE #########################\n",
        "# weights 1\n",
        "W1 = None\n",
        "# biases 1\n",
        "b1 = None\n",
        "\n",
        "# weigthed sum\n",
        "z1 = None\n",
        "\n",
        "#  activation\n",
        "h1 = tf.nn.relu(z1)\n",
        "####################### END #############################\n",
        "\n",
        "''' Second hidden layer with 100 neurons'''\n",
        "################## START CODE #########################\n",
        "# weights 1\n",
        "W2 = None\n",
        "# biases 1\n",
        "b2 = None\n",
        "\n",
        "# weigthed sum\n",
        "z2 = None\n",
        "\n",
        "# activation\n",
        "h2 = tf.nn.relu(z2)\n",
        "\n",
        "####################### END #############################\n",
        "\n",
        "''' third Layer with 60 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W3 = tf.Variable(tf.truncated_normal([100, 60], stddev=0.1))\n",
        "# biases 2\n",
        "b3 = None\n",
        "\n",
        "# weigthed sum\n",
        "z3 = tf.matmul(h2, W3) + b3\n",
        "\n",
        "# activation\n",
        "h3 = None\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fourth Layer with 30 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W4 = None\n",
        "# biases 2\n",
        "b4 = tf.Variable(tf.zeros([30]))\n",
        "\n",
        "# weigthed sum\n",
        "z4 = None\n",
        "\n",
        "# activation \n",
        "h4 = None\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fifth/output Layer with 10 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W5 = None\n",
        "# biases 2\n",
        "b5 = None\n",
        "# weigthed sum\n",
        "z5 = None\n",
        "\n",
        "# softmax activation (optional)\n",
        "h5 = tf.nn.softmax(z5)\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "\n",
        "\n",
        "# cross-entropy loss function (= -sum(yi * log(hi)) )\n",
        "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
        "# problems with log(0) which is NaN\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=z5, labels=y)\n",
        "cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "################### END ###############################\n",
        "\n",
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "correct_prediction = None\n",
        "accuracy = None\n",
        "\n",
        "# training\n",
        "################# START CODE ########################\n",
        "# learning rate\n",
        "lr = None\n",
        "train_step = None\n",
        "\n",
        "################# END ###############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0yF9yD-nVALT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start a session"
      ]
    },
    {
      "metadata": {
        "id": "63pJ02MzUwcM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Start session\n",
        "\n",
        "# initialize all variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2fC7310yU9b-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train & visualize train/val loss and accuracy"
      ]
    },
    {
      "metadata": {
        "id": "CVEm4NaYUy7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5227
        },
        "outputId": "b9073800-74f2-4fbf-c907-9cd1488ea376"
      },
      "cell_type": "code",
      "source": [
        "history = training(x_train, y_train, x_val, y_val, sess, epochs=100)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1.0\n",
            " train accuracy:0.92407274train loss: 43.378914\n",
            " ********* validation accuracy:1.0 validation loss: 0.18380551\n",
            "EPOCH 2.0\n",
            " train accuracy:0.92483634train loss: 50.24637\n",
            " ********* validation accuracy:1.0 validation loss: 0.03974467\n",
            "EPOCH 3.0\n",
            " train accuracy:0.92523634train loss: 53.33686\n",
            " ********* validation accuracy:1.0 validation loss: 0.019583764\n",
            "EPOCH 4.0\n",
            " train accuracy:0.9252545train loss: 55.348526\n",
            " ********* validation accuracy:1.0 validation loss: 0.012549597\n",
            "EPOCH 5.0\n",
            " train accuracy:0.92547274train loss: 56.830288\n",
            " ********* validation accuracy:1.0 validation loss: 0.009075951\n",
            "EPOCH 6.0\n",
            " train accuracy:0.92556363train loss: 58.004112\n",
            " ********* validation accuracy:1.0 validation loss: 0.0070276298\n",
            "EPOCH 7.0\n",
            " train accuracy:0.9255818train loss: 58.975483\n",
            " ********* validation accuracy:1.0 validation loss: 0.005690787\n",
            "EPOCH 8.0\n",
            " train accuracy:0.9256727train loss: 59.802765\n",
            " ********* validation accuracy:1.0 validation loss: 0.0047561377\n",
            "EPOCH 9.0\n",
            " train accuracy:0.92570907train loss: 60.522808\n",
            " ********* validation accuracy:1.0 validation loss: 0.0040677404\n",
            "EPOCH 10.0\n",
            " train accuracy:0.92570907train loss: 61.16166\n",
            " ********* validation accuracy:1.0 validation loss: 0.0035416123\n",
            "EPOCH 11.0\n",
            " train accuracy:0.9257636train loss: 61.735767\n",
            " ********* validation accuracy:1.0 validation loss: 0.0031277575\n",
            "EPOCH 12.0\n",
            " train accuracy:0.9258train loss: 62.253716\n",
            " ********* validation accuracy:1.0 validation loss: 0.0027945302\n",
            "EPOCH 13.0\n",
            " train accuracy:0.9258364train loss: 62.727356\n",
            " ********* validation accuracy:1.0 validation loss: 0.002521332\n",
            "EPOCH 14.0\n",
            " train accuracy:0.9258364train loss: 63.163506\n",
            " ********* validation accuracy:1.0 validation loss: 0.002293412\n",
            "EPOCH 15.0\n",
            " train accuracy:0.9258909train loss: 63.566597\n",
            " ********* validation accuracy:1.0 validation loss: 0.0021007166\n",
            "EPOCH 16.0\n",
            " train accuracy:0.9258182train loss: 63.94214\n",
            " ********* validation accuracy:1.0 validation loss: 0.0019356909\n",
            "EPOCH 17.0\n",
            " train accuracy:0.9259091train loss: 64.293434\n",
            " ********* validation accuracy:1.0 validation loss: 0.0017930685\n",
            "EPOCH 18.0\n",
            " train accuracy:0.92587274train loss: 64.62333\n",
            " ********* validation accuracy:1.0 validation loss: 0.0016686354\n",
            "EPOCH 19.0\n",
            " train accuracy:0.9258909train loss: 64.933105\n",
            " ********* validation accuracy:1.0 validation loss: 0.0015594146\n",
            "EPOCH 20.0\n",
            " train accuracy:0.92596364train loss: 65.22563\n",
            " ********* validation accuracy:1.0 validation loss: 0.0014627922\n",
            "EPOCH 21.0\n",
            " train accuracy:0.92596364train loss: 65.502914\n",
            " ********* validation accuracy:1.0 validation loss: 0.0013765807\n",
            "EPOCH 22.0\n",
            " train accuracy:0.9259818train loss: 65.76727\n",
            " ********* validation accuracy:1.0 validation loss: 0.0012993213\n",
            "EPOCH 23.0\n",
            " train accuracy:0.92605454train loss: 66.01955\n",
            " ********* validation accuracy:1.0 validation loss: 0.0012297895\n",
            "EPOCH 24.0\n",
            " train accuracy:0.92605454train loss: 66.26007\n",
            " ********* validation accuracy:1.0 validation loss: 0.00116686\n",
            "EPOCH 25.0\n",
            " train accuracy:0.92605454train loss: 66.49047\n",
            " ********* validation accuracy:1.0 validation loss: 0.0011096844\n",
            "EPOCH 26.0\n",
            " train accuracy:0.9260909train loss: 66.71113\n",
            " ********* validation accuracy:1.0 validation loss: 0.0010573833\n",
            "EPOCH 27.0\n",
            " train accuracy:0.92612725train loss: 66.922905\n",
            " ********* validation accuracy:1.0 validation loss: 0.0010095396\n",
            "EPOCH 28.0\n",
            " train accuracy:0.9261091train loss: 67.12696\n",
            " ********* validation accuracy:1.0 validation loss: 0.000965474\n",
            "EPOCH 29.0\n",
            " train accuracy:0.92614543train loss: 67.3238\n",
            " ********* validation accuracy:1.0 validation loss: 0.0009248911\n",
            "EPOCH 30.0\n",
            " train accuracy:0.9261818train loss: 67.51365\n",
            " ********* validation accuracy:1.0 validation loss: 0.0008873735\n",
            "EPOCH 31.0\n",
            " train accuracy:0.9261818train loss: 67.69705\n",
            " ********* validation accuracy:1.0 validation loss: 0.0008525066\n",
            "EPOCH 32.0\n",
            " train accuracy:0.9262train loss: 67.874535\n",
            " ********* validation accuracy:1.0 validation loss: 0.0008201712\n",
            "EPOCH 33.0\n",
            " train accuracy:0.9261818train loss: 68.04659\n",
            " ********* validation accuracy:1.0 validation loss: 0.0007899407\n",
            "EPOCH 34.0\n",
            " train accuracy:0.9261818train loss: 68.21338\n",
            " ********* validation accuracy:1.0 validation loss: 0.00076183904\n",
            "EPOCH 35.0\n",
            " train accuracy:0.92621815train loss: 68.375435\n",
            " ********* validation accuracy:1.0 validation loss: 0.00073548214\n",
            "EPOCH 36.0\n",
            " train accuracy:0.9261818train loss: 68.53282\n",
            " ********* validation accuracy:1.0 validation loss: 0.0007107653\n",
            "EPOCH 37.0\n",
            " train accuracy:0.9261818train loss: 68.68579\n",
            " ********* validation accuracy:1.0 validation loss: 0.0006875313\n",
            "EPOCH 38.0\n",
            " train accuracy:0.92614543train loss: 68.834236\n",
            " ********* validation accuracy:1.0 validation loss: 0.0006656656\n",
            "EPOCH 39.0\n",
            " train accuracy:0.92614543train loss: 68.979004\n",
            " ********* validation accuracy:1.0 validation loss: 0.00064505136\n",
            "EPOCH 40.0\n",
            " train accuracy:0.92621815train loss: 69.11989\n",
            " ********* validation accuracy:1.0 validation loss: 0.00062561955\n",
            "EPOCH 41.0\n",
            " train accuracy:0.9261818train loss: 69.25721\n",
            " ********* validation accuracy:1.0 validation loss: 0.0006072343\n",
            "EPOCH 42.0\n",
            " train accuracy:0.92621815train loss: 69.39065\n",
            " ********* validation accuracy:1.0 validation loss: 0.0005899361\n",
            "EPOCH 43.0\n",
            " train accuracy:0.9262train loss: 69.52151\n",
            " ********* validation accuracy:1.0 validation loss: 0.00057335536\n",
            "EPOCH 44.0\n",
            " train accuracy:0.9261818train loss: 69.648895\n",
            " ********* validation accuracy:1.0 validation loss: 0.0005576734\n",
            "EPOCH 45.0\n",
            " train accuracy:0.92621815train loss: 69.773605\n",
            " ********* validation accuracy:1.0 validation loss: 0.00054282823\n",
            "EPOCH 46.0\n",
            " train accuracy:0.9262364train loss: 69.8955\n",
            " ********* validation accuracy:1.0 validation loss: 0.0005287459\n",
            "EPOCH 47.0\n",
            " train accuracy:0.9262364train loss: 70.01483\n",
            " ********* validation accuracy:1.0 validation loss: 0.00051523803\n",
            "EPOCH 48.0\n",
            " train accuracy:0.9262546train loss: 70.13128\n",
            " ********* validation accuracy:1.0 validation loss: 0.0005023262\n",
            "EPOCH 49.0\n",
            " train accuracy:0.9262546train loss: 70.245285\n",
            " ********* validation accuracy:1.0 validation loss: 0.00049006514\n",
            "EPOCH 50.0\n",
            " train accuracy:0.9262364train loss: 70.35694\n",
            " ********* validation accuracy:1.0 validation loss: 0.00047834046\n",
            "EPOCH 51.0\n",
            " train accuracy:0.9262364train loss: 70.46619\n",
            " ********* validation accuracy:1.0 validation loss: 0.00046709023\n",
            "EPOCH 52.0\n",
            " train accuracy:0.92621815train loss: 70.57339\n",
            " ********* validation accuracy:1.0 validation loss: 0.0004563883\n",
            "EPOCH 53.0\n",
            " train accuracy:0.9261818train loss: 70.678566\n",
            " ********* validation accuracy:1.0 validation loss: 0.00044604635\n",
            "EPOCH 54.0\n",
            " train accuracy:0.9262train loss: 70.781746\n",
            " ********* validation accuracy:1.0 validation loss: 0.0004362598\n",
            "EPOCH 55.0\n",
            " train accuracy:0.9262364train loss: 70.88285\n",
            " ********* validation accuracy:1.0 validation loss: 0.00042674033\n",
            "EPOCH 56.0\n",
            " train accuracy:0.9262364train loss: 70.981804\n",
            " ********* validation accuracy:1.0 validation loss: 0.00041771194\n",
            "EPOCH 57.0\n",
            " train accuracy:0.92621815train loss: 71.07915\n",
            " ********* validation accuracy:1.0 validation loss: 0.0004089887\n",
            "EPOCH 58.0\n",
            " train accuracy:0.9262364train loss: 71.17499\n",
            " ********* validation accuracy:1.0 validation loss: 0.00040059682\n",
            "EPOCH 59.0\n",
            " train accuracy:0.9262364train loss: 71.26885\n",
            " ********* validation accuracy:1.0 validation loss: 0.00039255302\n",
            "EPOCH 60.0\n",
            " train accuracy:0.9262364train loss: 71.36137\n",
            " ********* validation accuracy:1.0 validation loss: 0.00038478096\n",
            "EPOCH 61.0\n",
            " train accuracy:0.9262364train loss: 71.452484\n",
            " ********* validation accuracy:1.0 validation loss: 0.00037727357\n",
            "EPOCH 62.0\n",
            " train accuracy:0.92627275train loss: 71.54226\n",
            " ********* validation accuracy:1.0 validation loss: 0.00037004508\n",
            "EPOCH 63.0\n",
            " train accuracy:0.9262909train loss: 71.63061\n",
            " ********* validation accuracy:1.0 validation loss: 0.0003630097\n",
            "EPOCH 64.0\n",
            " train accuracy:0.92627275train loss: 71.71736\n",
            " ********* validation accuracy:1.0 validation loss: 0.0003563343\n",
            "EPOCH 65.0\n",
            " train accuracy:0.92627275train loss: 71.80268\n",
            " ********* validation accuracy:1.0 validation loss: 0.00034978526\n",
            "EPOCH 66.0\n",
            " train accuracy:0.9262364train loss: 71.88679\n",
            " ********* validation accuracy:1.0 validation loss: 0.00034350087\n",
            "EPOCH 67.0\n",
            " train accuracy:0.92627275train loss: 71.96928\n",
            " ********* validation accuracy:1.0 validation loss: 0.00033741666\n",
            "EPOCH 68.0\n",
            " train accuracy:0.9263091train loss: 72.05051\n",
            " ********* validation accuracy:1.0 validation loss: 0.000331466\n",
            "EPOCH 69.0\n",
            " train accuracy:0.9263091train loss: 72.13046\n",
            " ********* validation accuracy:1.0 validation loss: 0.0003258539\n",
            "EPOCH 70.0\n",
            " train accuracy:0.9262909train loss: 72.209274\n",
            " ********* validation accuracy:1.0 validation loss: 0.00032036335\n",
            "EPOCH 71.0\n",
            " train accuracy:0.9262909train loss: 72.28687\n",
            " ********* validation accuracy:1.0 validation loss: 0.0003150373\n",
            "EPOCH 72.0\n",
            " train accuracy:0.9262909train loss: 72.36348\n",
            " ********* validation accuracy:1.0 validation loss: 0.0003098066\n",
            "EPOCH 73.0\n",
            " train accuracy:0.92627275train loss: 72.439316\n",
            " ********* validation accuracy:1.0 validation loss: 0.00030485966\n",
            "EPOCH 74.0\n",
            " train accuracy:0.9262909train loss: 72.51405\n",
            " ********* validation accuracy:1.0 validation loss: 0.00029987926\n",
            "EPOCH 75.0\n",
            " train accuracy:0.92627275train loss: 72.587616\n",
            " ********* validation accuracy:1.0 validation loss: 0.00029517547\n",
            "EPOCH 76.0\n",
            " train accuracy:0.92627275train loss: 72.66017\n",
            " ********* validation accuracy:1.0 validation loss: 0.00029061947\n",
            "EPOCH 77.0\n",
            " train accuracy:0.92627275train loss: 72.731606\n",
            " ********* validation accuracy:1.0 validation loss: 0.00028617552\n",
            "EPOCH 78.0\n",
            " train accuracy:0.92627275train loss: 72.802025\n",
            " ********* validation accuracy:1.0 validation loss: 0.00028179117\n",
            "EPOCH 79.0\n",
            " train accuracy:0.9262909train loss: 72.87149\n",
            " ********* validation accuracy:1.0 validation loss: 0.00027758803\n",
            "EPOCH 80.0\n",
            " train accuracy:0.9262909train loss: 72.94009\n",
            " ********* validation accuracy:1.0 validation loss: 0.00027347304\n",
            "EPOCH 81.0\n",
            " train accuracy:0.92627275train loss: 73.00791\n",
            " ********* validation accuracy:1.0 validation loss: 0.00026948444\n",
            "EPOCH 82.0\n",
            " train accuracy:0.9263273train loss: 73.07495\n",
            " ********* validation accuracy:1.0 validation loss: 0.00026558645\n",
            "EPOCH 83.0\n",
            " train accuracy:0.9263091train loss: 73.14083\n",
            " ********* validation accuracy:1.0 validation loss: 0.00026183866\n",
            "EPOCH 84.0\n",
            " train accuracy:0.9263273train loss: 73.205894\n",
            " ********* validation accuracy:1.0 validation loss: 0.0002581409\n",
            "EPOCH 85.0\n",
            " train accuracy:0.9263273train loss: 73.27026\n",
            " ********* validation accuracy:1.0 validation loss: 0.00025454804\n",
            "EPOCH 86.0\n",
            " train accuracy:0.9263091train loss: 73.333916\n",
            " ********* validation accuracy:1.0 validation loss: 0.00025111495\n",
            "EPOCH 87.0\n",
            " train accuracy:0.9263091train loss: 73.39676\n",
            " ********* validation accuracy:1.0 validation loss: 0.0002476985\n",
            "EPOCH 88.0\n",
            " train accuracy:0.9263091train loss: 73.45888\n",
            " ********* validation accuracy:1.0 validation loss: 0.00024440367\n",
            "EPOCH 89.0\n",
            " train accuracy:0.9263273train loss: 73.520325\n",
            " ********* validation accuracy:1.0 validation loss: 0.00024118752\n",
            "EPOCH 90.0\n",
            " train accuracy:0.9263273train loss: 73.58076\n",
            " ********* validation accuracy:1.0 validation loss: 0.00023797613\n",
            "EPOCH 91.0\n",
            " train accuracy:0.92634547train loss: 73.6406\n",
            " ********* validation accuracy:1.0 validation loss: 0.0002348863\n",
            "EPOCH 92.0\n",
            " train accuracy:0.92636365train loss: 73.699844\n",
            " ********* validation accuracy:1.0 validation loss: 0.00023194436\n",
            "EPOCH 93.0\n",
            " train accuracy:0.9263818train loss: 73.758095\n",
            " ********* validation accuracy:1.0 validation loss: 0.000229019\n",
            "EPOCH 94.0\n",
            " train accuracy:0.9263818train loss: 73.81568\n",
            " ********* validation accuracy:1.0 validation loss: 0.00022616048\n",
            "EPOCH 95.0\n",
            " train accuracy:0.92634547train loss: 73.872665\n",
            " ********* validation accuracy:1.0 validation loss: 0.00022336154\n",
            "EPOCH 96.0\n",
            " train accuracy:0.92634547train loss: 73.92911\n",
            " ********* validation accuracy:1.0 validation loss: 0.00022062934\n",
            "EPOCH 97.0\n",
            " train accuracy:0.92634547train loss: 73.98515\n",
            " ********* validation accuracy:1.0 validation loss: 0.0002179043\n",
            "EPOCH 98.0\n",
            " train accuracy:0.92634547train loss: 74.04063\n",
            " ********* validation accuracy:1.0 validation loss: 0.00021526744\n",
            "EPOCH 99.0\n",
            " train accuracy:0.92634547train loss: 74.09561\n",
            " ********* validation accuracy:1.0 validation loss: 0.00021275698\n",
            "EPOCH 100.0\n",
            " train accuracy:0.9263091train loss: 74.149994\n",
            " ********* validation accuracy:1.0 validation loss: 0.00021030848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MGoXcNh0yCI_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mSsJprzhU3CP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "pN119AN4U1Lk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0c34fd0-450b-4b47-cc8b-621a9b907343"
      },
      "cell_type": "code",
      "source": [
        "a_test, c_test  = sess.run([accuracy, cross_entropy], feed_dict={X: x_test, y: y_test})\n",
        "\n",
        "print('Test accuracy is: ', (\"%.2f\"%(a_test*100))+'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is:  92.95%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tdsl7Fc9VIMj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Introduce learning rate decay"
      ]
    },
    {
      "metadata": {
        "id": "NP35q0iBW8h1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Computational graph"
      ]
    },
    {
      "metadata": {
        "id": "AW10JPzZW5qu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create computational graph\n",
        "\n",
        "# input \n",
        "X = tf.placeholder(tf.float32, [None,784])\n",
        "# labels (onehot encoded)\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "# step for variable learning rate\n",
        "step_val = tf.placeholder(tf.int32)\n",
        "\n",
        "''' First hidden layer with 200 neurons'''\n",
        "####################### START CODE #############################\n",
        "# weights 1\n",
        "W1 = tf.Variable(tf.truncated_normal([784, 200], stddev=0.1))\n",
        "# biases 1\n",
        "b1 = None\n",
        "\n",
        "# weigthed sum\n",
        "z1 = None\n",
        "\n",
        "#  activation\n",
        "h1 = tf.nn.relu(z1)\n",
        "####################### END #############################\n",
        "\n",
        "''' Second hidden layer with 100 neurons'''\n",
        "################## START CODE #########################\n",
        "# weights 1\n",
        "W2 = None\n",
        "# biases 1\n",
        "b2 = None\n",
        "\n",
        "# weigthed sum\n",
        "z2 = None\n",
        "# activation\n",
        "h2 = tf.nn.relu(z2)\n",
        "\n",
        "####################### END #############################\n",
        "\n",
        "''' third Layer with 60 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W3 = tf.Variable(tf.truncated_normal([100, 60], stddev=0.1))\n",
        "# biases 2\n",
        "b3 = None\n",
        "\n",
        "# weigthed sum\n",
        "z3 = None\n",
        "\n",
        "# activation\n",
        "h3 = None\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fourth Layer with 30 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W4 = None\n",
        "# biases 2\n",
        "b4 = tf.Variable(tf.zeros([30]))\n",
        "\n",
        "# weigthed sum\n",
        "z4 = None\n",
        "\n",
        "# activation \n",
        "h4 = None\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fifth/output Layer with 10 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W5 = None\n",
        "# biases 2\n",
        "b5 = None\n",
        "# weigthed sum\n",
        "z5 = None\n",
        "\n",
        "# softmax activation (optional)\n",
        "h5 = tf.nn.softmax(z5)\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# cross-entropy loss function (= -sum(yi * log(hi)) )\n",
        "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
        "# problems with log(0) which is NaN\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=z5, labels=y)\n",
        "cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "################### END ###############################\n",
        "\n",
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "correct_prediction = tf.equal(tf.argmax(h5, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# training\n",
        "################# START CODE ########################\n",
        "# the learning rate is: # 0.0001 + 0.003 * (1/e)^(step/2000)), i.e. exponential decay from 0.003->0.0001\n",
        "lr = 0.0001 +  tf.train.exponential_decay(0.003, step_val, 2000, 1/math.e)\n",
        "train_step = None\n",
        "\n",
        "################# END ###############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_r9kiYMOXCFK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start Session"
      ]
    },
    {
      "metadata": {
        "id": "g8Z-jkTiXBGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Start session\n",
        "\n",
        "# initialize all variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vl4YPXlrXRNc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train & visualize train/val loss and accuracy"
      ]
    },
    {
      "metadata": {
        "id": "k-KAZHs4XE_I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5227
        },
        "outputId": "0f45a733-4250-44df-dd02-9a792068d4b6"
      },
      "cell_type": "code",
      "source": [
        "history = training(x_train, y_train, x_val, y_val, sess, epochs=100, step=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1.0\n",
            " train accuracy:0.95065457train loss: 16.215124\n",
            " ********* validation accuracy:0.9566 validation loss: 15.88669\n",
            "EPOCH 2.0\n",
            " train accuracy:0.9719273train loss: 9.256859\n",
            " ********* validation accuracy:0.9666 validation loss: 11.084019\n",
            "EPOCH 3.0\n",
            " train accuracy:0.9794545train loss: 6.580917\n",
            " ********* validation accuracy:0.9722 validation loss: 9.625569\n",
            "EPOCH 4.0\n",
            " train accuracy:0.9851818train loss: 4.839835\n",
            " ********* validation accuracy:0.9752 validation loss: 8.802889\n",
            "EPOCH 5.0\n",
            " train accuracy:0.9890364train loss: 3.660979\n",
            " ********* validation accuracy:0.9766 validation loss: 8.433773\n",
            "EPOCH 6.0\n",
            " train accuracy:0.9917273train loss: 2.9334877\n",
            " ********* validation accuracy:0.9776 validation loss: 8.303792\n",
            "EPOCH 7.0\n",
            " train accuracy:0.99374545train loss: 2.4221084\n",
            " ********* validation accuracy:0.9778 validation loss: 8.345439\n",
            "EPOCH 8.0\n",
            " train accuracy:0.99485457train loss: 2.0677953\n",
            " ********* validation accuracy:0.9784 validation loss: 8.4098625\n",
            "EPOCH 9.0\n",
            " train accuracy:0.99576366train loss: 1.81763\n",
            " ********* validation accuracy:0.9784 validation loss: 8.476338\n",
            "EPOCH 10.0\n",
            " train accuracy:0.9964727train loss: 1.6343076\n",
            " ********* validation accuracy:0.9782 validation loss: 8.490812\n",
            "EPOCH 11.0\n",
            " train accuracy:0.9968727train loss: 1.4969852\n",
            " ********* validation accuracy:0.9788 validation loss: 8.527338\n",
            "EPOCH 12.0\n",
            " train accuracy:0.99718183train loss: 1.3883063\n",
            " ********* validation accuracy:0.9786 validation loss: 8.552726\n",
            "EPOCH 13.0\n",
            " train accuracy:0.9974727train loss: 1.2980288\n",
            " ********* validation accuracy:0.979 validation loss: 8.580636\n",
            "EPOCH 14.0\n",
            " train accuracy:0.9977273train loss: 1.2221942\n",
            " ********* validation accuracy:0.979 validation loss: 8.606914\n",
            "EPOCH 15.0\n",
            " train accuracy:0.9978909train loss: 1.1583234\n",
            " ********* validation accuracy:0.979 validation loss: 8.637766\n",
            "EPOCH 16.0\n",
            " train accuracy:0.9980909train loss: 1.103913\n",
            " ********* validation accuracy:0.9788 validation loss: 8.66246\n",
            "EPOCH 17.0\n",
            " train accuracy:0.99823636train loss: 1.0575495\n",
            " ********* validation accuracy:0.9788 validation loss: 8.698398\n",
            "EPOCH 18.0\n",
            " train accuracy:0.9984364train loss: 1.0155276\n",
            " ********* validation accuracy:0.979 validation loss: 8.738387\n",
            "EPOCH 19.0\n",
            " train accuracy:0.99854547train loss: 0.977822\n",
            " ********* validation accuracy:0.9788 validation loss: 8.767621\n",
            "EPOCH 20.0\n",
            " train accuracy:0.9986182train loss: 0.94468987\n",
            " ********* validation accuracy:0.9788 validation loss: 8.803491\n",
            "EPOCH 21.0\n",
            " train accuracy:0.99863636train loss: 0.91348815\n",
            " ********* validation accuracy:0.9788 validation loss: 8.841523\n",
            "EPOCH 22.0\n",
            " train accuracy:0.99872726train loss: 0.8838453\n",
            " ********* validation accuracy:0.9788 validation loss: 8.874187\n",
            "EPOCH 23.0\n",
            " train accuracy:0.99881816train loss: 0.8568379\n",
            " ********* validation accuracy:0.9788 validation loss: 8.912815\n",
            "EPOCH 24.0\n",
            " train accuracy:0.9989091train loss: 0.83044404\n",
            " ********* validation accuracy:0.9792 validation loss: 8.947603\n",
            "EPOCH 25.0\n",
            " train accuracy:0.9989455train loss: 0.8070327\n",
            " ********* validation accuracy:0.9792 validation loss: 8.984089\n",
            "EPOCH 26.0\n",
            " train accuracy:0.999train loss: 0.78270966\n",
            " ********* validation accuracy:0.9792 validation loss: 9.021018\n",
            "EPOCH 27.0\n",
            " train accuracy:0.9990909train loss: 0.7606782\n",
            " ********* validation accuracy:0.9784 validation loss: 9.060518\n",
            "EPOCH 28.0\n",
            " train accuracy:0.99912727train loss: 0.73819023\n",
            " ********* validation accuracy:0.9786 validation loss: 9.094081\n",
            "EPOCH 29.0\n",
            " train accuracy:0.9991818train loss: 0.71739334\n",
            " ********* validation accuracy:0.9784 validation loss: 9.131963\n",
            "EPOCH 30.0\n",
            " train accuracy:0.99921817train loss: 0.69684875\n",
            " ********* validation accuracy:0.9786 validation loss: 9.165163\n",
            "EPOCH 31.0\n",
            " train accuracy:0.99923635train loss: 0.6767131\n",
            " ********* validation accuracy:0.9788 validation loss: 9.193018\n",
            "EPOCH 32.0\n",
            " train accuracy:0.9992909train loss: 0.65826297\n",
            " ********* validation accuracy:0.9788 validation loss: 9.233976\n",
            "EPOCH 33.0\n",
            " train accuracy:0.9993273train loss: 0.63994074\n",
            " ********* validation accuracy:0.979 validation loss: 9.266002\n",
            "EPOCH 34.0\n",
            " train accuracy:0.9993455train loss: 0.6218515\n",
            " ********* validation accuracy:0.9788 validation loss: 9.303282\n",
            "EPOCH 35.0\n",
            " train accuracy:0.9994train loss: 0.6046541\n",
            " ********* validation accuracy:0.9788 validation loss: 9.338615\n",
            "EPOCH 36.0\n",
            " train accuracy:0.9994train loss: 0.58836883\n",
            " ********* validation accuracy:0.9788 validation loss: 9.373158\n",
            "EPOCH 37.0\n",
            " train accuracy:0.9994train loss: 0.5727953\n",
            " ********* validation accuracy:0.9788 validation loss: 9.403711\n",
            "EPOCH 38.0\n",
            " train accuracy:0.9994364train loss: 0.5571807\n",
            " ********* validation accuracy:0.9786 validation loss: 9.440565\n",
            "EPOCH 39.0\n",
            " train accuracy:0.9994909train loss: 0.5425223\n",
            " ********* validation accuracy:0.9786 validation loss: 9.475339\n",
            "EPOCH 40.0\n",
            " train accuracy:0.9994909train loss: 0.5284677\n",
            " ********* validation accuracy:0.9788 validation loss: 9.506289\n",
            "EPOCH 41.0\n",
            " train accuracy:0.9994909train loss: 0.5145154\n",
            " ********* validation accuracy:0.9786 validation loss: 9.541364\n",
            "EPOCH 42.0\n",
            " train accuracy:0.9995091train loss: 0.50171643\n",
            " ********* validation accuracy:0.9788 validation loss: 9.574503\n",
            "EPOCH 43.0\n",
            " train accuracy:0.99954545train loss: 0.488745\n",
            " ********* validation accuracy:0.9788 validation loss: 9.6059475\n",
            "EPOCH 44.0\n",
            " train accuracy:0.99954545train loss: 0.47672236\n",
            " ********* validation accuracy:0.9788 validation loss: 9.638057\n",
            "EPOCH 45.0\n",
            " train accuracy:0.99954545train loss: 0.46518078\n",
            " ********* validation accuracy:0.9788 validation loss: 9.672674\n",
            "EPOCH 46.0\n",
            " train accuracy:0.99954545train loss: 0.45353052\n",
            " ********* validation accuracy:0.9788 validation loss: 9.706282\n",
            "EPOCH 47.0\n",
            " train accuracy:0.9995818train loss: 0.44301906\n",
            " ********* validation accuracy:0.9788 validation loss: 9.738011\n",
            "EPOCH 48.0\n",
            " train accuracy:0.9996182train loss: 0.43249097\n",
            " ********* validation accuracy:0.979 validation loss: 9.774426\n",
            "EPOCH 49.0\n",
            " train accuracy:0.99963635train loss: 0.42256522\n",
            " ********* validation accuracy:0.979 validation loss: 9.802956\n",
            "EPOCH 50.0\n",
            " train accuracy:0.99963635train loss: 0.4125806\n",
            " ********* validation accuracy:0.9788 validation loss: 9.835783\n",
            "EPOCH 51.0\n",
            " train accuracy:0.9996727train loss: 0.4037022\n",
            " ********* validation accuracy:0.9786 validation loss: 9.869482\n",
            "EPOCH 52.0\n",
            " train accuracy:0.9996909train loss: 0.39467528\n",
            " ********* validation accuracy:0.979 validation loss: 9.893092\n",
            "EPOCH 53.0\n",
            " train accuracy:0.99970907train loss: 0.38568887\n",
            " ********* validation accuracy:0.979 validation loss: 9.9301815\n",
            "EPOCH 54.0\n",
            " train accuracy:0.9997454train loss: 0.37777334\n",
            " ********* validation accuracy:0.979 validation loss: 9.959039\n",
            "EPOCH 55.0\n",
            " train accuracy:0.9997454train loss: 0.36958736\n",
            " ********* validation accuracy:0.979 validation loss: 9.986043\n",
            "EPOCH 56.0\n",
            " train accuracy:0.9997454train loss: 0.3619952\n",
            " ********* validation accuracy:0.979 validation loss: 10.02182\n",
            "EPOCH 57.0\n",
            " train accuracy:0.99978185train loss: 0.35444263\n",
            " ********* validation accuracy:0.979 validation loss: 10.045941\n",
            "EPOCH 58.0\n",
            " train accuracy:0.9998train loss: 0.34752634\n",
            " ********* validation accuracy:0.979 validation loss: 10.079581\n",
            "EPOCH 59.0\n",
            " train accuracy:0.9998364train loss: 0.34038943\n",
            " ********* validation accuracy:0.979 validation loss: 10.108484\n",
            "EPOCH 60.0\n",
            " train accuracy:0.9998364train loss: 0.33372784\n",
            " ********* validation accuracy:0.979 validation loss: 10.137882\n",
            "EPOCH 61.0\n",
            " train accuracy:0.9998364train loss: 0.32742444\n",
            " ********* validation accuracy:0.979 validation loss: 10.161833\n",
            "EPOCH 62.0\n",
            " train accuracy:0.9998364train loss: 0.32107514\n",
            " ********* validation accuracy:0.979 validation loss: 10.196353\n",
            "EPOCH 63.0\n",
            " train accuracy:0.99985456train loss: 0.31513533\n",
            " ********* validation accuracy:0.9788 validation loss: 10.218748\n",
            "EPOCH 64.0\n",
            " train accuracy:0.99987274train loss: 0.3094554\n",
            " ********* validation accuracy:0.979 validation loss: 10.248678\n",
            "EPOCH 65.0\n",
            " train accuracy:0.99987274train loss: 0.30375883\n",
            " ********* validation accuracy:0.979 validation loss: 10.281156\n",
            "EPOCH 66.0\n",
            " train accuracy:0.99987274train loss: 0.29817817\n",
            " ********* validation accuracy:0.979 validation loss: 10.304914\n",
            "EPOCH 67.0\n",
            " train accuracy:0.9998909train loss: 0.29296464\n",
            " ********* validation accuracy:0.979 validation loss: 10.33407\n",
            "EPOCH 68.0\n",
            " train accuracy:0.9998909train loss: 0.28791532\n",
            " ********* validation accuracy:0.979 validation loss: 10.360847\n",
            "EPOCH 69.0\n",
            " train accuracy:0.9998909train loss: 0.28297597\n",
            " ********* validation accuracy:0.979 validation loss: 10.389462\n",
            "EPOCH 70.0\n",
            " train accuracy:0.9998909train loss: 0.27809605\n",
            " ********* validation accuracy:0.979 validation loss: 10.41376\n",
            "EPOCH 71.0\n",
            " train accuracy:0.9999091train loss: 0.27364618\n",
            " ********* validation accuracy:0.979 validation loss: 10.440547\n",
            "EPOCH 72.0\n",
            " train accuracy:0.9999091train loss: 0.26937538\n",
            " ********* validation accuracy:0.979 validation loss: 10.463956\n",
            "EPOCH 73.0\n",
            " train accuracy:0.9999091train loss: 0.26496994\n",
            " ********* validation accuracy:0.979 validation loss: 10.490062\n",
            "EPOCH 74.0\n",
            " train accuracy:0.9999091train loss: 0.26092505\n",
            " ********* validation accuracy:0.979 validation loss: 10.518574\n",
            "EPOCH 75.0\n",
            " train accuracy:0.9999091train loss: 0.25687853\n",
            " ********* validation accuracy:0.979 validation loss: 10.539752\n",
            "EPOCH 76.0\n",
            " train accuracy:0.9999091train loss: 0.2530785\n",
            " ********* validation accuracy:0.979 validation loss: 10.568369\n",
            "EPOCH 77.0\n",
            " train accuracy:0.9999091train loss: 0.24929766\n",
            " ********* validation accuracy:0.979 validation loss: 10.58976\n",
            "EPOCH 78.0\n",
            " train accuracy:0.9999091train loss: 0.24575828\n",
            " ********* validation accuracy:0.979 validation loss: 10.620374\n",
            "EPOCH 79.0\n",
            " train accuracy:0.9999091train loss: 0.24210066\n",
            " ********* validation accuracy:0.979 validation loss: 10.641222\n",
            "EPOCH 80.0\n",
            " train accuracy:0.9999091train loss: 0.23872021\n",
            " ********* validation accuracy:0.979 validation loss: 10.664019\n",
            "EPOCH 81.0\n",
            " train accuracy:0.9999091train loss: 0.23544869\n",
            " ********* validation accuracy:0.979 validation loss: 10.692378\n",
            "EPOCH 82.0\n",
            " train accuracy:0.9999091train loss: 0.23216093\n",
            " ********* validation accuracy:0.979 validation loss: 10.714521\n",
            "EPOCH 83.0\n",
            " train accuracy:0.9999091train loss: 0.22905263\n",
            " ********* validation accuracy:0.9788 validation loss: 10.738111\n",
            "EPOCH 84.0\n",
            " train accuracy:0.9999091train loss: 0.22602217\n",
            " ********* validation accuracy:0.9788 validation loss: 10.761091\n",
            "EPOCH 85.0\n",
            " train accuracy:0.9999273train loss: 0.22314347\n",
            " ********* validation accuracy:0.9788 validation loss: 10.789223\n",
            "EPOCH 86.0\n",
            " train accuracy:0.9999273train loss: 0.2202455\n",
            " ********* validation accuracy:0.979 validation loss: 10.809972\n",
            "EPOCH 87.0\n",
            " train accuracy:0.9999273train loss: 0.21748857\n",
            " ********* validation accuracy:0.9786 validation loss: 10.832826\n",
            "EPOCH 88.0\n",
            " train accuracy:0.9999273train loss: 0.21480636\n",
            " ********* validation accuracy:0.9786 validation loss: 10.855959\n",
            "EPOCH 89.0\n",
            " train accuracy:0.9999273train loss: 0.21223855\n",
            " ********* validation accuracy:0.9786 validation loss: 10.878963\n",
            "EPOCH 90.0\n",
            " train accuracy:0.9999273train loss: 0.20961522\n",
            " ********* validation accuracy:0.9786 validation loss: 10.905779\n",
            "EPOCH 91.0\n",
            " train accuracy:0.9999273train loss: 0.20714612\n",
            " ********* validation accuracy:0.9786 validation loss: 10.926858\n",
            "EPOCH 92.0\n",
            " train accuracy:0.9999273train loss: 0.2047655\n",
            " ********* validation accuracy:0.9786 validation loss: 10.948891\n",
            "EPOCH 93.0\n",
            " train accuracy:0.9999273train loss: 0.20237142\n",
            " ********* validation accuracy:0.9786 validation loss: 10.970618\n",
            "EPOCH 94.0\n",
            " train accuracy:0.9999273train loss: 0.2000216\n",
            " ********* validation accuracy:0.9786 validation loss: 10.996255\n",
            "EPOCH 95.0\n",
            " train accuracy:0.9999273train loss: 0.19780186\n",
            " ********* validation accuracy:0.9786 validation loss: 11.019517\n",
            "EPOCH 96.0\n",
            " train accuracy:0.9999273train loss: 0.1955963\n",
            " ********* validation accuracy:0.9786 validation loss: 11.043874\n",
            "EPOCH 97.0\n",
            " train accuracy:0.9999273train loss: 0.19349313\n",
            " ********* validation accuracy:0.9786 validation loss: 11.06233\n",
            "EPOCH 98.0\n",
            " train accuracy:0.9999273train loss: 0.19148521\n",
            " ********* validation accuracy:0.9786 validation loss: 11.083577\n",
            "EPOCH 99.0\n",
            " train accuracy:0.99994546train loss: 0.18941501\n",
            " ********* validation accuracy:0.9786 validation loss: 11.106511\n",
            "EPOCH 100.0\n",
            " train accuracy:0.99994546train loss: 0.18750487\n",
            " ********* validation accuracy:0.9786 validation loss: 11.129354\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KkeyHimTyEOZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tpDp3DSPXLQa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "l6IdYzU7XKVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19d249fe-6f25-4c37-e126-0b04ad1f97fa"
      },
      "cell_type": "code",
      "source": [
        "a_test, c_test  = sess.run([accuracy, cross_entropy], feed_dict={X: x_test, y: y_test})\n",
        "\n",
        "print('Test accuracy is: ', (\"%.2f\"%(a_test*100))+'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is:  97.68%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e-TnuKZh26wH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "16lHWmTLZ4yz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 8. Use dropout"
      ]
    },
    {
      "metadata": {
        "id": "_lj9seh4aWKr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Computational graph"
      ]
    },
    {
      "metadata": {
        "id": "xbZEABFKaUHq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Create computational graph\n",
        "\n",
        "# input \n",
        "X = tf.placeholder(tf.float32, [None,784])\n",
        "# labels (onehot encoded)\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "# step for variable learning rate\n",
        "step_val = tf.placeholder(tf.int32)\n",
        "\n",
        "# variable learning rate\n",
        "lr = tf.placeholder(tf.float32)\n",
        "# Probability of keeping a node during dropout = 1.0 at test time (no dropout) and 0.75 at training time\n",
        "pkeep_val = tf.placeholder(tf.float32)\n",
        "\n",
        "\n",
        "''' First hidden layer with 200 neurons'''\n",
        "################## START CODE #########################\n",
        "# weights 1\n",
        "W1 = None\n",
        "# biases 1\n",
        "b1 = None\n",
        "\n",
        "# weigthed sum\n",
        "z1 = tf.matmul(X, W1) + b1\n",
        "\n",
        "#  activation\n",
        "h1 = None\n",
        "\n",
        "# dropout\n",
        "h1d = tf.nn.dropout(h1, pkeep_val)\n",
        "################## END #########################\n",
        "\n",
        "''' Second hidden layer with 100 neurons'''\n",
        "################## START CODE #########################\n",
        "# weights 1\n",
        "W2 = None\n",
        "# biases 1\n",
        "b2 = None\n",
        "\n",
        "# weigthed sum\n",
        "z2 = tf.matmul(h1d, W2) + b2\n",
        "\n",
        "# activation\n",
        "h2 = tf.nn.relu(z2)\n",
        "\n",
        "# dropout\n",
        "h2d = None\n",
        "\n",
        "\n",
        "####################### END #############################\n",
        "\n",
        "''' third Layer with 60 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W3 = tf.Variable(tf.truncated_normal([100, 60], stddev=0.1))\n",
        "# biases 2\n",
        "b3 = None\n",
        "\n",
        "# weigthed sum\n",
        "z3 = tf.matmul(h2d, W3) + b3\n",
        "\n",
        "# activation\n",
        "h3 = None\n",
        "\n",
        "# dropout\n",
        "h3d = None\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fourth Layer with 30 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W4 = None\n",
        "# biases 2\n",
        "b4 = tf.Variable(tf.zeros([30]))\n",
        "\n",
        "# weigthed sum\n",
        "z4 = None\n",
        "\n",
        "# activation \n",
        "h4 = None\n",
        "\n",
        "# dropout\n",
        "h4d = None\n",
        "\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "''' fifth/output Layer with 10 neurons'''\n",
        "##################### START CODE #########################\n",
        "# weights 2\n",
        "W5 = tf.Variable(tf.truncated_normal([30, 10], stddev=0.1))#None\n",
        "# biases 2\n",
        "b5 = None\n",
        "# weigthed sum\n",
        "z5 = None\n",
        "\n",
        "# softmax activation\n",
        "h5 = tf.nn.softmax(z5)\n",
        "\n",
        "#################### END ##################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# cross-entropy loss function (= -sum(yi * log(hi)) )\n",
        "# TensorFlow provides the softmax_cross_entropy_with_logits function to avoid numerical stability\n",
        "# problems with log(0) which is NaN\n",
        "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=z5, labels=y)\n",
        "cross_entropy = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "################### END ###############################\n",
        "\n",
        "# accuracy of the trained model, between 0 (worst) and 1 (best)\n",
        "correct_prediction = tf.equal(tf.argmax(h5, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# training\n",
        "################# START CODE ########################\n",
        "# the learning rate is: # 0.0001 + 0.003 * (1/e)^(step/2000)), i.e. exponential decay from 0.003->0.0001\n",
        "lr = 0.0001 +  tf.train.exponential_decay(0.003, step_val, 2000, 1/math.e)\n",
        "train_step = None\n",
        "\n",
        "\n",
        "################# END ###############################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GkYBhaiAac8F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Start session"
      ]
    },
    {
      "metadata": {
        "id": "MgY9Nkwbab6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Start session\n",
        "\n",
        "# initialize all variables\n",
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RbwpERfsai8-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train & visualize train/val loss and accuracy"
      ]
    },
    {
      "metadata": {
        "id": "EXLkseb7ah-U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5227
        },
        "outputId": "04f8efb8-1cf7-48c8-e5cf-87f9c09a6b09"
      },
      "cell_type": "code",
      "source": [
        "history = training(x_train, y_train, x_val, y_val, sess, epochs=100, step=True, pkeep=0.75)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH 1.0\n",
            " train accuracy:0.12858182train loss: 2.288576\n",
            " ********* validation accuracy:0.1548 validation loss: 2.2787628\n",
            "EPOCH 2.0\n",
            " train accuracy:0.15125455train loss: 2.2737474\n",
            " ********* validation accuracy:0.237 validation loss: 2.2573707\n",
            "EPOCH 3.0\n",
            " train accuracy:0.17216364train loss: 2.2575464\n",
            " ********* validation accuracy:0.3158 validation loss: 2.2329862\n",
            "EPOCH 4.0\n",
            " train accuracy:0.19303636train loss: 2.23828\n",
            " ********* validation accuracy:0.367 validation loss: 2.2057352\n",
            "EPOCH 5.0\n",
            " train accuracy:0.21156363train loss: 2.217743\n",
            " ********* validation accuracy:0.4012 validation loss: 2.176915\n",
            "EPOCH 6.0\n",
            " train accuracy:0.22416364train loss: 2.1983018\n",
            " ********* validation accuracy:0.4182 validation loss: 2.1477358\n",
            "EPOCH 7.0\n",
            " train accuracy:0.237train loss: 2.1771755\n",
            " ********* validation accuracy:0.4292 validation loss: 2.1195092\n",
            "EPOCH 8.0\n",
            " train accuracy:0.24258181train loss: 2.1589847\n",
            " ********* validation accuracy:0.4388 validation loss: 2.0930855\n",
            "EPOCH 9.0\n",
            " train accuracy:0.2500909train loss: 2.1438236\n",
            " ********* validation accuracy:0.4474 validation loss: 2.0689237\n",
            "EPOCH 10.0\n",
            " train accuracy:0.2580182train loss: 2.1273606\n",
            " ********* validation accuracy:0.451 validation loss: 2.0470915\n",
            "EPOCH 11.0\n",
            " train accuracy:0.2599818train loss: 2.1136754\n",
            " ********* validation accuracy:0.4528 validation loss: 2.027394\n",
            "EPOCH 12.0\n",
            " train accuracy:0.26423636train loss: 2.1025908\n",
            " ********* validation accuracy:0.4566 validation loss: 2.0096214\n",
            "EPOCH 13.0\n",
            " train accuracy:0.27052727train loss: 2.087939\n",
            " ********* validation accuracy:0.4594 validation loss: 1.993455\n",
            "EPOCH 14.0\n",
            " train accuracy:0.27336365train loss: 2.077192\n",
            " ********* validation accuracy:0.4634 validation loss: 1.9785894\n",
            "EPOCH 15.0\n",
            " train accuracy:0.27661818train loss: 2.067372\n",
            " ********* validation accuracy:0.4656 validation loss: 1.9647884\n",
            "EPOCH 16.0\n",
            " train accuracy:0.27481818train loss: 2.0604534\n",
            " ********* validation accuracy:0.4684 validation loss: 1.9517893\n",
            "EPOCH 17.0\n",
            " train accuracy:0.27976364train loss: 2.052166\n",
            " ********* validation accuracy:0.4704 validation loss: 1.9393969\n",
            "EPOCH 18.0\n",
            " train accuracy:0.2812train loss: 2.0426211\n",
            " ********* validation accuracy:0.472 validation loss: 1.9274623\n",
            "EPOCH 19.0\n",
            " train accuracy:0.28405455train loss: 2.033117\n",
            " ********* validation accuracy:0.4732 validation loss: 1.9158721\n",
            "EPOCH 20.0\n",
            " train accuracy:0.28594545train loss: 2.026609\n",
            " ********* validation accuracy:0.4756 validation loss: 1.9045107\n",
            "EPOCH 21.0\n",
            " train accuracy:0.28627273train loss: 2.0172572\n",
            " ********* validation accuracy:0.4772 validation loss: 1.8933252\n",
            "EPOCH 22.0\n",
            " train accuracy:0.28907272train loss: 2.0086398\n",
            " ********* validation accuracy:0.4776 validation loss: 1.8822395\n",
            "EPOCH 23.0\n",
            " train accuracy:0.29432726train loss: 2.000495\n",
            " ********* validation accuracy:0.4794 validation loss: 1.8712422\n",
            "EPOCH 24.0\n",
            " train accuracy:0.2902train loss: 1.9967409\n",
            " ********* validation accuracy:0.4816 validation loss: 1.8602442\n",
            "EPOCH 25.0\n",
            " train accuracy:0.2924909train loss: 1.98959\n",
            " ********* validation accuracy:0.4838 validation loss: 1.84926\n",
            "EPOCH 26.0\n",
            " train accuracy:0.29418182train loss: 1.9825534\n",
            " ********* validation accuracy:0.4842 validation loss: 1.8383043\n",
            "EPOCH 27.0\n",
            " train accuracy:0.29614547train loss: 1.9747368\n",
            " ********* validation accuracy:0.4858 validation loss: 1.8273405\n",
            "EPOCH 28.0\n",
            " train accuracy:0.30032727train loss: 1.9658976\n",
            " ********* validation accuracy:0.4892 validation loss: 1.8163455\n",
            "EPOCH 29.0\n",
            " train accuracy:0.30027273train loss: 1.9579599\n",
            " ********* validation accuracy:0.4896 validation loss: 1.8053446\n",
            "EPOCH 30.0\n",
            " train accuracy:0.30127272train loss: 1.9505421\n",
            " ********* validation accuracy:0.492 validation loss: 1.7943391\n",
            "EPOCH 31.0\n",
            " train accuracy:0.3024train loss: 1.9442085\n",
            " ********* validation accuracy:0.495 validation loss: 1.783335\n",
            "EPOCH 32.0\n",
            " train accuracy:0.30763635train loss: 1.934872\n",
            " ********* validation accuracy:0.4978 validation loss: 1.7723\n",
            "EPOCH 33.0\n",
            " train accuracy:0.30774546train loss: 1.9253355\n",
            " ********* validation accuracy:0.5004 validation loss: 1.7612993\n",
            "EPOCH 34.0\n",
            " train accuracy:0.31072727train loss: 1.9176416\n",
            " ********* validation accuracy:0.5036 validation loss: 1.7503176\n",
            "EPOCH 35.0\n",
            " train accuracy:0.31203637train loss: 1.9127688\n",
            " ********* validation accuracy:0.5064 validation loss: 1.7393289\n",
            "EPOCH 36.0\n",
            " train accuracy:0.3136909train loss: 1.903127\n",
            " ********* validation accuracy:0.5098 validation loss: 1.728411\n",
            "EPOCH 37.0\n",
            " train accuracy:0.316train loss: 1.8971814\n",
            " ********* validation accuracy:0.5134 validation loss: 1.7175338\n",
            "EPOCH 38.0\n",
            " train accuracy:0.31843635train loss: 1.8875872\n",
            " ********* validation accuracy:0.5172 validation loss: 1.7066797\n",
            "EPOCH 39.0\n",
            " train accuracy:0.32041818train loss: 1.8796145\n",
            " ********* validation accuracy:0.5212 validation loss: 1.6958723\n",
            "EPOCH 40.0\n",
            " train accuracy:0.32263637train loss: 1.8725923\n",
            " ********* validation accuracy:0.5248 validation loss: 1.6851127\n",
            "EPOCH 41.0\n",
            " train accuracy:0.32458183train loss: 1.8698869\n",
            " ********* validation accuracy:0.527 validation loss: 1.6744317\n",
            "EPOCH 42.0\n",
            " train accuracy:0.3254train loss: 1.8612038\n",
            " ********* validation accuracy:0.5306 validation loss: 1.6638258\n",
            "EPOCH 43.0\n",
            " train accuracy:0.32405454train loss: 1.8549536\n",
            " ********* validation accuracy:0.5364 validation loss: 1.6533182\n",
            "EPOCH 44.0\n",
            " train accuracy:0.32921818train loss: 1.8467807\n",
            " ********* validation accuracy:0.5414 validation loss: 1.6428963\n",
            "EPOCH 45.0\n",
            " train accuracy:0.33167273train loss: 1.8370091\n",
            " ********* validation accuracy:0.5456 validation loss: 1.6325382\n",
            "EPOCH 46.0\n",
            " train accuracy:0.33154544train loss: 1.8323206\n",
            " ********* validation accuracy:0.549 validation loss: 1.6222872\n",
            "EPOCH 47.0\n",
            " train accuracy:0.33612728train loss: 1.823058\n",
            " ********* validation accuracy:0.5506 validation loss: 1.6121172\n",
            "EPOCH 48.0\n",
            " train accuracy:0.33572727train loss: 1.818177\n",
            " ********* validation accuracy:0.555 validation loss: 1.6020571\n",
            "EPOCH 49.0\n",
            " train accuracy:0.3394train loss: 1.8085097\n",
            " ********* validation accuracy:0.5598 validation loss: 1.5921063\n",
            "EPOCH 50.0\n",
            " train accuracy:0.3402train loss: 1.8012476\n",
            " ********* validation accuracy:0.563 validation loss: 1.5822276\n",
            "EPOCH 51.0\n",
            " train accuracy:0.34425455train loss: 1.7955601\n",
            " ********* validation accuracy:0.5658 validation loss: 1.5724663\n",
            "EPOCH 52.0\n",
            " train accuracy:0.34478182train loss: 1.7888974\n",
            " ********* validation accuracy:0.569 validation loss: 1.5628163\n",
            "EPOCH 53.0\n",
            " train accuracy:0.34821817train loss: 1.7806389\n",
            " ********* validation accuracy:0.5724 validation loss: 1.5532805\n",
            "EPOCH 54.0\n",
            " train accuracy:0.34801817train loss: 1.7762879\n",
            " ********* validation accuracy:0.5758 validation loss: 1.5438117\n",
            "EPOCH 55.0\n",
            " train accuracy:0.35230908train loss: 1.7640761\n",
            " ********* validation accuracy:0.5776 validation loss: 1.5344412\n",
            "EPOCH 56.0\n",
            " train accuracy:0.35403636train loss: 1.763149\n",
            " ********* validation accuracy:0.5806 validation loss: 1.5251949\n",
            "EPOCH 57.0\n",
            " train accuracy:0.357train loss: 1.7512228\n",
            " ********* validation accuracy:0.5844 validation loss: 1.516077\n",
            "EPOCH 58.0\n",
            " train accuracy:0.3569091train loss: 1.7487497\n",
            " ********* validation accuracy:0.5876 validation loss: 1.5070225\n",
            "EPOCH 59.0\n",
            " train accuracy:0.3588train loss: 1.7420652\n",
            " ********* validation accuracy:0.5906 validation loss: 1.4981072\n",
            "EPOCH 60.0\n",
            " train accuracy:0.36150908train loss: 1.7331889\n",
            " ********* validation accuracy:0.5934 validation loss: 1.4892985\n",
            "EPOCH 61.0\n",
            " train accuracy:0.36310908train loss: 1.7281449\n",
            " ********* validation accuracy:0.597 validation loss: 1.4805691\n",
            "EPOCH 62.0\n",
            " train accuracy:0.36743635train loss: 1.717533\n",
            " ********* validation accuracy:0.599 validation loss: 1.4719485\n",
            "EPOCH 63.0\n",
            " train accuracy:0.36498183train loss: 1.7197758\n",
            " ********* validation accuracy:0.6032 validation loss: 1.4634224\n",
            "EPOCH 64.0\n",
            " train accuracy:0.37154546train loss: 1.7055769\n",
            " ********* validation accuracy:0.605 validation loss: 1.4549972\n",
            "EPOCH 65.0\n",
            " train accuracy:0.37532726train loss: 1.6940131\n",
            " ********* validation accuracy:0.607 validation loss: 1.4466853\n",
            "EPOCH 66.0\n",
            " train accuracy:0.37732726train loss: 1.6917316\n",
            " ********* validation accuracy:0.609 validation loss: 1.4384726\n",
            "EPOCH 67.0\n",
            " train accuracy:0.37556362train loss: 1.6864631\n",
            " ********* validation accuracy:0.6114 validation loss: 1.430371\n",
            "EPOCH 68.0\n",
            " train accuracy:0.37903637train loss: 1.6802688\n",
            " ********* validation accuracy:0.613 validation loss: 1.4223378\n",
            "EPOCH 69.0\n",
            " train accuracy:0.38136363train loss: 1.6803799\n",
            " ********* validation accuracy:0.6164 validation loss: 1.414425\n",
            "EPOCH 70.0\n",
            " train accuracy:0.3814train loss: 1.6696755\n",
            " ********* validation accuracy:0.6176 validation loss: 1.4065998\n",
            "EPOCH 71.0\n",
            " train accuracy:0.38696364train loss: 1.6626613\n",
            " ********* validation accuracy:0.6186 validation loss: 1.3988829\n",
            "EPOCH 72.0\n",
            " train accuracy:0.38705453train loss: 1.6625254\n",
            " ********* validation accuracy:0.6214 validation loss: 1.3912313\n",
            "EPOCH 73.0\n",
            " train accuracy:0.3839273train loss: 1.6558237\n",
            " ********* validation accuracy:0.6244 validation loss: 1.3836823\n",
            "EPOCH 74.0\n",
            " train accuracy:0.3914909train loss: 1.6438247\n",
            " ********* validation accuracy:0.6268 validation loss: 1.3762121\n",
            "EPOCH 75.0\n",
            " train accuracy:0.3932182train loss: 1.6424083\n",
            " ********* validation accuracy:0.6286 validation loss: 1.3688402\n",
            "EPOCH 76.0\n",
            " train accuracy:0.39458182train loss: 1.6385154\n",
            " ********* validation accuracy:0.6306 validation loss: 1.3615814\n",
            "EPOCH 77.0\n",
            " train accuracy:0.39394546train loss: 1.6309489\n",
            " ********* validation accuracy:0.6324 validation loss: 1.3543928\n",
            "EPOCH 78.0\n",
            " train accuracy:0.40118182train loss: 1.6227949\n",
            " ********* validation accuracy:0.634 validation loss: 1.3472501\n",
            "EPOCH 79.0\n",
            " train accuracy:0.40505454train loss: 1.6114528\n",
            " ********* validation accuracy:0.6346 validation loss: 1.3402519\n",
            "EPOCH 80.0\n",
            " train accuracy:0.40243638train loss: 1.6111177\n",
            " ********* validation accuracy:0.6354 validation loss: 1.3333148\n",
            "EPOCH 81.0\n",
            " train accuracy:0.40394545train loss: 1.6069082\n",
            " ********* validation accuracy:0.6372 validation loss: 1.3264842\n",
            "EPOCH 82.0\n",
            " train accuracy:0.40789092train loss: 1.5983226\n",
            " ********* validation accuracy:0.6382 validation loss: 1.3197154\n",
            "EPOCH 83.0\n",
            " train accuracy:0.40945455train loss: 1.5958744\n",
            " ********* validation accuracy:0.6402 validation loss: 1.3130327\n",
            "EPOCH 84.0\n",
            " train accuracy:0.41034546train loss: 1.593973\n",
            " ********* validation accuracy:0.6406 validation loss: 1.3064082\n",
            "EPOCH 85.0\n",
            " train accuracy:0.4146909train loss: 1.5841926\n",
            " ********* validation accuracy:0.642 validation loss: 1.2998741\n",
            "EPOCH 86.0\n",
            " train accuracy:0.40994546train loss: 1.5824294\n",
            " ********* validation accuracy:0.6438 validation loss: 1.2934123\n",
            "EPOCH 87.0\n",
            " train accuracy:0.42023635train loss: 1.570719\n",
            " ********* validation accuracy:0.6446 validation loss: 1.286991\n",
            "EPOCH 88.0\n",
            " train accuracy:0.41796362train loss: 1.569991\n",
            " ********* validation accuracy:0.6454 validation loss: 1.2806816\n",
            "EPOCH 89.0\n",
            " train accuracy:0.41812727train loss: 1.5652819\n",
            " ********* validation accuracy:0.648 validation loss: 1.2744346\n",
            "EPOCH 90.0\n",
            " train accuracy:0.4191273train loss: 1.5597912\n",
            " ********* validation accuracy:0.6494 validation loss: 1.268253\n",
            "EPOCH 91.0\n",
            " train accuracy:0.4226909train loss: 1.5565237\n",
            " ********* validation accuracy:0.6506 validation loss: 1.262163\n",
            "EPOCH 92.0\n",
            " train accuracy:0.42543638train loss: 1.5544307\n",
            " ********* validation accuracy:0.652 validation loss: 1.2561426\n",
            "EPOCH 93.0\n",
            " train accuracy:0.42885455train loss: 1.5448853\n",
            " ********* validation accuracy:0.6526 validation loss: 1.2501953\n",
            "EPOCH 94.0\n",
            " train accuracy:0.43089092train loss: 1.5392747\n",
            " ********* validation accuracy:0.6544 validation loss: 1.2442783\n",
            "EPOCH 95.0\n",
            " train accuracy:0.43256363train loss: 1.5338587\n",
            " ********* validation accuracy:0.655 validation loss: 1.23843\n",
            "EPOCH 96.0\n",
            " train accuracy:0.43474546train loss: 1.5268434\n",
            " ********* validation accuracy:0.6562 validation loss: 1.2326458\n",
            "EPOCH 97.0\n",
            " train accuracy:0.43792728train loss: 1.5258787\n",
            " ********* validation accuracy:0.6584 validation loss: 1.2268863\n",
            "EPOCH 98.0\n",
            " train accuracy:0.434train loss: 1.5167224\n",
            " ********* validation accuracy:0.6616 validation loss: 1.2212273\n",
            "EPOCH 99.0\n",
            " train accuracy:0.43838182train loss: 1.5194966\n",
            " ********* validation accuracy:0.6624 validation loss: 1.2156187\n",
            "EPOCH 100.0\n",
            " train accuracy:0.43781817train loss: 1.5087237\n",
            " ********* validation accuracy:0.6628 validation loss: 1.2100422\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EqDeC51MyFnQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ngOoBZfnapbM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "GtCnAN0laokB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15b20b9f-9772-4713-bcb8-ce7235781c48"
      },
      "cell_type": "code",
      "source": [
        "a_test, c_test  = sess.run([accuracy, cross_entropy], feed_dict={X: x_test, y: y_test, pkeep_val: 1})\n",
        "\n",
        "print('Test accuracy is: ', (\"%.2f\"%(a_test*100))+'%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuracy is:  64.06%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TYN3t19Eaxj0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 9. Convolutional Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "RjxgtOMqayyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b317b2f-0be1-4502-a44a-53947c4a14cc"
      },
      "cell_type": "code",
      "source": [
        "''' Let Your Imagination Run Wild'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Let Your Imagination Run Wild'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}